:py:mod:`arkouda`
=================

.. py:module:: arkouda


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   _version/index.rst
   accessor/index.rst
   alignment/index.rst
   array_view/index.rst
   categorical/index.rst
   client/index.rst
   client_dtypes/index.rst
   dataframe/index.rst
   dtypes/index.rst
   groupbyclass/index.rst
   index/index.rst
   infoclass/index.rst
   io_util/index.rst
   join/index.rst
   logger/index.rst
   match/index.rst
   matcher/index.rst
   message/index.rst
   numeric/index.rst
   pdarrayIO/index.rst
   pdarrayclass/index.rst
   pdarraycreation/index.rst
   pdarraysetops/index.rst
   plotting/index.rst
   row/index.rst
   security/index.rst
   segarray/index.rst
   series/index.rst
   sorting/index.rst
   strings/index.rst
   timeclass/index.rst
   util/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   arkouda.pdarray
   arkouda.ArrayView
   arkouda.pdarray
   arkouda.Strings
   arkouda.GroupBy
   arkouda.BitVector
   arkouda.Fields
   arkouda.IPv4
   arkouda.pdarray
   arkouda.GroupBy
   arkouda.Strings
   arkouda.Categorical
   arkouda.pdarray
   arkouda._Timescalar
   arkouda._AbstractBaseTime
   arkouda.Datetime
   arkouda.Timedelta
   arkouda.pdarray
   arkouda.GroupBy
   arkouda.SegArray
   arkouda.DataFrame
   arkouda.Row
   arkouda.pdarray
   arkouda.GroupBy
   arkouda.Index
   arkouda.MultiIndex
   arkouda.Series
   arkouda.Strings
   arkouda.pdarray
   arkouda.Categorical
   arkouda.GroupBy
   arkouda.Datetime
   arkouda.Categorical
   arkouda.Strings
   arkouda.CachedAccessor
   arkouda.Properties
   arkouda.DatetimeAccessor
   arkouda.StringAccessor



Functions
~~~~~~~~~

.. autoapisummary::

   arkouda.get_versions
   arkouda.parse_single_value
   arkouda.create_pdarray
   arkouda.array
   arkouda.arange
   arkouda.zeros
   arkouda.ones
   arkouda.full
   arkouda.concatenate
   arkouda.translate_np_dtype
   arkouda.resolve_scalar_dtype
   arkouda.isSupportedInt
   arkouda.zeros
   arkouda.arange
   arkouda.array
   arkouda.broadcast
   arkouda.BitVectorizer
   arkouda.ip_address
   arkouda.check_np_dtype
   arkouda.translate_np_dtype
   arkouda.resolve_scalar_dtype
   arkouda.get_byteorder
   arkouda.get_server_byteorder
   arkouda.clear
   arkouda.any
   arkouda.all
   arkouda.is_sorted
   arkouda.sum
   arkouda.prod
   arkouda.min
   arkouda.max
   arkouda.argmin
   arkouda.argmax
   arkouda.mean
   arkouda.var
   arkouda.std
   arkouda.mink
   arkouda.maxk
   arkouda.argmink
   arkouda.argmaxk
   arkouda.popcount
   arkouda.parity
   arkouda.clz
   arkouda.ctz
   arkouda.rotl
   arkouda.rotr
   arkouda.attach_pdarray
   arkouda.unregister_pdarray_by_name
   arkouda.argsort
   arkouda.coargsort
   arkouda.sort
   arkouda.in1d
   arkouda.concatenate
   arkouda.union1d
   arkouda.intersect1d
   arkouda.setdiff1d
   arkouda.setxor1d
   arkouda.array
   arkouda.zeros
   arkouda.ones
   arkouda.full
   arkouda.zeros_like
   arkouda.ones_like
   arkouda.full_like
   arkouda.arange
   arkouda.linspace
   arkouda.randint
   arkouda.uniform
   arkouda.standard_normal
   arkouda.random_strings_uniform
   arkouda.random_strings_lognormal
   arkouda.from_series
   arkouda.ls
   arkouda.read
   arkouda.load
   arkouda.get_datasets
   arkouda.load_all
   arkouda.save_all
   arkouda.get_filetype
   arkouda.get_null_indices
   arkouda.unique
   arkouda.broadcast
   arkouda.join_on_eq_with_dt
   arkouda.enableVerbose
   arkouda.disableVerbose
   arkouda.isSupportedInt
   arkouda.from_series
   arkouda.ak_array
   arkouda._get_factor
   arkouda._identity
   arkouda.date_range
   arkouda.timedelta_range
   arkouda.information
   arkouda.list_registry
   arkouda.list_symbol_table
   arkouda.pretty_print_information
   arkouda.is_sorted
   arkouda.attach_pdarray
   arkouda.isSupportedInt
   arkouda.zeros
   arkouda.ones
   arkouda.array
   arkouda.arange
   arkouda.concatenate
   arkouda.unique
   arkouda.broadcast
   arkouda.load
   arkouda.gen_ranges
   arkouda._aggregator
   arkouda.sorted
   arkouda.intersect
   arkouda.invert_permutation
   arkouda.intx
   arkouda.arange
   arkouda.ones
   arkouda.argsort
   arkouda.in1d
   arkouda.coargsort
   arkouda.register
   arkouda.convert_if_categorical
   arkouda.concatenate
   arkouda.get_callback
   arkouda.unique
   arkouda.in1dmulti
   arkouda.is_sorted
   arkouda.array
   arkouda.arange
   arkouda.ones
   arkouda.zeros
   arkouda.concatenate
   arkouda.in1d
   arkouda.argsort
   arkouda.unique
   arkouda.broadcast
   arkouda.unsqueeze
   arkouda.zero_up
   arkouda.align
   arkouda.right_align
   arkouda.left_align
   arkouda.in1dmulti
   arkouda.lookup
   arkouda.in1d_intervals
   arkouda.search_intervals
   arkouda.interval_lookup
   arkouda.plot_dist
   arkouda.string_operators
   arkouda.date_operators



Attributes
~~~~~~~~~~

.. autoapisummary::

   arkouda.__version__
   arkouda.OrderType
   arkouda.intTypes
   arkouda.bitType
   arkouda.akint64
   arkouda.DTypes
   arkouda.DTypeObjects
   arkouda.dtype
   arkouda.bool
   arkouda.int64
   arkouda.float64
   arkouda.uint8
   arkouda.uint64
   arkouda.str_
   arkouda.intTypes
   arkouda.bitType
   arkouda.ARKOUDA_SUPPORTED_DTYPES
   arkouda.bool_scalars
   arkouda.float_scalars
   arkouda.int_scalars
   arkouda.numeric_scalars
   arkouda.numpy_scalars
   arkouda.str_scalars
   arkouda.all_scalars
   arkouda.SortingAlgorithm
   arkouda.GROUPBY_REDUCTION_TYPES
   arkouda.int64
   arkouda.intTypes
   arkouda._BASE_UNIT
   arkouda._unit2normunit
   arkouda._unit2factor
   arkouda.AllSymbols
   arkouda.RegisteredSymbols
   arkouda.akint64
   arkouda.akbool
   arkouda.str_
   arkouda.int64
   arkouda.float64
   arkouda.bool
   arkouda.akbool
   arkouda.akint64
   arkouda.akfloat64


.. py:function:: get_versions()

   Get version information or return default if unable to do so.


.. py:data:: __version__
   

   

.. py:class:: pdarray(name: str, mydtype: numpy.dtype, size: arkouda.dtypes.int_scalars, ndim: arkouda.dtypes.int_scalars, shape: Sequence[int], itemsize: arkouda.dtypes.int_scalars)

   The basic arkouda array class. This class contains only the
   attributies of the array; the data resides on the arkouda
   server. When a server operation results in a new array, arkouda
   will create a pdarray instance that points to the array data on
   the server. As such, the user should not initialize pdarray
   instances directly.

   .. attribute:: name

      The server-side identifier for the array

      :type: str

   .. attribute:: dtype

      The element type of the array

      :type: dtype

   .. attribute:: size

      The number of elements in the array

      :type: int_scalars

   .. attribute:: ndim

      The rank of the array (currently only rank 1 arrays supported)

      :type: int_scalars

   .. attribute:: shape

      A list or tuple containing the sizes of each dimension of the array

      :type: Sequence[int]

   .. attribute:: itemsize

      The size in bytes of each element

      :type: int_scalars

   .. py:attribute:: BinOps
      

      

   .. py:attribute:: OpEqOps
      

      

   .. py:attribute:: objtype
      :annotation: = pdarray

      

   .. py:attribute:: __array_priority__
      :annotation: = 1000

      

   .. py:method:: __del__(self)


   .. py:method:: __bool__(self) -> bool


   .. py:method:: __len__(self)


   .. py:method:: __str__(self)

      Return str(self).


   .. py:method:: __repr__(self)

      Return repr(self).


   .. py:method:: format_other(self, other: object) -> str

      Attempt to cast scalar other to the element dtype of this pdarray,
      and print the resulting value to a string (e.g. for sending to a
      server command). The user should not call this function directly.

      :param other: The scalar to be cast to the pdarray.dtype
      :type other: object

      :rtype: string representation of np.dtype corresponding to the other parameter

      :raises TypeError: Raised if the other parameter cannot be converted to
          Numpy dtype


   .. py:method:: _binop(self, other: pdarray, op: str) -> pdarray

      Executes binary operation specified by the op string

      :param other: The pdarray upon which the binop is to be executed
      :type other: pdarray
      :param op: The binop to be executed
      :type op: str

      :returns: A pdarray encapsulating the binop result
      :rtype: pdarray

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set, or if the
          pdarray sizes don't match
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype


   .. py:method:: _r_binop(self, other: pdarray, op: str) -> pdarray

      Executes reverse binary operation specified by the op string

      :param other: The pdarray upon which the reverse binop is to be executed
      :type other: pdarray
      :param op: The name of the reverse binop to be executed
      :type op: str

      :returns: A pdarray encapsulating the reverse binop result
      :rtype: pdarray

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype


   .. py:method:: __add__(self, other)


   .. py:method:: __radd__(self, other)


   .. py:method:: __sub__(self, other)


   .. py:method:: __rsub__(self, other)


   .. py:method:: __mul__(self, other)


   .. py:method:: __rmul__(self, other)


   .. py:method:: __truediv__(self, other)


   .. py:method:: __rtruediv__(self, other)


   .. py:method:: __floordiv__(self, other)


   .. py:method:: __rfloordiv__(self, other)


   .. py:method:: __mod__(self, other)


   .. py:method:: __rmod__(self, other)


   .. py:method:: __lshift__(self, other)


   .. py:method:: __rlshift__(self, other)


   .. py:method:: __rshift__(self, other)


   .. py:method:: __rrshift__(self, other)


   .. py:method:: __and__(self, other)


   .. py:method:: __rand__(self, other)


   .. py:method:: __or__(self, other)


   .. py:method:: __ror__(self, other)


   .. py:method:: __xor__(self, other)


   .. py:method:: __rxor__(self, other)


   .. py:method:: __pow__(self, other)


   .. py:method:: __rpow__(self, other)


   .. py:method:: __lt__(self, other)

      Return self<value.


   .. py:method:: __gt__(self, other)

      Return self>value.


   .. py:method:: __le__(self, other)

      Return self<=value.


   .. py:method:: __ge__(self, other)

      Return self>=value.


   .. py:method:: __eq__(self, other)

      Return self==value.


   .. py:method:: __ne__(self, other)

      Return self!=value.


   .. py:method:: __neg__(self)


   .. py:method:: __invert__(self)


   .. py:method:: opeq(self, other, op)


   .. py:method:: __iadd__(self, other)


   .. py:method:: __isub__(self, other)


   .. py:method:: __imul__(self, other)


   .. py:method:: __itruediv__(self, other)


   .. py:method:: __ifloordiv__(self, other)


   .. py:method:: __ilshift__(self, other)


   .. py:method:: __irshift__(self, other)


   .. py:method:: __iand__(self, other)


   .. py:method:: __ior__(self, other)


   .. py:method:: __ixor__(self, other)


   .. py:method:: __ipow__(self, other)


   .. py:method:: __iter__(self)
      :abstractmethod:


   .. py:method:: __getitem__(self, key)


   .. py:method:: __setitem__(self, key, value)


   .. py:method:: fill(self, value: arkouda.dtypes.numeric_scalars) -> None

      Fill the array (in place) with a constant value.

      :param value:
      :type value: numeric_scalars

      :raises TypeError: Raised if value is not an int, int64, float, or float64


   .. py:method:: any(self) -> numpy.bool_

      Return True iff any element of the array evaluates to True.


   .. py:method:: all(self) -> numpy.bool_

      Return True iff all elements of the array evaluate to True.


   .. py:method:: is_registered(self) -> numpy.bool_

      Return True iff the object is contained in the registry

      :param None:

      :returns: Indicates if the object is contained in the registry
      :rtype: bool

      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: _list_component_names(self) -> List[str]

      Internal Function that returns a list of all component names

      :param None:

      :returns: List of all component names
      :rtype: List[str]


   .. py:method:: info(self) -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str


   .. py:method:: pretty_print_info(self) -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None


   .. py:method:: is_sorted(self) -> numpy.bool_

      Return True iff the array is monotonically non-decreasing.

      :param None:

      :returns: Indicates if the array is monotonically non-decreasing
      :rtype: bool

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: sum(self) -> arkouda.dtypes.numeric_and_bool_scalars

      Return the sum of all elements in the array.


   .. py:method:: prod(self) -> numpy.float64

      Return the product of all elements in the array. Return value is
      always a np.float64 or np.int64.


   .. py:method:: min(self) -> arkouda.dtypes.numpy_scalars

      Return the minimum value of the array.


   .. py:method:: max(self) -> arkouda.dtypes.numpy_scalars

      Return the maximum value of the array.


   .. py:method:: argmin(self) -> numpy.int64

      Return the index of the first occurrence of the array min value


   .. py:method:: argmax(self) -> numpy.int64

      Return the index of the first occurrence of the array max value.


   .. py:method:: mean(self) -> numpy.float64

      Return the mean of the array.


   .. py:method:: var(self, ddof: arkouda.dtypes.int_scalars = 0) -> numpy.float64

      Compute the variance. See ``arkouda.var`` for details.

      :param ddof: "Delta Degrees of Freedom" used in calculating var
      :type ddof: int_scalars

      :returns: The scalar variance of the array
      :rtype: np.float64

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises ValueError: Raised if the ddof >= pdarray size
      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: std(self, ddof: arkouda.dtypes.int_scalars = 0) -> numpy.float64

      Compute the standard deviation. See ``arkouda.std`` for details.

      :param ddof: "Delta Degrees of Freedom" used in calculating std
      :type ddof: int_scalars

      :returns: The scalar standard deviation of the array
      :rtype: np.float64

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: mink(self, k: arkouda.dtypes.int_scalars) -> pdarray

      Compute the minimum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: The maximum `k` values from pda
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray


   .. py:method:: maxk(self, k: arkouda.dtypes.int_scalars) -> pdarray

      Compute the maximum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: The maximum `k` values from pda
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray


   .. py:method:: argmink(self, k: arkouda.dtypes.int_scalars) -> pdarray

      Compute the minimum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: Indices corresponding to the maximum `k` values from pda
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray


   .. py:method:: argmaxk(self, k: arkouda.dtypes.int_scalars) -> pdarray

      Finds the indices corresponding to the maximum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: Indices corresponding to the  maximum `k` values, sorted
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray


   .. py:method:: popcount(self) -> pdarray

      Find the population (number of bits set) in each element. See `ak.popcount`.


   .. py:method:: parity(self) -> pdarray

      Find the parity (XOR of all bits) in each element. See `ak.parity`.


   .. py:method:: clz(self) -> pdarray

      Count the number of leading zeros in each element. See `ak.clz`.


   .. py:method:: ctz(self) -> pdarray

      Count the number of trailing zeros in each element. See `ak.ctz`.


   .. py:method:: rotl(self, other) -> pdarray

      Rotate bits left by <other>.


   .. py:method:: rotr(self, other) -> pdarray

      Rotate bits right by <other>.


   .. py:method:: astype(self, dtype) -> pdarray

      Cast values of pdarray to provided dtype

      :param dtype: Dtype to cast to
      :type dtype: np.dtype or str

      :returns: An arkouda pdarray with values converted to the specified data type
      :rtype: ak.pdarray

      .. rubric:: Notes

      This is essentially shorthand for ak.cast(x, '<dtype>') where x is a pdarray.


   .. py:method:: reshape(self, *shape, order='row_major')

      Gives a new shape to an array without changing its data.

      :param shape: The new shape should be compatible with the original shape.
      :type shape: int, tuple of ints, or pdarray
      :param order: Read the elements of the pdarray in this index order
                    By default, read the elements in row_major or C-like order where the last index changes the fastest
                    If 'column_major' or 'F', read the elements in column_major or Fortran-like order where the first index changes the fastest
      :type order: str {'row_major' | 'C' | 'column_major' | 'F'}

      :returns: An arrayview object with the data from the array but with the new shape
      :rtype: ArrayView


   .. py:method:: to_ndarray(self) -> numpy.ndarray

      Convert the array to a np.ndarray, transferring array data from the
      Arkouda server to client-side Python. Note: if the pdarray size exceeds
      client.maxTransferBytes, a RuntimeError is raised.

      :returns: A numpy ndarray with the same attributes and data as the pdarray
      :rtype: np.ndarray

      :raises RuntimeError: Raised if there is a server-side error thrown, if the pdarray size
          exceeds the built-in client.maxTransferBytes size limit, or if the bytes
          received does not match expected number of bytes

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_ndarray()
      array([0, 1, 2, 3, 4])

      >>> type(a.to_ndarray())
      numpy.ndarray


   .. py:method:: to_cuda(self)

      Convert the array to a Numba DeviceND array, transferring array data from the
      arkouda server to Python via ndarray. If the array exceeds a builtin size limit,
      a RuntimeError is raised.

      :returns: A Numba ndarray with the same attributes and data as the pdarray; on GPU
      :rtype: numba.DeviceNDArray

      :raises ImportError: Raised if CUDA is not available
      :raises ModuleNotFoundError: Raised if Numba is either not installed or not enabled
      :raises RuntimeError: Raised if there is a server-side error thrown in the course of retrieving
          the pdarray.

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_cuda()
      array([0, 1, 2, 3, 4])

      >>> type(a.to_cuda())
      numpy.devicendarray


   .. py:method:: save(self, prefix_path: str, dataset: str = 'array', mode: str = 'truncate', compressed: bool = False, file_format: str = 'HDF5') -> str

      Save the pdarray to HDF5 or Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param compressed: Defaults to False. When True, files will be written with Snappy compression
                         and RLE bit packing. This is currently only supported on Parquet files and will
                         not impact the generated files when writing HDF5 files.
      :type compressed: bool
      :param file_format: By default, saved files will be written to the HDF5 file format. If
                          'Parquet', the files will be written to the Parquet file format. This
                          is case insensitive.
      :type file_format: str {'HDF5', 'Parquet'}

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray
      :raises ValueError: Raised if there is an error in parsing the prefix path pointing to
          file write location or if the mode parameter is neither truncate
          nor append
      :raises TypeError: Raised if any one of the prefix_path, dataset, or mode parameters
          is not a string

      .. seealso:: :obj:`save_all`, :obj:`load`, :obj:`read`

      .. rubric:: Notes

      The prefix_path must be visible to the arkouda server and the user must
      have write permission.

      Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales``. If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.

      .. rubric:: Examples

      >>> a = ak.arange(0, 100, 1)
      >>> a.save('arkouda_range', dataset='array')
      >>> a.save('arkouda_range_parquet', dataset='array', file_format='Parquet')

      Array is saved in numLocales files with names like ``tmp/arkouda_range_LOCALE0``

      The array can be read back in as follows

      >>> b = ak.read('arkouda_range', dataset='array')
      >>> (a == b).all()
      True

      >>> c = ak.read_parquet('arkouda_range_parquet*')
      >>> (c == b).all()
      True


   .. py:method:: save_parquet(self, prefix_path: str, dataset: str = 'array', mode: str = 'truncate', compressed: bool = False) -> str

      Save the pdarray to Parquet. The result is a collection of Parquet files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in Parquet files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
      :type mode: str {'truncate', 'append'}
      :param compressed: By default, write without Snappy compression and RLE encoding.
      :type compressed: bool

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray
      :raises ValueError: Raised if there is an error in parsing the prefix path pointing to
          file write location or if the mode parameter is neither truncate
          nor append
      :raises TypeError: Raised if any one of the prefix_path, dataset, or mode parameters
          is not a string

      .. seealso:: :obj:`save`, :obj:`save_all`, :obj:`load`, :obj:`read`

      .. rubric:: Notes

      The prefix_path must be visible to the arkouda server and the user must
      have write permission.

      Output files have names of the form ``<prefix_path>_LOCALE<i>.parquet``, where ``<i>``
      ranges from 0 to ``numLocales``. If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.

      .. rubric:: Examples

      >>> a = ak.arange(0, 100, 1)
      >>> a.save_parquet('arkouda_range')

      Array is saved in numLocales files with names like ``arkouda_range_LOCALE0000.parquet``

      The array can be read back in as follows

      >>> b = ak.read('arkouda_range')
      >>> (a == b).all()
      True


   .. py:method:: save_hdf(self, prefix_path: str, dataset: str = 'array', mode: str = 'truncate') -> str

      Save the pdarray to HDF5. The result is a collection of HDF5 files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in HDF5 files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
      :type mode: str {'truncate', 'append'}
      :param compressed: By default, write without Snappy compression and RLE encoding.
      :type compressed: bool

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray
      :raises ValueError: Raised if there is an error in parsing the prefix path pointing to
          file write location or if the mode parameter is neither truncate
          nor append
      :raises TypeError: Raised if any one of the prefix_path, dataset, or mode parameters
          is not a string

      .. seealso:: :obj:`save`, :obj:`save_all`, :obj:`load`, :obj:`read`

      .. rubric:: Notes

      The prefix_path must be visible to the arkouda server and the user must
      have write permission.

      Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales``. If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.

      .. rubric:: Examples

      >>> a = ak.arange(0, 100, 1)
      >>> a.save_hdf('arkouda_range')

      Array is saved in numLocales files with names like ``arkouda_range_LOCALE0000``

      The array can be read back in as follows

      >>> b = ak.read('arkouda_range')
      >>> (a == b).all()
      True


   .. py:method:: register(self, user_defined_name: str) -> pdarray

      Register this pdarray with a user defined name in the arkouda server
      so it can be attached to later using pdarray.attach()
      This is an in-place operation, registering a pdarray more than once will
      update the name in the registry and remove the previously registered name.
      A name can only be registered to one pdarray at a time.

      :param user_defined_name: user defined name array is to be registered under
      :type user_defined_name: str

      :returns: The same pdarray which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support a fluid programming style.
                Please note you cannot register two different pdarrays with the same name.
      :rtype: pdarray

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the pdarray with the user_defined_name
          If the user is attempting to register more than one pdarray with the same name, the former should be
          unregistered first to free up the registration name.

      .. seealso:: :obj:`attach`, :obj:`unregister`, :obj:`is_registered`, :obj:`list_registry`, :obj:`unregister_pdarray_by_name`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion
      until they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()


   .. py:method:: unregister(self) -> None

      Unregister a pdarray in the arkouda server which was previously
      registered using register() and/or attahced to using attach()


      :rtype: None

      :raises RuntimeError: Raised if the server could not find the internal name/symbol to remove

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion until
      they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()


   .. py:method:: attach(user_defined_name: str) -> pdarray
      :staticmethod:

      class method to return a pdarray attached to the registered name in the arkouda
      server which was registered using register()

      :param user_defined_name: user defined name which array was registered under
      :type user_defined_name: str

      :returns: pdarray which is bound to corresponding server side component that was registered with user_defined_name
      :rtype: pdarray

      :raises TypeError: Raised if user_defined_name is not a str

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion
      until they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()


   .. py:method:: _get_grouping_keys(self) -> List[pdarray]

      Private method for generating grouping keys used by GroupBy.

      API: this method must be defined by all groupable arrays, and it
      must return a list of arrays that can be (co)argsorted.



.. py:function:: parse_single_value(msg: str) -> object

   Attempt to convert a scalar return value from the arkouda server to a
   numpy scalar in Python. The user should not call this function directly.

   :param msg: scalar value in string form to be converted to a numpy scalar
   :type msg: str

   :rtype: object numpy scalar


.. py:function:: create_pdarray(repMsg: str) -> pdarray

       Return a pdarray instance pointing to an array created by the arkouda server.
       The user should not call this function directly.

       Parameters
       ----------
       repMsg : str
           space-delimited string containing the pdarray name, datatype, size
           dimension, shape,and itemsize

       Returns
       -------
       pdarray
           A pdarray with the same attributes and data as the pdarray; on GPU

       Raises
   -   -----
       ValueError
           If there's an error in parsing the repMsg parameter into the six
           values needed to create the pdarray instance
       RuntimeError
           Raised if a server-side error is thrown in the process of creating
           the pdarray instance



.. py:function:: array(a: Union[arkouda.pdarrayclass.pdarray, numpy.ndarray, Iterable], dtype: Union[numpy.dtype, type, str] = None) -> Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]

   Convert a Python or Numpy Iterable to a pdarray or Strings object, sending
   the corresponding data to the arkouda server.

   :param a: Rank-1 array of a supported dtype
   :type a: Union[pdarray, np.ndarray]
   :param dtype: The target dtype to cast values to
   :type dtype: np.dtype, type, or str

   :returns: A pdarray instance stored on arkouda server or Strings instance, which
             is composed of two pdarrays stored on arkouda server
   :rtype: pdarray or Strings

   :raises TypeError: Raised if a is not a pdarray, np.ndarray, or Python Iterable such as a
       list, array, tuple, or deque
   :raises RuntimeError: Raised if a is not one-dimensional, nbytes > maxTransferBytes, a.dtype is
       not supported (not in DTypes), or if the product of a size and
       a.itemsize > maxTransferBytes
   :raises ValueError: Raised if the returned message is malformed or does not contain the fields
       required to generate the array.

   .. seealso:: :obj:`pdarray.to_ndarray`

   .. rubric:: Notes

   The number of bytes in the input array cannot exceed `arkouda.maxTransferBytes`,
   otherwise a RuntimeError will be raised. This is to protect the user
   from overwhelming the connection between the Python client and the arkouda
   server, under the assumption that it is a low-bandwidth connection. The user
   may override this limit by setting ak.maxTransferBytes to a larger value,
   but should proceed with caution.

   If the pdrray or ndarray is of type U, this method is called twice recursively
   to create the Strings object and the two corresponding pdarrays for string
   bytes and offsets, respectively.

   .. rubric:: Examples

   >>> ak.array(np.arange(1,10))
   array([1, 2, 3, 4, 5, 6, 7, 8, 9])

   >>> ak.array(range(1,10))
   array([1, 2, 3, 4, 5, 6, 7, 8, 9])

   >>> strings = ak.array(['string {}'.format(i) for i in range(0,5)])
   >>> type(strings)
   <class 'arkouda.strings.Strings'>


.. py:function:: arange(*args, **kwargs) -> arkouda.pdarrayclass.pdarray

   arange([start,] stop[, stride,] dtype=int64)

   Create a pdarray of consecutive integers within the interval [start, stop).
   If only one arg is given then arg is the stop parameter. If two args are
   given, then the first arg is start and second is stop. If three args are
   given, then the first arg is start, second is stop, third is stride.

   The return value is cast to type dtype

   :param start: Starting value (inclusive)
   :type start: int_scalars, optional
   :param stop: Stopping value (exclusive)
   :type stop: int_scalars
   :param stride: The difference between consecutive elements, the default stride is 1,
                  if stride is specified then start must also be specified.
   :type stride: int_scalars, optional
   :param dtype: The target dtype to cast values to
   :type dtype: np.dtype, type, or str

   :returns: Integers from start (inclusive) to stop (exclusive) by stride
   :rtype: pdarray, dtype

   :raises TypeError: Raised if start, stop, or stride is not an int object
   :raises ZeroDivisionError: Raised if stride == 0

   .. seealso:: :obj:`linspace`, :obj:`zeros`, :obj:`ones`, :obj:`randint`

   .. rubric:: Notes

   Negative strides result in decreasing values. Currently, only int64
   pdarrays can be created with this method. For float64 arrays, use
   the linspace method.

   .. rubric:: Examples

   >>> ak.arange(0, 5, 1)
   array([0, 1, 2, 3, 4])

   >>> ak.arange(5, 0, -1)
   array([5, 4, 3, 2, 1])

   >>> ak.arange(0, 10, 2)
   array([0, 2, 4, 6, 8])

   >>> ak.arange(-5, -10, -1)
   array([-5, -6, -7, -8, -9])


.. py:function:: zeros(size: Union[arkouda.dtypes.int_scalars, str], dtype: Union[numpy.dtype, type, str] = float64) -> arkouda.pdarrayclass.pdarray

   Create a pdarray filled with zeros.

   :param size: Size of the array (only rank-1 arrays supported)
   :type size: int_scalars
   :param dtype: Type of resulting array, default float64
   :type dtype: all_scalars

   :returns: Zeros of the requested size and dtype
   :rtype: pdarray

   :raises TypeError: Raised if the supplied dtype is not supported or if the size
       parameter is neither an int nor a str that is parseable to an int.

   .. seealso:: :obj:`ones`, :obj:`zeros_like`

   .. rubric:: Examples

   >>> ak.zeros(5, dtype=ak.int64)
   array([0, 0, 0, 0, 0])

   >>> ak.zeros(5, dtype=ak.float64)
   array([0, 0, 0, 0, 0])

   >>> ak.zeros(5, dtype=ak.bool)
   array([False, False, False, False, False])


.. py:function:: ones(size: Union[arkouda.dtypes.int_scalars, str], dtype: Union[numpy.dtype, type, str] = float64) -> arkouda.pdarrayclass.pdarray

   Create a pdarray filled with ones.

   :param size: Size of the array (only rank-1 arrays supported)
   :type size: int_scalars
   :param dtype: Resulting array type, default float64
   :type dtype: Union[float64, int64, bool]

   :returns: Ones of the requested size and dtype
   :rtype: pdarray

   :raises TypeError: Raised if the supplied dtype is not supported or if the size
       parameter is neither an int nor a str that is parseable to an int.

   .. seealso:: :obj:`zeros`, :obj:`ones_like`

   .. rubric:: Examples

   >>> ak.ones(5, dtype=ak.int64)
   array([1, 1, 1, 1, 1])

   >>> ak.ones(5, dtype=ak.float64)
   array([1, 1, 1, 1, 1])

   >>> ak.ones(5, dtype=ak.bool)
   array([True, True, True, True, True])


.. py:function:: full(size: Union[arkouda.dtypes.int_scalars, str], fill_value: arkouda.dtypes.int_scalars, dtype: Union[numpy.dtype, type, str] = float64) -> arkouda.pdarrayclass.pdarray

   Create a pdarray filled with fill_value.

   :param size: Size of the array (only rank-1 arrays supported)
   :type size: int_scalars
   :param fill_value: Value with which the array will be filled
   :type fill_value: int_scalars
   :param dtype: Resulting array type, default float64
   :type dtype: all_scalars

   :returns: array of the requested size and dtype filled with fill_value
   :rtype: pdarray

   :raises TypeError: Raised if the supplied dtype is not supported or if the size
       parameter is neither an int nor a str that is parseable to an int.

   .. seealso:: :obj:`zeros`, :obj:`ones`

   .. rubric:: Examples

   >>> ak.full(5, 7, dtype=ak.int64)
   array([7, 7, 7, 7, 7])

   >>> ak.full(5, 9, dtype=ak.float64)
   array([9, 9, 9, 9, 9])

   >>> ak.full(5, 5, dtype=ak.bool)
   array([True, True, True, True, True])


.. py:function:: concatenate(arrays: Sequence[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, Categorical]], ordered: bool = True) -> Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, Categorical]

   Concatenate a list or tuple of ``pdarray`` or ``Strings`` objects into
   one ``pdarray`` or ``Strings`` object, respectively.

   :param arrays: The arrays to concatenate. Must all have same dtype.
   :type arrays: Sequence[Union[pdarray,Strings,Categorical]]
   :param ordered: If True (default), the arrays will be appended in the
                   order given. If False, array data may be interleaved
                   in blocks, which can greatly improve performance but
                   results in non-deterministic ordering of elements.
   :type ordered: bool

   :returns: Single pdarray or Strings object containing all values, returned in
             the original order
   :rtype: Union[pdarray,Strings,Categorical]

   :raises ValueError: Raised if arrays is empty or if 1..n pdarrays have
       differing dtypes
   :raises TypeError: Raised if arrays is not a pdarrays or Strings python Sequence such as a
       list or tuple
   :raises RuntimeError: Raised if 1..n array elements are dtypes for which
       concatenate has not been implemented.

   .. rubric:: Examples

   >>> ak.concatenate([ak.array([1, 2, 3]), ak.array([4, 5, 6])])
   array([1, 2, 3, 4, 5, 6])

   >>> ak.concatenate([ak.array([True,False,True]),ak.array([False,True,True])])
   array([True, False, True, False, True, True])

   >>> ak.concatenate([ak.array(['one','two']),ak.array(['three','four','five'])])
   array(['one', 'two', 'three', 'four', 'five'])


.. py:function:: translate_np_dtype(dt: numpy.dtype) -> Tuple[str, int]

   Split numpy dtype dt into its kind and byte size, raising
   TypeError for unsupported dtypes.

   :raises TypeError: Raised if the dtype is not in supported dtypes or if
       dt is not a np.dtype


.. py:function:: resolve_scalar_dtype(val: object) -> str

   Try to infer what dtype arkouda_server should treat val as.


.. py:data:: OrderType
   

   

.. py:class:: ArrayView(base: arkouda.pdarrayclass.pdarray, shape, order='row_major')

   A multi-dimensional view of a pdarray. Arkouda ``ArraryView`` behaves similarly to numpy's ndarray.
   The base pdarray is stored in 1-dimension but can be indexed and treated logically as if it were multi-dimensional

   .. attribute:: base

      The base pdarray that is being viewed as a multi-dimensional object

      :type: pdarray

   .. attribute:: dtype

      The element type of the base pdarray (equivalent to base.dtype)

      :type: dtype

   .. attribute:: size

      The number of elements in the base pdarray (equivalent to base.size)

      :type: int_scalars

   .. attribute:: shape

      A pdarray specifying the sizes of each dimension of the array

      :type: pdarray[int]

   .. attribute:: ndim

      Number of dimensions (equivalent to shape.size)

      :type: int_scalars

   .. attribute:: itemsize

      The size in bytes of each element (equivalent to base.itemsize)

      :type: int_scalars

   .. attribute:: order

      Index order to read and write the elements.
      By default or if 'C'/'row_major', read and write data in row_major order
      If 'F'/'column_major', read and write data in column_major order

      :type: str {'C'/'row_major' | 'F'/'column_major'}

   .. py:method:: __len__(self)


   .. py:method:: __repr__(self)

      Return repr(self).


   .. py:method:: __str__(self)

      Return str(self).


   .. py:method:: __getitem__(self, key)


   .. py:method:: __setitem__(self, key, value)


   .. py:method:: to_ndarray(self) -> numpy.ndarray

      Convert the ArrayView to a np.ndarray, transferring array data from the
      Arkouda server to client-side Python. Note: if the ArrayView size exceeds
      client.maxTransferBytes, a RuntimeError is raised.

      :returns: A numpy ndarray with the same attributes and data as the ArrayView
      :rtype: np.ndarray

      :raises RuntimeError: Raised if there is a server-side error thrown, if the ArrayView size
          exceeds the built-in client.maxTransferBytes size limit, or if the bytes
          received does not match expected number of bytes

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`

      .. rubric:: Examples

      >>> a = ak.arange(6).reshape(2,3)
      >>> a.to_ndarray()
      array([[0, 1, 2],
             [3, 4, 5]])
      >>> type(a.to_ndarray())
      numpy.ndarray



.. py:class:: pdarray(name: str, mydtype: numpy.dtype, size: arkouda.dtypes.int_scalars, ndim: arkouda.dtypes.int_scalars, shape: Sequence[int], itemsize: arkouda.dtypes.int_scalars)

   The basic arkouda array class. This class contains only the
   attributies of the array; the data resides on the arkouda
   server. When a server operation results in a new array, arkouda
   will create a pdarray instance that points to the array data on
   the server. As such, the user should not initialize pdarray
   instances directly.

   .. attribute:: name

      The server-side identifier for the array

      :type: str

   .. attribute:: dtype

      The element type of the array

      :type: dtype

   .. attribute:: size

      The number of elements in the array

      :type: int_scalars

   .. attribute:: ndim

      The rank of the array (currently only rank 1 arrays supported)

      :type: int_scalars

   .. attribute:: shape

      A list or tuple containing the sizes of each dimension of the array

      :type: Sequence[int]

   .. attribute:: itemsize

      The size in bytes of each element

      :type: int_scalars

   .. py:attribute:: BinOps
      

      

   .. py:attribute:: OpEqOps
      

      

   .. py:attribute:: objtype
      :annotation: = pdarray

      

   .. py:attribute:: __array_priority__
      :annotation: = 1000

      

   .. py:method:: __del__(self)


   .. py:method:: __bool__(self) -> bool


   .. py:method:: __len__(self)


   .. py:method:: __str__(self)

      Return str(self).


   .. py:method:: __repr__(self)

      Return repr(self).


   .. py:method:: format_other(self, other: object) -> str

      Attempt to cast scalar other to the element dtype of this pdarray,
      and print the resulting value to a string (e.g. for sending to a
      server command). The user should not call this function directly.

      :param other: The scalar to be cast to the pdarray.dtype
      :type other: object

      :rtype: string representation of np.dtype corresponding to the other parameter

      :raises TypeError: Raised if the other parameter cannot be converted to
          Numpy dtype


   .. py:method:: _binop(self, other: pdarray, op: str) -> pdarray

      Executes binary operation specified by the op string

      :param other: The pdarray upon which the binop is to be executed
      :type other: pdarray
      :param op: The binop to be executed
      :type op: str

      :returns: A pdarray encapsulating the binop result
      :rtype: pdarray

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set, or if the
          pdarray sizes don't match
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype


   .. py:method:: _r_binop(self, other: pdarray, op: str) -> pdarray

      Executes reverse binary operation specified by the op string

      :param other: The pdarray upon which the reverse binop is to be executed
      :type other: pdarray
      :param op: The name of the reverse binop to be executed
      :type op: str

      :returns: A pdarray encapsulating the reverse binop result
      :rtype: pdarray

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype


   .. py:method:: __add__(self, other)


   .. py:method:: __radd__(self, other)


   .. py:method:: __sub__(self, other)


   .. py:method:: __rsub__(self, other)


   .. py:method:: __mul__(self, other)


   .. py:method:: __rmul__(self, other)


   .. py:method:: __truediv__(self, other)


   .. py:method:: __rtruediv__(self, other)


   .. py:method:: __floordiv__(self, other)


   .. py:method:: __rfloordiv__(self, other)


   .. py:method:: __mod__(self, other)


   .. py:method:: __rmod__(self, other)


   .. py:method:: __lshift__(self, other)


   .. py:method:: __rlshift__(self, other)


   .. py:method:: __rshift__(self, other)


   .. py:method:: __rrshift__(self, other)


   .. py:method:: __and__(self, other)


   .. py:method:: __rand__(self, other)


   .. py:method:: __or__(self, other)


   .. py:method:: __ror__(self, other)


   .. py:method:: __xor__(self, other)


   .. py:method:: __rxor__(self, other)


   .. py:method:: __pow__(self, other)


   .. py:method:: __rpow__(self, other)


   .. py:method:: __lt__(self, other)

      Return self<value.


   .. py:method:: __gt__(self, other)

      Return self>value.


   .. py:method:: __le__(self, other)

      Return self<=value.


   .. py:method:: __ge__(self, other)

      Return self>=value.


   .. py:method:: __eq__(self, other)

      Return self==value.


   .. py:method:: __ne__(self, other)

      Return self!=value.


   .. py:method:: __neg__(self)


   .. py:method:: __invert__(self)


   .. py:method:: opeq(self, other, op)


   .. py:method:: __iadd__(self, other)


   .. py:method:: __isub__(self, other)


   .. py:method:: __imul__(self, other)


   .. py:method:: __itruediv__(self, other)


   .. py:method:: __ifloordiv__(self, other)


   .. py:method:: __ilshift__(self, other)


   .. py:method:: __irshift__(self, other)


   .. py:method:: __iand__(self, other)


   .. py:method:: __ior__(self, other)


   .. py:method:: __ixor__(self, other)


   .. py:method:: __ipow__(self, other)


   .. py:method:: __iter__(self)
      :abstractmethod:


   .. py:method:: __getitem__(self, key)


   .. py:method:: __setitem__(self, key, value)


   .. py:method:: fill(self, value: arkouda.dtypes.numeric_scalars) -> None

      Fill the array (in place) with a constant value.

      :param value:
      :type value: numeric_scalars

      :raises TypeError: Raised if value is not an int, int64, float, or float64


   .. py:method:: any(self) -> numpy.bool_

      Return True iff any element of the array evaluates to True.


   .. py:method:: all(self) -> numpy.bool_

      Return True iff all elements of the array evaluate to True.


   .. py:method:: is_registered(self) -> numpy.bool_

      Return True iff the object is contained in the registry

      :param None:

      :returns: Indicates if the object is contained in the registry
      :rtype: bool

      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: _list_component_names(self) -> List[str]

      Internal Function that returns a list of all component names

      :param None:

      :returns: List of all component names
      :rtype: List[str]


   .. py:method:: info(self) -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str


   .. py:method:: pretty_print_info(self) -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None


   .. py:method:: is_sorted(self) -> numpy.bool_

      Return True iff the array is monotonically non-decreasing.

      :param None:

      :returns: Indicates if the array is monotonically non-decreasing
      :rtype: bool

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: sum(self) -> arkouda.dtypes.numeric_and_bool_scalars

      Return the sum of all elements in the array.


   .. py:method:: prod(self) -> numpy.float64

      Return the product of all elements in the array. Return value is
      always a np.float64 or np.int64.


   .. py:method:: min(self) -> arkouda.dtypes.numpy_scalars

      Return the minimum value of the array.


   .. py:method:: max(self) -> arkouda.dtypes.numpy_scalars

      Return the maximum value of the array.


   .. py:method:: argmin(self) -> numpy.int64

      Return the index of the first occurrence of the array min value


   .. py:method:: argmax(self) -> numpy.int64

      Return the index of the first occurrence of the array max value.


   .. py:method:: mean(self) -> numpy.float64

      Return the mean of the array.


   .. py:method:: var(self, ddof: arkouda.dtypes.int_scalars = 0) -> numpy.float64

      Compute the variance. See ``arkouda.var`` for details.

      :param ddof: "Delta Degrees of Freedom" used in calculating var
      :type ddof: int_scalars

      :returns: The scalar variance of the array
      :rtype: np.float64

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises ValueError: Raised if the ddof >= pdarray size
      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: std(self, ddof: arkouda.dtypes.int_scalars = 0) -> numpy.float64

      Compute the standard deviation. See ``arkouda.std`` for details.

      :param ddof: "Delta Degrees of Freedom" used in calculating std
      :type ddof: int_scalars

      :returns: The scalar standard deviation of the array
      :rtype: np.float64

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: mink(self, k: arkouda.dtypes.int_scalars) -> pdarray

      Compute the minimum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: The maximum `k` values from pda
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray


   .. py:method:: maxk(self, k: arkouda.dtypes.int_scalars) -> pdarray

      Compute the maximum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: The maximum `k` values from pda
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray


   .. py:method:: argmink(self, k: arkouda.dtypes.int_scalars) -> pdarray

      Compute the minimum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: Indices corresponding to the maximum `k` values from pda
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray


   .. py:method:: argmaxk(self, k: arkouda.dtypes.int_scalars) -> pdarray

      Finds the indices corresponding to the maximum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: Indices corresponding to the  maximum `k` values, sorted
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray


   .. py:method:: popcount(self) -> pdarray

      Find the population (number of bits set) in each element. See `ak.popcount`.


   .. py:method:: parity(self) -> pdarray

      Find the parity (XOR of all bits) in each element. See `ak.parity`.


   .. py:method:: clz(self) -> pdarray

      Count the number of leading zeros in each element. See `ak.clz`.


   .. py:method:: ctz(self) -> pdarray

      Count the number of trailing zeros in each element. See `ak.ctz`.


   .. py:method:: rotl(self, other) -> pdarray

      Rotate bits left by <other>.


   .. py:method:: rotr(self, other) -> pdarray

      Rotate bits right by <other>.


   .. py:method:: astype(self, dtype) -> pdarray

      Cast values of pdarray to provided dtype

      :param dtype: Dtype to cast to
      :type dtype: np.dtype or str

      :returns: An arkouda pdarray with values converted to the specified data type
      :rtype: ak.pdarray

      .. rubric:: Notes

      This is essentially shorthand for ak.cast(x, '<dtype>') where x is a pdarray.


   .. py:method:: reshape(self, *shape, order='row_major')

      Gives a new shape to an array without changing its data.

      :param shape: The new shape should be compatible with the original shape.
      :type shape: int, tuple of ints, or pdarray
      :param order: Read the elements of the pdarray in this index order
                    By default, read the elements in row_major or C-like order where the last index changes the fastest
                    If 'column_major' or 'F', read the elements in column_major or Fortran-like order where the first index changes the fastest
      :type order: str {'row_major' | 'C' | 'column_major' | 'F'}

      :returns: An arrayview object with the data from the array but with the new shape
      :rtype: ArrayView


   .. py:method:: to_ndarray(self) -> numpy.ndarray

      Convert the array to a np.ndarray, transferring array data from the
      Arkouda server to client-side Python. Note: if the pdarray size exceeds
      client.maxTransferBytes, a RuntimeError is raised.

      :returns: A numpy ndarray with the same attributes and data as the pdarray
      :rtype: np.ndarray

      :raises RuntimeError: Raised if there is a server-side error thrown, if the pdarray size
          exceeds the built-in client.maxTransferBytes size limit, or if the bytes
          received does not match expected number of bytes

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_ndarray()
      array([0, 1, 2, 3, 4])

      >>> type(a.to_ndarray())
      numpy.ndarray


   .. py:method:: to_cuda(self)

      Convert the array to a Numba DeviceND array, transferring array data from the
      arkouda server to Python via ndarray. If the array exceeds a builtin size limit,
      a RuntimeError is raised.

      :returns: A Numba ndarray with the same attributes and data as the pdarray; on GPU
      :rtype: numba.DeviceNDArray

      :raises ImportError: Raised if CUDA is not available
      :raises ModuleNotFoundError: Raised if Numba is either not installed or not enabled
      :raises RuntimeError: Raised if there is a server-side error thrown in the course of retrieving
          the pdarray.

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_cuda()
      array([0, 1, 2, 3, 4])

      >>> type(a.to_cuda())
      numpy.devicendarray


   .. py:method:: save(self, prefix_path: str, dataset: str = 'array', mode: str = 'truncate', compressed: bool = False, file_format: str = 'HDF5') -> str

      Save the pdarray to HDF5 or Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param compressed: Defaults to False. When True, files will be written with Snappy compression
                         and RLE bit packing. This is currently only supported on Parquet files and will
                         not impact the generated files when writing HDF5 files.
      :type compressed: bool
      :param file_format: By default, saved files will be written to the HDF5 file format. If
                          'Parquet', the files will be written to the Parquet file format. This
                          is case insensitive.
      :type file_format: str {'HDF5', 'Parquet'}

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray
      :raises ValueError: Raised if there is an error in parsing the prefix path pointing to
          file write location or if the mode parameter is neither truncate
          nor append
      :raises TypeError: Raised if any one of the prefix_path, dataset, or mode parameters
          is not a string

      .. seealso:: :obj:`save_all`, :obj:`load`, :obj:`read`

      .. rubric:: Notes

      The prefix_path must be visible to the arkouda server and the user must
      have write permission.

      Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales``. If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.

      .. rubric:: Examples

      >>> a = ak.arange(0, 100, 1)
      >>> a.save('arkouda_range', dataset='array')
      >>> a.save('arkouda_range_parquet', dataset='array', file_format='Parquet')

      Array is saved in numLocales files with names like ``tmp/arkouda_range_LOCALE0``

      The array can be read back in as follows

      >>> b = ak.read('arkouda_range', dataset='array')
      >>> (a == b).all()
      True

      >>> c = ak.read_parquet('arkouda_range_parquet*')
      >>> (c == b).all()
      True


   .. py:method:: save_parquet(self, prefix_path: str, dataset: str = 'array', mode: str = 'truncate', compressed: bool = False) -> str

      Save the pdarray to Parquet. The result is a collection of Parquet files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in Parquet files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
      :type mode: str {'truncate', 'append'}
      :param compressed: By default, write without Snappy compression and RLE encoding.
      :type compressed: bool

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray
      :raises ValueError: Raised if there is an error in parsing the prefix path pointing to
          file write location or if the mode parameter is neither truncate
          nor append
      :raises TypeError: Raised if any one of the prefix_path, dataset, or mode parameters
          is not a string

      .. seealso:: :obj:`save`, :obj:`save_all`, :obj:`load`, :obj:`read`

      .. rubric:: Notes

      The prefix_path must be visible to the arkouda server and the user must
      have write permission.

      Output files have names of the form ``<prefix_path>_LOCALE<i>.parquet``, where ``<i>``
      ranges from 0 to ``numLocales``. If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.

      .. rubric:: Examples

      >>> a = ak.arange(0, 100, 1)
      >>> a.save_parquet('arkouda_range')

      Array is saved in numLocales files with names like ``arkouda_range_LOCALE0000.parquet``

      The array can be read back in as follows

      >>> b = ak.read('arkouda_range')
      >>> (a == b).all()
      True


   .. py:method:: save_hdf(self, prefix_path: str, dataset: str = 'array', mode: str = 'truncate') -> str

      Save the pdarray to HDF5. The result is a collection of HDF5 files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in HDF5 files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
      :type mode: str {'truncate', 'append'}
      :param compressed: By default, write without Snappy compression and RLE encoding.
      :type compressed: bool

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray
      :raises ValueError: Raised if there is an error in parsing the prefix path pointing to
          file write location or if the mode parameter is neither truncate
          nor append
      :raises TypeError: Raised if any one of the prefix_path, dataset, or mode parameters
          is not a string

      .. seealso:: :obj:`save`, :obj:`save_all`, :obj:`load`, :obj:`read`

      .. rubric:: Notes

      The prefix_path must be visible to the arkouda server and the user must
      have write permission.

      Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales``. If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.

      .. rubric:: Examples

      >>> a = ak.arange(0, 100, 1)
      >>> a.save_hdf('arkouda_range')

      Array is saved in numLocales files with names like ``arkouda_range_LOCALE0000``

      The array can be read back in as follows

      >>> b = ak.read('arkouda_range')
      >>> (a == b).all()
      True


   .. py:method:: register(self, user_defined_name: str) -> pdarray

      Register this pdarray with a user defined name in the arkouda server
      so it can be attached to later using pdarray.attach()
      This is an in-place operation, registering a pdarray more than once will
      update the name in the registry and remove the previously registered name.
      A name can only be registered to one pdarray at a time.

      :param user_defined_name: user defined name array is to be registered under
      :type user_defined_name: str

      :returns: The same pdarray which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support a fluid programming style.
                Please note you cannot register two different pdarrays with the same name.
      :rtype: pdarray

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the pdarray with the user_defined_name
          If the user is attempting to register more than one pdarray with the same name, the former should be
          unregistered first to free up the registration name.

      .. seealso:: :obj:`attach`, :obj:`unregister`, :obj:`is_registered`, :obj:`list_registry`, :obj:`unregister_pdarray_by_name`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion
      until they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()


   .. py:method:: unregister(self) -> None

      Unregister a pdarray in the arkouda server which was previously
      registered using register() and/or attahced to using attach()


      :rtype: None

      :raises RuntimeError: Raised if the server could not find the internal name/symbol to remove

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion until
      they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()


   .. py:method:: attach(user_defined_name: str) -> pdarray
      :staticmethod:

      class method to return a pdarray attached to the registered name in the arkouda
      server which was registered using register()

      :param user_defined_name: user defined name which array was registered under
      :type user_defined_name: str

      :returns: pdarray which is bound to corresponding server side component that was registered with user_defined_name
      :rtype: pdarray

      :raises TypeError: Raised if user_defined_name is not a str

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion
      until they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()


   .. py:method:: _get_grouping_keys(self) -> List[pdarray]

      Private method for generating grouping keys used by GroupBy.

      API: this method must be defined by all groupable arrays, and it
      must return a list of arrays that can be (co)argsorted.



.. py:function:: isSupportedInt(num)


.. py:data:: intTypes
   

   

.. py:data:: bitType
   

   

.. py:data:: akint64
   

   

.. py:class:: Strings(strings_pdarray: arkouda.pdarrayclass.pdarray, bytes_size: arkouda.dtypes.int_scalars)

   Represents an array of strings whose data resides on the
   arkouda server. The user should not call this class directly;
   rather its instances are created by other arkouda functions.

   .. attribute:: entry

      Encapsulation of a Segmented Strings array contained on
      the arkouda server.  This is a composite of
       - offsets array: starting indices for each string
       - bytes array: raw bytes of all strings joined by nulls

      :type: pdarray

   .. attribute:: size

      The number of strings in the array

      :type: int_scalars

   .. attribute:: nbytes

      The total number of bytes in all strings

      :type: int_scalars

   .. attribute:: ndim

      The rank of the array (currently only rank 1 arrays supported)

      :type: int_scalars

   .. attribute:: shape

      The sizes of each dimension of the array

      :type: tuple

   .. attribute:: dtype

      The dtype is ak.str

      :type: dtype

   .. attribute:: logger

      Used for all logging operations

      :type: ArkoudaLogger

   .. rubric:: Notes

   Strings is composed of two pdarrays: (1) offsets, which contains the
   starting indices for each string and (2) bytes, which contains the
   raw bytes of all strings, delimited by nulls.

   .. py:attribute:: BinOps
      

      

   .. py:attribute:: objtype
      :annotation: = str

      

   .. py:method:: from_return_msg(rep_msg: str) -> Strings
      :staticmethod:

      Factory method for creating a Strings object from an Arkouda server
      response message

      :param rep_msg: Server response message currently of form
                      `created name type size ndim shape itemsize+created bytes.size 1234`
      :type rep_msg: str

      :returns: object representing a segmented strings array on the server
      :rtype: Strings

      :raises RuntimeError: Raised if there's an error converting a server-returned str-descriptor

      .. rubric:: Notes

      We really don't have an itemsize because these are variable length strings.
      In the future we could probably use this position to store the total bytes.


   .. py:method:: from_parts(offset_attrib: Union[arkouda.pdarrayclass.pdarray, str], bytes_attrib: Union[arkouda.pdarrayclass.pdarray, str]) -> Strings
      :staticmethod:

      Factory method for creating a Strings object from an Arkouda server
      response where the arrays are separate components.

      :param offset_attrib: the array containing the offsets
      :type offset_attrib: Union[pdarray, str]
      :param bytes_attrib: the array containing the string values
      :type bytes_attrib: Union[pdarray, str]

      :returns: object representing a segmented strings array on the server
      :rtype: Strings

      :raises RuntimeError: Raised if there's an error converting a server-returned str-descriptor

      .. rubric:: Notes

      This factory method is used when we construct the parts of a Strings
      object on the client side and transfer the offsets & bytes separately
      to the server.  This results in two entries in the symbol table and we
      need to instruct the server to assemble the into a composite entity.


   .. py:method:: __iter__(self)
      :abstractmethod:


   .. py:method:: __len__(self) -> int


   .. py:method:: __str__(self) -> str

      Return str(self).


   .. py:method:: __repr__(self) -> str

      Return repr(self).


   .. py:method:: _binop(self, other: Union[Strings, arkouda.dtypes.str_scalars], op: str) -> arkouda.pdarrayclass.pdarray

      Executes the requested binop on this Strings instance and the
      parameter Strings object and returns the results within
      a pdarray object.

      :param other: the other object is a Strings object
      :type other: Strings, str_scalars
      :param op: name of the binary operation to be performed
      :type op: str

      :returns: encapsulating the results of the requested binop
      :rtype: pdarray

      :raises ValueError: Raised if (1) the op is not in the self.BinOps set, or (2) if the
          sizes of this and the other instance don't match, or (3) the other
          object is not a Strings object
      :raises RuntimeError: Raised if a server-side error is thrown while executing the
          binary operation


   .. py:method:: __eq__(self, other) -> bool

      Return self==value.


   .. py:method:: __ne__(self, other) -> bool

      Return self!=value.


   .. py:method:: __getitem__(self, key)


   .. py:method:: get_lengths(self) -> arkouda.pdarrayclass.pdarray

      Return the length of each string in the array.

      :returns: The length of each string
      :rtype: pdarray, int

      :raises RuntimeError: Raised if there is a server-side error thrown


   .. py:method:: to_lower(self) -> Strings

      Returns a new Strings with all uppercase characters from the original replaced with their lowercase equivalent

      :returns: Strings with all uppercase characters from the original replaced with their lowercase equivalent
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.to_upper`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS {i}' for i in range(5)])
      >>> strings
      array(['StrINgS 0', 'StrINgS 1', 'StrINgS 2', 'StrINgS 3', 'StrINgS 4'])
      >>> strings.to_lower()
      array(['strings 0', 'strings 1', 'strings 2', 'strings 3', 'strings 4'])


   .. py:method:: to_upper(self) -> Strings

      Returns a new Strings with all lowercase characters from the original replaced with their uppercase equivalent

      :returns: Strings with all lowercase characters from the original replaced with their uppercase equivalent
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.to_lower`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS {i}' for i in range(5)])
      >>> strings
      array(['StrINgS 0', 'StrINgS 1', 'StrINgS 2', 'StrINgS 3', 'StrINgS 4'])
      >>> strings.to_upper()
      array(['STRINGS 0', 'STRINGS 1', 'STRINGS 2', 'STRINGS 3', 'STRINGS 4'])


   .. py:method:: is_lower(self) -> arkouda.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the Strings is entirely lowercase

      :returns: True for elements that are entirely lowercase, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.is_upper`

      .. rubric:: Examples

      >>> lower = ak.array([f'strings {i}' for i in range(3)])
      >>> upper = ak.array([f'STRINGS {i}' for i in range(3)])
      >>> strings = ak.concatenate([lower, upper])
      >>> strings
      array(['strings 0', 'strings 1', 'strings 2', 'STRINGS 0', 'STRINGS 1', 'STRINGS 2'])
      >>> strings.is_lower()
      array([True True True False False False])


   .. py:method:: is_upper(self) -> arkouda.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the Strings is entirely uppercase

      :returns: True for elements that are entirely uppercase, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.is_lower`

      .. rubric:: Examples

      >>> lower = ak.array([f'strings {i}' for i in range(3)])
      >>> upper = ak.array([f'STRINGS {i}' for i in range(3)])
      >>> strings = ak.concatenate([lower, upper])
      >>> strings
      array(['strings 0', 'strings 1', 'strings 2', 'STRINGS 0', 'STRINGS 1', 'STRINGS 2'])
      >>> strings.is_upper()
      array([False False False True True True])


   .. py:method:: cached_regex_patterns(self) -> List

      Returns the regex patterns for which Match objects have been cached


   .. py:method:: purge_cached_regex_patterns(self) -> None

      purges cached regex patterns


   .. py:method:: _get_matcher(self, pattern: Union[bytes, arkouda.dtypes.str_scalars], create: bool = True)

      internal function to fetch cached Matcher objects


   .. py:method:: find_locations(self, pattern: Union[bytes, arkouda.dtypes.str_scalars]) -> Tuple[arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray]

      Finds pattern matches and returns pdarrays containing the number, start postitions, and lengths of matches

      :param pattern: The regex pattern used to find matches
      :type pattern: str_scalars

      :returns: * *pdarray, int64* -- For each original string, the number of pattern matches
                * *pdarray, int64* -- The start positons of pattern matches
                * *pdarray, int64* -- The lengths of pattern matches

      :raises TypeError: Raised if the pattern parameter is not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.findall`, :obj:`Strings.match`

      .. rubric:: Examples

      >>> strings = ak.array(['{} string {}'.format(i, i) for i in range(1, 6)])
      >>> num_matches, starts, lens = strings.find_locations('\d')
      >>> num_matches
      array([2, 2, 2, 2, 2])
      >>> starts
      array([0, 9, 0, 9, 0, 9, 0, 9, 0, 9])
      >>> lens
      array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))


   .. py:method:: search(self, pattern: Union[bytes, arkouda.dtypes.str_scalars]) -> arkouda.match.Match

      Returns a match object with the first location in each element where pattern produces a match.
      Elements match if any part of the string matches the regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: str

      :returns: Match object where elements match if any part of the string matches the regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.search('_+')
      <ak.Match object: matched=True, span=(1, 2); matched=True, span=(0, 4); matched=False; matched=True, span=(0, 2); matched=False>


   .. py:method:: match(self, pattern: Union[bytes, arkouda.dtypes.str_scalars]) -> arkouda.match.Match

      Returns a match object where elements match only if the beginning of the string matches the regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: str

      :returns: Match object where elements match only if the beginning of the string matches the regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.match('_+')
      <ak.Match object: matched=False; matched=True, span=(0, 4); matched=False; matched=True, span=(0, 2); matched=False>


   .. py:method:: fullmatch(self, pattern: Union[bytes, arkouda.dtypes.str_scalars]) -> arkouda.match.Match

      Returns a match object where elements match only if the whole string matches the regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: str

      :returns: Match object where elements match only if the whole string matches the regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.fullmatch('_+')
      <ak.Match object: matched=False; matched=True, span=(0, 4); matched=False; matched=False; matched=False>


   .. py:method:: split(self, pattern: Union[bytes, arkouda.dtypes.str_scalars], maxsplit: int = 0, return_segments: bool = False) -> Union[Strings, Tuple]

      Returns a new Strings split by the occurrences of pattern. If maxsplit is nonzero, at most maxsplit splits occur

      :param pattern: Regex used to split strings into substrings
      :type pattern: str
      :param maxsplit: The max number of pattern match occurences in each element to split.
                       The default maxsplit=0 splits on all occurences
      :type maxsplit: int
      :param return_segments: If True, return mapping of original strings to first substring
                              in return array.
      :type return_segments: bool

      :returns: * *Strings* -- Substrings with pattern matches removed
                * *pdarray, int64 (optional)* -- For each original string, the index of first corresponding substring
                  in the return array

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.split('_+', maxsplit=2, return_segments=True)
      (array(['1', '2', '', '', '', '3', '', '4', '5____6___7', '']), array([0 3 5 6 9]))


   .. py:method:: findall(self, pattern: Union[bytes, arkouda.dtypes.str_scalars], return_match_origins: bool = False) -> Union[Strings, Tuple]

      Return a new Strings containg all non-overlapping matches of pattern

      :param pattern: Regex used to find matches
      :type pattern: str_scalars
      :param return_match_origins: If True, return a pdarray containing the index of the original string each pattern match is from
      :type return_match_origins: bool

      :returns: * *Strings* -- Strings object containing only pattern matches
                * *pdarray, int64 (optional)* -- The index of the original string each pattern match is from

      :raises TypeError: Raised if the pattern parameter is not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.find_locations`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.findall('_+', return_match_origins=True)
      (array(['_', '___', '____', '__', '___', '____', '___']), array([0 0 1 3 3 3 3]))


   .. py:method:: sub(self, pattern: Union[bytes, arkouda.dtypes.str_scalars], repl: Union[bytes, arkouda.dtypes.str_scalars], count: int = 0) -> Strings

      Return new Strings obtained by replacing non-overlapping occurrences of pattern with the replacement repl.
      If count is nonzero, at most count substitutions occur

      :param pattern: The regex to substitue
      :type pattern: str_scalars
      :param repl: The substring to replace pattern matches with
      :type repl: str_scalars
      :param count: The max number of pattern match occurences in each element to replace.
                    The default count=0 replaces all occurences of pattern with repl
      :type count: int

      :returns: Strings with pattern matches replaced
      :rtype: Strings

      :raises TypeError: Raised if pattern or repl are not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.subn`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.sub(pattern='_+', repl='-', count=2)
      array(['1-2-', '-', '3', '-4-5____6___7', ''])


   .. py:method:: subn(self, pattern: Union[bytes, arkouda.dtypes.str_scalars], repl: Union[bytes, arkouda.dtypes.str_scalars], count: int = 0) -> Tuple

      Perform the same operation as sub(), but return a tuple (new_Strings, number_of_substitions)

      :param pattern: The regex to substitue
      :type pattern: str_scalars
      :param repl: The substring to replace pattern matches with
      :type repl: str_scalars
      :param count: The max number of pattern match occurences in each element to replace.
                    The default count=0 replaces all occurences of pattern with repl
      :type count: int

      :returns: * *Strings* -- Strings with pattern matches replaced
                * *pdarray, int64* -- The number of substitutions made for each element of Strings

      :raises TypeError: Raised if pattern or repl are not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.sub`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.subn(pattern='_+', repl='-', count=2)
      (array(['1-2-', '-', '3', '-4-5____6___7', '']), array([2 1 0 2 0]))


   .. py:method:: contains(self, substr: Union[bytes, arkouda.dtypes.str_scalars], regex: bool = False) -> arkouda.pdarrayclass.pdarray

      Check whether each element contains the given substring.

      :param substr: The substring in the form of string or byte array to search for
      :type substr: str_scalars
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2 (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: True for elements that contain substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not bytes or str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.startswith`, :obj:`Strings.endswith`

      .. rubric:: Examples

      >>> strings = ak.array(['{} string {}'.format(i, i) for i in range(1, 6)])
      >>> strings
      array(['1 string 1', '2 string 2', '3 string 3', '4 string 4', '5 string 5'])
      >>> strings.contains('string')
      array([True, True, True, True, True])
      >>> strings.contains('string \d', regex=True)
      array([True, True, True, True, True])


   .. py:method:: startswith(self, substr: Union[bytes, arkouda.dtypes.str_scalars], regex: bool = False) -> arkouda.pdarrayclass.pdarray

      Check whether each element starts with the given substring.

      :param substr: The prefix to search for
      :type substr: Union[bytes, str_scalars]
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2 (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: True for elements that start with substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not a bytes ior str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.contains`, :obj:`Strings.endswith`

      .. rubric:: Examples

      >>> strings_end = ak.array(['string {}'.format(i) for i in range(1, 6)])
      >>> strings_end
      array(['string 1', 'string 2', 'string 3', 'string 4', 'string 5'])
      >>> strings_end.startswith('string')
      array([True, True, True, True, True])
      >>> strings_start = ak.array(['{} string'.format(i) for i in range(1,6)])
      >>> strings_start
      array(['1 string', '2 string', '3 string', '4 string', '5 string'])
      >>> strings_start.startswith('\d str', regex = True)
      array([True, True, True, True, True])


   .. py:method:: endswith(self, substr: Union[bytes, arkouda.dtypes.str_scalars], regex: bool = False) -> arkouda.pdarrayclass.pdarray

      Check whether each element ends with the given substring.

      :param substr: The suffix to search for
      :type substr: Union[bytes, str_scalars]
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2 (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: True for elements that end with substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not bytes or str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.contains`, :obj:`Strings.startswith`

      .. rubric:: Examples

      >>> strings_start = ak.array(['{} string'.format(i) for i in range(1,6)])
      >>> strings_start
      array(['1 string', '2 string', '3 string', '4 string', '5 string'])
      >>> strings_start.endswith('ing')
      array([True, True, True, True, True])
      >>> strings_end = ak.array(['string {}'.format(i) for i in range(1, 6)])
      >>> strings_end
      array(['string 1', 'string 2', 'string 3', 'string 4', 'string 5'])
      >>> strings_end.endswith('ing \d', regex = True)
      array([True, True, True, True, True])


   .. py:method:: flatten(self, delimiter: str, return_segments: bool = False, regex: bool = False) -> Union[Strings, Tuple]

      Unpack delimiter-joined substrings into a flat array.

      :param delimiter: Characters used to split strings into substrings
      :type delimiter: str
      :param return_segments: If True, also return mapping of original strings to first substring
                              in return array.
      :type return_segments: bool
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2 (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: * *Strings* -- Flattened substrings with delimiters removed
                * *pdarray, int64 (optional)* -- For each original string, the index of first corresponding substring
                  in the return array

      .. seealso:: :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> orig = ak.array(['one|two', 'three|four|five', 'six'])
      >>> orig.flatten('|')
      array(['one', 'two', 'three', 'four', 'five', 'six'])
      >>> flat, map = orig.flatten('|', return_segments=True)
      >>> map
      array([0, 2, 5])
      >>> under = ak.array(['one_two', 'three_____four____five', 'six'])
      >>> under_flat, under_map = under.flatten('_+', return_segments=True, regex=True)
      >>> under_flat
      array(['one', 'two', 'three', 'four', 'five', 'six'])
      >>> under_map
      array([0, 2, 5])


   .. py:method:: peel(self, delimiter: Union[bytes, arkouda.dtypes.str_scalars], times: arkouda.dtypes.int_scalars = 1, includeDelimiter: bool = False, keepPartial: bool = False, fromRight: bool = False, regex: bool = False) -> Tuple

      Peel off one or more delimited fields from each string (similar
      to string.partition), returning two new arrays of strings.
      *Warning*: This function is experimental and not guaranteed to work.

      :param delimiter: The separator where the split will occur
      :type delimiter: Union[bytes, str_scalars]
      :param times: The number of times the delimiter is sought, i.e. skip over
                    the first (times-1) delimiters
      :type times: Union[int, np.int64]
      :param includeDelimiter: If true, append the delimiter to the end of the first return
                               array. By default, it is prepended to the beginning of the
                               second return array.
      :type includeDelimiter: bool
      :param keepPartial: If true, a string that does not contain <times> instances of
                          the delimiter will be returned in the first array. By default,
                          such strings are returned in the second array.
      :type keepPartial: bool
      :param fromRight: If true, peel from the right instead of the left (see also rpeel)
      :type fromRight: bool
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2 (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns:

                left: Strings
                    The field(s) peeled from the end of each string (unless
                    fromRight is true)
                right: Strings
                    The remainder of each string after peeling (unless fromRight
                    is true)
      :rtype: Tuple[Strings, Strings]

      :raises TypeError: Raised if the delimiter parameter is not byte or str_scalars, if
          times is not int64, or if includeDelimiter, keepPartial, or
          fromRight is not bool
      :raises ValueError: Raised if times is < 1 or if delimiter is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`rpeel`, :obj:`stick`, :obj:`lstick`

      .. rubric:: Examples

      >>> s = ak.array(['a.b', 'c.d', 'e.f.g'])
      >>> s.peel('.')
      (array(['a', 'c', 'e']), array(['b', 'd', 'f.g']))
      >>> s.peel('.', includeDelimiter=True)
      (array(['a.', 'c.', 'e.']), array(['b', 'd', 'f.g']))
      >>> s.peel('.', times=2)
      (array(['', '', 'e.f']), array(['a.b', 'c.d', 'g']))
      >>> s.peel('.', times=2, keepPartial=True)
      (array(['a.b', 'c.d', 'e.f']), array(['', '', 'g']))


   .. py:method:: rpeel(self, delimiter: Union[bytes, arkouda.dtypes.str_scalars], times: arkouda.dtypes.int_scalars = 1, includeDelimiter: bool = False, keepPartial: bool = False, regex: bool = False)

      Peel off one or more delimited fields from the end of each string
      (similar to string.rpartition), returning two new arrays of strings.
      *Warning*: This function is experimental and not guaranteed to work.

      :param delimiter: The separator where the split will occur
      :type delimiter: Union[bytes, str_scalars]
      :param times: The number of times the delimiter is sought, i.e. skip over
                    the last (times-1) delimiters
      :type times: Union[int, np.int64]
      :param includeDelimiter: If true, prepend the delimiter to the start of the first return
                               array. By default, it is appended to the end of the
                               second return array.
      :type includeDelimiter: bool
      :param keepPartial: If true, a string that does not contain <times> instances of
                          the delimiter will be returned in the second array. By default,
                          such strings are returned in the first array.
      :type keepPartial: bool
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2 (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns:

                left: Strings
                    The remainder of the string after peeling
                right: Strings
                    The field(s) that were peeled from the right of each string
      :rtype: Tuple[Strings, Strings]

      :raises TypeError: Raised if the delimiter parameter is not bytes or str_scalars or
          if times is not int64
      :raises ValueError: Raised if times is < 1 or if delimiter is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`peel`, :obj:`stick`, :obj:`lstick`

      .. rubric:: Examples

      >>> s = ak.array(['a.b', 'c.d', 'e.f.g'])
      >>> s.rpeel('.')
      (array(['a', 'c', 'e.f']), array(['b', 'd', 'g']))
      # Compared against peel
      >>> s.peel('.')
      (array(['a', 'c', 'e']), array(['b', 'd', 'f.g']))


   .. py:method:: stick(self, other: Strings, delimiter: Union[bytes, arkouda.dtypes.str_scalars] = '', toLeft: bool = False) -> Strings

      Join the strings from another array onto one end of the strings
      of this array, optionally inserting a delimiter.
      *Warning*: This function is experimental and not guaranteed to work.

      :param other: The strings to join onto self's strings
      :type other: Strings
      :param delimiter: String inserted between self and other
      :type delimiter: str
      :param toLeft: If true, join other strings to the left of self. By default,
                     other is joined to the right of self.
      :type toLeft: bool

      :returns: The array of joined strings
      :rtype: Strings

      :raises TypeError: Raised if the delimiter parameter is not bytes or str_scalars
          or if the other parameter is not a Strings instance
      :raises ValueError: Raised if times is < 1
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`lstick`, :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> s = ak.array(['a', 'c', 'e'])
      >>> t = ak.array(['b', 'd', 'f'])
      >>> s.stick(t, delimiter='.')
      array(['a.b', 'c.d', 'e.f'])


   .. py:method:: __add__(self, other: Strings) -> Strings


   .. py:method:: lstick(self, other: Strings, delimiter: Union[bytes, arkouda.dtypes.str_scalars] = '') -> Strings

      Join the strings from another array onto the left of the strings
      of this array, optionally inserting a delimiter.
      *Warning*: This function is experimental and not guaranteed to work.

      :param other: The strings to join onto self's strings
      :type other: Strings
      :param delimiter: String inserted between self and other
      :type delimiter: Union[bytes,str_scalars]

      :returns: The array of joined strings, as other + self
      :rtype: Strings

      :raises TypeError: Raised if the delimiter parameter is neither bytes nor a str
          or if the other parameter is not a Strings instance
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`stick`, :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> s = ak.array(['a', 'c', 'e'])
      >>> t = ak.array(['b', 'd', 'f'])
      >>> s.lstick(t, delimiter='.')
      array(['b.a', 'd.c', 'f.e'])


   .. py:method:: __radd__(self, other: Strings) -> Strings


   .. py:method:: hash(self) -> Tuple[arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray]

      Compute a 128-bit hash of each string.

      :returns: A tuple of two int64 pdarrays. The ith hash value is the concatenation
                of the ith values from each array.
      :rtype: Tuple[pdarray,pdarray]

      .. rubric:: Notes

      The implementation uses SipHash128, a fast and balanced hash function (used
      by Python for dictionaries and sets). For realistic numbers of strings (up
      to about 10**15), the probability of a collision between two 128-bit hash
      values is negligible.


   .. py:method:: group(self) -> arkouda.pdarrayclass.pdarray

      Return the permutation that groups the array, placing equivalent
      strings together. All instances of the same string are guaranteed to lie
      in one contiguous block of the permuted array, but the blocks are not
      necessarily ordered.

      :returns: The permutation that groups the array by value
      :rtype: pdarray

      .. seealso:: :obj:`GroupBy`, :obj:`unique`

      .. rubric:: Notes

      If the arkouda server is compiled with "-sSegmentedArray.useHash=true",
      then arkouda uses 128-bit hash values to group strings, rather than sorting
      the strings directly. This method is fast, but the resulting permutation
      merely groups equivalent strings and does not sort them. If the "useHash"
      parameter is false, then a full sort is performed.

      :raises RuntimeError: Raised if there is a server-side error in executing group request or
          creating the pdarray encapsulating the return message


   .. py:method:: _get_grouping_keys(self) -> List[arkouda.pdarrayclass.pdarray]

      Private method for generating grouping keys used by GroupBy.

      API: this method must be defined by all groupable arrays, and it
      must return a list of arrays that can be (co)argsorted.


   .. py:method:: to_ndarray(self) -> numpy.ndarray

      Convert the array to a np.ndarray, transferring array data from the
      arkouda server to Python. If the array exceeds a built-in size limit,
      a RuntimeError is raised.

      :returns: A numpy ndarray with the same strings as this array
      :rtype: np.ndarray

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``arkouda.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting ak.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`

      .. rubric:: Examples

      >>> a = ak.array(["hello", "my", "world"])
      >>> a.to_ndarray()
      array(['hello', 'my', 'world'], dtype='<U5')
      >>> type(a.to_ndarray())
      numpy.ndarray


   .. py:method:: _comp_to_ndarray(self, comp: str) -> numpy.ndarray

      This is an internal helper function to perform the to_ndarray for one
      of the string components.

      :param comp: The strings component to request
      :type comp: str

      :returns: A numpy ndarray with the same attributes and data as the pdarray
      :rtype: np.ndarray

      :raises RuntimeError: Raised if there is a server-side error thrown, if the pdarray size
          exceeds the built-in client.maxTransferBytes size limit, or if the bytes
          received does not match expected number of bytes

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.


   .. py:method:: astype(self, dtype) -> arkouda.pdarrayclass.pdarray

      Cast values of Strings object to provided dtype

      :param dtype: Dtype to cast to
      :type dtype: np.dtype or str

      :returns: An arkouda pdarray with values converted to the specified data type
      :rtype: ak.pdarray

      .. rubric:: Notes

      This is essentially shorthand for ak.cast(x, '<dtype>') where x is a pdarray.


   .. py:method:: save(self, prefix_path: str, dataset: str = 'strings_array', mode: str = 'truncate', save_offsets: bool = True, compressed: bool = False, file_format: str = 'HDF5') -> str

      Save the Strings object to HDF5 or Parquet. The result is a collection of
      files, one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the Strings array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: The name of the Strings dataset to be written, defaults to strings_array
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Strings dataset within existing files.
      :type mode: str {'truncate' | 'append'}
      :param save_offsets: Defaults to True which will instruct the server to save the offsets array to HDF5
                           If False the offsets array will not be save and will be derived from the string values
                           upon load/read. This is not supported for Parquet files.
      :type save_offsets: bool
      :param compressed: Defaults to False. When True, files will be written with Snappy compression
                         and RLE bit packing. This is currently only supported on Parquet files and will
                         not impact the generated files when writing HDF5 files.
      :type compressed: bool
      :param file_format: By default, saved files will be written to the HDF5 file format. If
                          'Parquet', the files will be written to the Parquet file format. This
                          is case insensitive.
      :type file_format: str

      :rtype: String message indicating result of save operation

      :raises ValueError: Raised if the lengths of columns and values differ, or the mode is
          neither 'truncate' nor 'append'
      :raises TypeError: Raised if prefix_path, dataset, or mode is not a str

      .. seealso:: :obj:`pdarrayIO.save`

      .. rubric:: Notes

      Important implementation notes: (1) Strings state is saved as two datasets
      within an hdf5 group: one for the string characters and one for the
      segments corresponding to the start of each string, (2) the hdf5 group is named
      via the dataset parameter.


   .. py:method:: save_parquet(self, prefix_path: str, dataset: str = 'strings_array', mode: str = 'truncate', compressed: bool = False) -> str

      Save the Strings object to Parquet. The result is a collection of Parquet files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the Strings array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: The name of the Strings dataset to be written, defaults to strings_array
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Strings dataset within existing files.
      :type mode: str {'truncate' | 'append'}
      :param compressed: Defaults to False. When True, files will be written with Snappy compression
                         and RLE bit packing.
      :type compressed: bool

      :rtype: String message indicating result of save operation

      :raises ValueError: Raised if the lengths of columns and values differ, or the mode is
          neither 'truncate' nor 'append'
      :raises TypeError: Raised if prefix_path, dataset, or mode is not a str

      .. seealso:: :obj:`strings.save`, :obj:`pdarray.save_parquet`


   .. py:method:: save_hdf(self, prefix_path: str, dataset: str = 'strings_array', mode: str = 'truncate', save_offsets: bool = True) -> str

      Save the Strings object to HDF5. The result is a collection of HDF5 files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the Strings array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: The name of the Strings dataset to be written, defaults to strings_array
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Strings dataset within existing files.
      :type mode: str {'truncate' | 'append'}
      :param save_offsets: Defaults to True which will instruct the server to save the offsets array to HDF5
                           If False the offsets array will not be save and will be derived from the string values
                           upon load/read.
      :type save_offsets: bool

      :rtype: String message indicating result of save operation

      :raises ValueError: Raised if the lengths of columns and values differ, or the mode is
          neither 'truncate' nor 'append'
      :raises TypeError: Raised if prefix_path, dataset, or mode is not a str

      .. seealso:: :obj:`strings.save`, :obj:`pdarray.save`


   .. py:method:: is_registered(self) -> numpy.bool_

      Return True iff the object is contained in the registry

      :param None:

      :returns: Indicates if the object is contained in the registry
      :rtype: bool

      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: _list_component_names(self) -> List[str]

      Internal Function that returns a list of all component names

      :param None:

      :returns: List of all component names
      :rtype: List[str]


   .. py:method:: info(self) -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str


   .. py:method:: pretty_print_info(self) -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None


   .. py:method:: register(self, user_defined_name: str) -> Strings

      Register this Strings object with a user defined name in the arkouda server
      so it can be attached to later using Strings.attach()
      This is an in-place operation, registering a Strings object more than once will
      update the name in the registry and remove the previously registered name.
      A name can only be registered to one object at a time.

      :param user_defined_name: user defined name which the Strings object is to be registered under
      :type user_defined_name: str

      :returns: The same Strings object which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support a fluid programming style.
                Please note you cannot register two different objects with the same name.
      :rtype: Strings

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the Strings object with the user_defined_name
          If the user is attempting to register more than one object with the same name, the former should be
          unregistered first to free up the registration name.

      .. seealso:: :obj:`attach`, :obj:`unregister`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion
      until they are unregistered.


   .. py:method:: unregister(self) -> None

      Unregister a Strings object in the arkouda server which was previously
      registered using register() and/or attached to using attach()


      :rtype: None

      :raises RuntimeError: Raised if the server could not find the internal name/symbol to remove

      .. seealso:: :obj:`register`, :obj:`attach`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion until
      they are unregistered.


   .. py:method:: attach(user_defined_name: str) -> Strings
      :staticmethod:

      class method to return a Strings object attached to the registered name in the arkouda
      server which was registered using register()

      :param user_defined_name: user defined name which the Strings object was registered under
      :type user_defined_name: str

      :returns: the Strings object registered with user_defined_name in the arkouda server
      :rtype: Strings object

      :raises TypeError: Raised if user_defined_name is not a str

      .. seealso:: :obj:`register`, :obj:`unregister`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion
      until they are unregistered.


   .. py:method:: unregister_strings_by_name(user_defined_name: str) -> None
      :staticmethod:

      Unregister a Strings object in the arkouda server previously registered via register()

      :param user_defined_name: The registered name of the Strings object
      :type user_defined_name: str

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`attach`, :obj:`is_registered`



.. py:function:: zeros(size: Union[arkouda.dtypes.int_scalars, str], dtype: Union[numpy.dtype, type, str] = float64) -> arkouda.pdarrayclass.pdarray

   Create a pdarray filled with zeros.

   :param size: Size of the array (only rank-1 arrays supported)
   :type size: int_scalars
   :param dtype: Type of resulting array, default float64
   :type dtype: all_scalars

   :returns: Zeros of the requested size and dtype
   :rtype: pdarray

   :raises TypeError: Raised if the supplied dtype is not supported or if the size
       parameter is neither an int nor a str that is parseable to an int.

   .. seealso:: :obj:`ones`, :obj:`zeros_like`

   .. rubric:: Examples

   >>> ak.zeros(5, dtype=ak.int64)
   array([0, 0, 0, 0, 0])

   >>> ak.zeros(5, dtype=ak.float64)
   array([0, 0, 0, 0, 0])

   >>> ak.zeros(5, dtype=ak.bool)
   array([False, False, False, False, False])


.. py:function:: arange(*args, **kwargs) -> arkouda.pdarrayclass.pdarray

   arange([start,] stop[, stride,] dtype=int64)

   Create a pdarray of consecutive integers within the interval [start, stop).
   If only one arg is given then arg is the stop parameter. If two args are
   given, then the first arg is start and second is stop. If three args are
   given, then the first arg is start, second is stop, third is stride.

   The return value is cast to type dtype

   :param start: Starting value (inclusive)
   :type start: int_scalars, optional
   :param stop: Stopping value (exclusive)
   :type stop: int_scalars
   :param stride: The difference between consecutive elements, the default stride is 1,
                  if stride is specified then start must also be specified.
   :type stride: int_scalars, optional
   :param dtype: The target dtype to cast values to
   :type dtype: np.dtype, type, or str

   :returns: Integers from start (inclusive) to stop (exclusive) by stride
   :rtype: pdarray, dtype

   :raises TypeError: Raised if start, stop, or stride is not an int object
   :raises ZeroDivisionError: Raised if stride == 0

   .. seealso:: :obj:`linspace`, :obj:`zeros`, :obj:`ones`, :obj:`randint`

   .. rubric:: Notes

   Negative strides result in decreasing values. Currently, only int64
   pdarrays can be created with this method. For float64 arrays, use
   the linspace method.

   .. rubric:: Examples

   >>> ak.arange(0, 5, 1)
   array([0, 1, 2, 3, 4])

   >>> ak.arange(5, 0, -1)
   array([5, 4, 3, 2, 1])

   >>> ak.arange(0, 10, 2)
   array([0, 2, 4, 6, 8])

   >>> ak.arange(-5, -10, -1)
   array([-5, -6, -7, -8, -9])


.. py:function:: array(a: Union[arkouda.pdarrayclass.pdarray, numpy.ndarray, Iterable], dtype: Union[numpy.dtype, type, str] = None) -> Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]

   Convert a Python or Numpy Iterable to a pdarray or Strings object, sending
   the corresponding data to the arkouda server.

   :param a: Rank-1 array of a supported dtype
   :type a: Union[pdarray, np.ndarray]
   :param dtype: The target dtype to cast values to
   :type dtype: np.dtype, type, or str

   :returns: A pdarray instance stored on arkouda server or Strings instance, which
             is composed of two pdarrays stored on arkouda server
   :rtype: pdarray or Strings

   :raises TypeError: Raised if a is not a pdarray, np.ndarray, or Python Iterable such as a
       list, array, tuple, or deque
   :raises RuntimeError: Raised if a is not one-dimensional, nbytes > maxTransferBytes, a.dtype is
       not supported (not in DTypes), or if the product of a size and
       a.itemsize > maxTransferBytes
   :raises ValueError: Raised if the returned message is malformed or does not contain the fields
       required to generate the array.

   .. seealso:: :obj:`pdarray.to_ndarray`

   .. rubric:: Notes

   The number of bytes in the input array cannot exceed `arkouda.maxTransferBytes`,
   otherwise a RuntimeError will be raised. This is to protect the user
   from overwhelming the connection between the Python client and the arkouda
   server, under the assumption that it is a low-bandwidth connection. The user
   may override this limit by setting ak.maxTransferBytes to a larger value,
   but should proceed with caution.

   If the pdrray or ndarray is of type U, this method is called twice recursively
   to create the Strings object and the two corresponding pdarrays for string
   bytes and offsets, respectively.

   .. rubric:: Examples

   >>> ak.array(np.arange(1,10))
   array([1, 2, 3, 4, 5, 6, 7, 8, 9])

   >>> ak.array(range(1,10))
   array([1, 2, 3, 4, 5, 6, 7, 8, 9])

   >>> strings = ak.array(['string {}'.format(i) for i in range(0,5)])
   >>> type(strings)
   <class 'arkouda.strings.Strings'>


.. py:class:: GroupBy(keys: groupable, assume_sorted: bool = False, hash_strings: bool = True)

   Group an array or list of arrays by value, usually in preparation
   for aggregating the within-group values of another array.

   :param keys: The array to group by value, or if list, the column arrays to group by row
   :type keys: (list of) pdarray, Strings, or Categorical
   :param assume_sorted: If True, assume keys is already sorted (Default: False)
   :type assume_sorted: bool

   .. attribute:: nkeys

      The number of key arrays (columns)

      :type: int

   .. attribute:: size

      The length of the input array(s), i.e. number of rows

      :type: int

   .. attribute:: permutation

      The permutation that sorts the keys array(s) by value (row)

      :type: pdarray

   .. attribute:: unique_keys

      The unique values of the keys array(s), in grouped order

      :type: (list of) pdarray, Strings, or Categorical

   .. attribute:: ngroups

      The length of the unique_keys array(s), i.e. number of groups

      :type: int

   .. attribute:: segments

      The start index of each group in the grouped array(s)

      :type: pdarray

   .. attribute:: logger

      Used for all logging operations

      :type: ArkoudaLogger

   :raises TypeError: Raised if keys is a pdarray with a dtype other than int64

   .. rubric:: Notes

   Integral pdarrays, Strings, and Categoricals are natively supported, but
   float64 and bool arrays are not.

   For a user-defined class to be groupable, it must inherit from pdarray
   and define or overload the grouping API:
     1) a ._get_grouping_keys() method that returns a list of pdarrays
        that can be (co)argsorted.
     2) (Optional) a .group() method that returns the permutation that
        groups the array
   If the input is a single array with a .group() method defined, method 2
   will be used; otherwise, method 1 will be used.

   .. py:attribute:: Reductions
      

      

   .. py:method:: count(self) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Count the number of elements in each group, i.e. the number of times
      each key appears.

      :param none:

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **counts** (*pdarray, int64*) -- The number of times each unique key appears

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 2, 3, 1, 2, 4, 3, 4, 3, 4])
      >>> g = ak.GroupBy(a)
      >>> keys,counts = g.count()
      >>> keys
      array([1, 2, 3, 4])
      >>> counts
      array([1, 2, 4, 3])


   .. py:method:: aggregate(self, values: groupable, operator: str, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group another
      array of values and apply a reduction to each group's values.

      :param values: The values to group and reduce
      :type values: pdarray
      :param operator: The name of the reduction operator to use
      :type operator: str

      :returns: * **unique_keys** (*groupable*) -- The unique keys, in grouped order
                * **aggregates** (*groupable*) -- One aggregate value per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if the requested operator is not supported for the
          values dtype

      .. rubric:: Examples

      >>> keys = ak.arange(0, 10)
      >>> vals = ak.linspace(-1, 1, 10)
      >>> g = ak.GroupBy(keys)
      >>> g.aggregate(vals, 'sum')
      (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([-1, -0.77777777777777768,
      -0.55555555555555536, -0.33333333333333348, -0.11111111111111116,
      0.11111111111111116, 0.33333333333333348, 0.55555555555555536, 0.77777777777777768,
      1]))
      >>> g.aggregate(vals, 'min')
      (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([-1, -0.77777777777777779,
      -0.55555555555555558, -0.33333333333333337, -0.11111111111111116, 0.11111111111111116,
      0.33333333333333326, 0.55555555555555536, 0.77777777777777768, 1]))


   .. py:method:: sum(self, values: arkouda.pdarrayclass.pdarray, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and sum each group's values.

      :param values: The values to group and sum
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_sums** (*pdarray*) -- One sum per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array

      .. rubric:: Notes

      The grouped sum of a boolean ``pdarray`` returns integers.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.sum(b)
      (array([2, 3, 4]), array([8, 14, 6]))


   .. py:method:: prod(self, values: arkouda.pdarrayclass.pdarray, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and compute the product of each group's
      values.

      :param values: The values to group and multiply
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_products** (*pdarray, float64*) -- One product per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object
      :raises ValueError: Raised if the key array size does not match the values size
          or if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if prod is not supported for the values dtype

      .. rubric:: Notes

      The return dtype is always float64.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.prod(b)
      (array([2, 3, 4]), array([12, 108.00000000000003, 8.9999999999999982]))


   .. py:method:: mean(self, values: arkouda.pdarrayclass.pdarray, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and compute the mean of each group's
      values.

      :param values: The values to group and average
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_means** (*pdarray, float64*) -- One mean value per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object
      :raises ValueError: Raised if the key array size does not match the values size
          or if the operator is not in the GroupBy.Reductions array

      .. rubric:: Notes

      The return dtype is always float64.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.mean(b)
      (array([2, 3, 4]), array([2.6666666666666665, 2.7999999999999998, 3]))


   .. py:method:: min(self, values: arkouda.pdarrayclass.pdarray, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the minimum of each group's
      values.

      :param values: The values to group and find minima
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_minima** (*pdarray*) -- One minimum per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if min is
          not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values size
          or if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if min is not supported for the values dtype

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.min(b)
      (array([2, 3, 4]), array([1, 1, 3]))


   .. py:method:: max(self, values: arkouda.pdarrayclass.pdarray, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the maximum of each
      group's values.

      :param values: The values to group and find maxima
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_maxima** (*pdarray*) -- One maximum per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if max is
          not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if max is not supported for the values dtype

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.max(b)
      (array([2, 3, 4]), array([4, 4, 3]))


   .. py:method:: argmin(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the location of the first
      minimum of each group's values.

      :param values: The values to group and find argmin
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_argminima** (*pdarray, int64*) -- One index per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if argmax
          is not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values
          size or if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if argmin is not supported for the values dtype

      .. rubric:: Notes

      The returned indices refer to the original values array as
      passed in, not the permutation applied by the GroupBy instance.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.argmin(b)
      (array([2, 3, 4]), array([5, 4, 2]))


   .. py:method:: argmax(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the location of the first
      maximum of each group's values.

      :param values: The values to group and find argmax
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_argmaxima** (*pdarray, int64*) -- One index per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if argmax
          is not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array

      .. rubric:: Notes

      The returned indices refer to the original values array as passed in,
      not the permutation applied by the GroupBy instance.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.argmax(b)
      (array([2, 3, 4]), array([9, 3, 2]))


   .. py:method:: nunique(self, values: groupable) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group another
      array of values and return the number of unique values in each group.

      :param values: The values to group and find unique values
      :type values: pdarray, int64

      :returns: * **unique_keys** (*groupable*) -- The unique keys, in grouped order
                * **group_nunique** (*groupable*) -- Number of unique values per unique key in the GroupBy instance

      :raises TypeError: Raised if the dtype(s) of values array(s) does/do not support
          the nunique method
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if nunique is not supported for the values dtype

      .. rubric:: Examples

      >>> data = ak.array([3, 4, 3, 1, 1, 4, 3, 4, 1, 4])
      >>> data
      array([3, 4, 3, 1, 1, 4, 3, 4, 1, 4])
      >>> labels = ak.array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4])
      >>> labels
      ak.array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4])
      >>> g = ak.GroupBy(labels)
      >>> g.keys
      ak.array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4])
      >>> g.nunique(data)
      array([1,2,3,4]), array([2, 2, 3, 1])
      #    Group (1,1,1) has values [3,4,3] -> there are 2 unique values 3&4
      #    Group (2,2,2) has values [1,1,4] -> 2 unique values 1&4
      #    Group (3,3,3) has values [3,4,1] -> 3 unique values
      #    Group (4) has values [4] -> 1 unique value


   .. py:method:: any(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[Union[arkouda.pdarrayclass.pdarray, List[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]], arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group another
      array of values and perform an "or" reduction on each group.

      :param values: The values to group and reduce with "or"
      :type values: pdarray, bool

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_any** (*pdarray, bool*) -- One bool per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not bool
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array


   .. py:method:: all(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[Union[arkouda.pdarrayclass.pdarray, List[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]], arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform an "and" reduction on
      each group.

      :param values: The values to group and reduce with "and"
      :type values: pdarray, bool

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_any** (*pdarray, bool*) -- One bool per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not bool
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype


   .. py:method:: OR(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[Union[arkouda.pdarrayclass.pdarray, List[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]], arkouda.pdarrayclass.pdarray]

      Bitwise OR of values in each segment.

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform a bitwise OR reduction on
      each group.

      :param values: The values to group and reduce with OR
      :type values: pdarray, int64

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **result** (*pdarray, int64*) -- Bitwise OR of values in segments corresponding to keys

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not int64
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype


   .. py:method:: AND(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[Union[arkouda.pdarrayclass.pdarray, List[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]], arkouda.pdarrayclass.pdarray]

      Bitwise AND of values in each segment.

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform a bitwise AND reduction on
      each group.

      :param values: The values to group and reduce with AND
      :type values: pdarray, int64

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **result** (*pdarray, int64*) -- Bitwise AND of values in segments corresponding to keys

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not int64
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype


   .. py:method:: XOR(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[Union[arkouda.pdarrayclass.pdarray, List[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]], arkouda.pdarrayclass.pdarray]

      Bitwise XOR of values in each segment.

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform a bitwise XOR reduction on
      each group.

      :param values: The values to group and reduce with XOR
      :type values: pdarray, int64

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **result** (*pdarray, int64*) -- Bitwise XOR of values in segments corresponding to keys

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not int64
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype


   .. py:method:: broadcast(self, values: arkouda.pdarrayclass.pdarray, permute: bool = True) -> arkouda.pdarrayclass.pdarray

      Fill each group's segment with a constant value.

      :param values: The values to put in each group's segment
      :type values: pdarray
      :param permute: If True (default), permute broadcast values back to the ordering
                      of the original array on which GroupBy was called. If False, the
                      broadcast values are grouped by value.
      :type permute: bool

      :returns: The broadcast values
      :rtype: pdarray

      :raises TypeError: Raised if value is not a pdarray object
      :raises ValueError: Raised if the values array does not have one
          value per segment

      .. rubric:: Notes

      This function is a sparse analog of ``np.broadcast``. If a
      GroupBy object represents a sparse matrix (tensor), then
      this function takes a (dense) column vector and replicates
      each value to the non-zero elements in the corresponding row.

      .. rubric:: Examples

      >>> a = ak.array([0, 1, 0, 1, 0])
      >>> values = ak.array([3, 5])
      >>> g = ak.GroupBy(a)
      # By default, result is in original order
      >>> g.broadcast(values)
      array([3, 5, 3, 5, 3])

      # With permute=False, result is in grouped order
      >>> g.broadcast(values, permute=False)
      array([3, 3, 3, 5, 5]

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 1, 4, 4, 4, 1, 3, 3, 2, 2])
      >>> g = ak.GroupBy(a)
      >>> keys,counts = g.count()
      >>> g.broadcast(counts > 2)
      array([True False True True True False True True False False])
      >>> g.broadcast(counts == 3)
      array([True False True True True False True True False False])
      >>> g.broadcast(counts < 4)
      array([True True True True True True True True True True])



.. py:function:: broadcast(segments: arkouda.pdarrayclass.pdarray, values: arkouda.pdarrayclass.pdarray, size: Union[int, numpy.int64, numpy.uint64] = -1, permutation: Union[arkouda.pdarrayclass.pdarray, None] = None)

   Broadcast a dense column vector to the rows of a sparse matrix or grouped array.

   :param segments: Offsets of the start of each row in the sparse matrix or grouped array.
                    Must be sorted in ascending order.
   :type segments: pdarray, int64
   :param values: The values to broadcast, one per row (or group)
   :type values: pdarray
   :param size: The total number of nonzeros in the matrix. If permutation is given, this
                argument is ignored and the size is inferred from the permutation array.
   :type size: int
   :param permutation: The permutation to go from the original ordering of nonzeros to the ordering
                       grouped by row. To broadcast values back to the original ordering, this
                       permutation will be inverted. If no permutation is supplied, it is assumed
                       that the original nonzeros were already grouped by row. In this case, the
                       size argument must be given.
   :type permutation: pdarray, int64

   :returns: The broadcast values, one per nonzero
   :rtype: pdarray

   :raises ValueError: - If segments and values are different sizes
       - If segments are empty
       - If number of nonzeros (either user-specified or inferred from permutation)
         is less than one

   .. rubric:: Examples

   # Define a sparse matrix with 3 rows and 7 nonzeros
   >>> row_starts = ak.array([0, 2, 5])
   >>> nnz = 7
   # Broadcast the row number to each nonzero element
   >>> row_number = ak.arange(3)
   >>> ak.broadcast(row_starts, row_number, nnz)
   array([0 0 1 1 1 2 2])

   # If the original nonzeros were in reverse order...
   >>> permutation = ak.arange(6, -1, -1)
   >>> ak.broadcast(row_starts, row_number, permutation=permutation)
   array([2 2 1 1 1 0 0])


.. py:function:: BitVectorizer(width=64, reverse=False)

   Make a callback (i.e. function) that can be called on an
   array to create a BitVector.

   :param width: The number of bit fields in the vector
   :type width: int
   :param reverse: If True, display bits from least significant (left) to most
                   significant (right). By default, the most significant bit
                   is the left-most bit.
   :type reverse: bool

   :returns: **bitvectorizer** -- A function that takes an array and returns a BitVector instance
   :rtype: callable


.. py:class:: BitVector(values, width=64, reverse=False)

   Bases: :py:obj:`arkouda.pdarrayclass.pdarray`

   Represent integers as bit vectors, e.g. a set of flags.

   :param values: The integers to represent as bit vectors
   :type values: pdarray, int64
   :param width: The number of bit fields in the vector
   :type width: int
   :param reverse: If True, display bits from least significant (left) to most
                   significant (right). By default, the most significant bit
                   is the left-most bit.
   :type reverse: bool

   :returns: **bitvectors** -- The array of binary vectors
   :rtype: BitVector

   .. rubric:: Notes

   This class is a thin wrapper around pdarray that mostly affects
   how values are displayed to the user. Operators and methods will
   typically treat this class like a uint64 pdarray.

   .. py:attribute:: conserves
      

      

   .. py:method:: format(self, x)

      Format a single binary vector as a string.


   .. py:method:: __str__(self)

      Return str(self).


   .. py:method:: __repr__(self)

      Return repr(self).


   .. py:method:: to_ndarray(self)

      Export data to a numpy array of string-formatted bit vectors.


   .. py:method:: _cast(self, values)


   .. py:method:: __getitem__(self, key)


   .. py:method:: __setitem__(self, key, value)


   .. py:method:: _binop(self, other, op)

      Executes binary operation specified by the op string

      :param other: The pdarray upon which the binop is to be executed
      :type other: pdarray
      :param op: The binop to be executed
      :type op: str

      :returns: A pdarray encapsulating the binop result
      :rtype: pdarray

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set, or if the
          pdarray sizes don't match
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype


   .. py:method:: _r_binop(self, other, op)

      Executes reverse binary operation specified by the op string

      :param other: The pdarray upon which the reverse binop is to be executed
      :type other: pdarray
      :param op: The name of the reverse binop to be executed
      :type op: str

      :returns: A pdarray encapsulating the reverse binop result
      :rtype: pdarray

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype


   .. py:method:: opeq(self, other, op)



.. py:class:: Fields(values, names, MSB_left=True, pad='-', separator='', show_int=True)

   Bases: :py:obj:`BitVector`

   An integer-backed representation of a set of named binary fields, e.g. flags.

   :param values: The array of field values. If (u)int64, the values are used as-is for the
                  binary representation of fields. If Strings, the values are converted
                  to binary according to the mapping defined by the names and MSB_left
                  arguments.
   :type values: pdarray or Strings
   :param names: The names of the fields, in order. A string will be treated as a list
                 of single-character field names. Multi-character field names are allowed,
                 but must be passed as a list or tuple and user must specify a separator.
   :type names: str or sequence of str
   :param MSB_left: Controls how field names are mapped to binary values. If True (default),
                    the left-most field name corresponds to the most significant bit in the
                    binary representation. If False, the left-most field name corresponds to
                    the least significant bit.
   :type MSB_left: bool
   :param pad: Character to display when field is not present. Use empty string if no
               padding is desired.
   :type pad: str
   :param separator: Substring that separates fields. Used to parse input values (if ak.Strings)
                     and to display output.
   :type separator: str
   :param show_int: If True (default), display the integer value of the binary fields in output.
   :type show_int: bool

   :returns: **fields** -- The array of field values
   :rtype: Fields

   .. rubric:: Notes

   This class is a thin wrapper around pdarray that mostly affects
   how values are displayed to the user. Operators and methods will
   typically treat this class like an int64 pdarray.

   .. py:method:: _convert_strings(self, s)

      Convert string field names to binary vectors.


   .. py:method:: _parse_scalar(self, s)

      Convert a string of named fields to a binary value.


   .. py:method:: format(self, x)

      Format a single binary value as a string of named fields.


   .. py:method:: __setitem__(self, key, value)


   .. py:method:: _cast(self, values)


   .. py:method:: _binop(self, other, op)

      Executes binary operation specified by the op string

      :param other: The pdarray upon which the binop is to be executed
      :type other: pdarray
      :param op: The binop to be executed
      :type op: str

      :returns: A pdarray encapsulating the binop result
      :rtype: pdarray

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set, or if the
          pdarray sizes don't match
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype


   .. py:method:: _r_binop(self, other, op)

      Executes reverse binary operation specified by the op string

      :param other: The pdarray upon which the reverse binop is to be executed
      :type other: pdarray
      :param op: The name of the reverse binop to be executed
      :type op: str

      :returns: A pdarray encapsulating the reverse binop result
      :rtype: pdarray

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype


   .. py:method:: opeq(self, other, op)



.. py:function:: ip_address(values)

   Convert values to an Arkouda array of IP addresses.

   :param values: The integer IP addresses or IPv4 object.
   :type values: list-like, integer pdarray, or IPv4

   :returns: The same IP addresses as an Arkouda array
   :rtype: IPv4

   .. rubric:: Notes

   This helper is intended to help future proof changes made to
   accomodate IPv6 and to prevent errors if a user inadvertently
   casts a IPv4 instead of a int64 pdarray. It can also be used
   for importing Python lists of IP addresses into Arkouda.


.. py:class:: IPv4(values)

   Bases: :py:obj:`arkouda.pdarrayclass.pdarray`

   Represent integers as IPv4 addresses.

   :param values: The integer IP addresses
   :type values: pdarray, int64

   :returns: The same IP addresses
   :rtype: IPv4

   .. rubric:: Notes

   This class is a thin wrapper around pdarray that mostly affects
   how values are displayed to the user. Operators and methods will
   typically treat this class like an int64 pdarray.

   .. py:method:: format(self, x)

      Format a single integer IP address as a string.


   .. py:method:: normalize(self, x)

      Take in an IP address as a string, integer, or IPAddress object,
      and convert it to an integer.


   .. py:method:: _is_supported_scalar(self, x)


   .. py:method:: __str__(self)

      Return str(self).


   .. py:method:: __repr__(self)

      Return repr(self).


   .. py:method:: to_ndarray(self)

      Export array as a numpy array of integers.


   .. py:method:: __getitem__(self, key)


   .. py:method:: __setitem__(self, key, value)


   .. py:method:: _binop(self, other, op)

      Executes binary operation specified by the op string

      :param other: The pdarray upon which the binop is to be executed
      :type other: pdarray
      :param op: The binop to be executed
      :type op: str

      :returns: A pdarray encapsulating the binop result
      :rtype: pdarray

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set, or if the
          pdarray sizes don't match
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype


   .. py:method:: _r_binop(self, other, op)

      Executes reverse binary operation specified by the op string

      :param other: The pdarray upon which the reverse binop is to be executed
      :type other: pdarray
      :param op: The name of the reverse binop to be executed
      :type op: str

      :returns: A pdarray encapsulating the reverse binop result
      :rtype: pdarray

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype


   .. py:method:: opeq(self, other, op)



.. py:data:: DTypes
   

   

.. py:data:: DTypeObjects
   

   

.. py:data:: dtype
   

   

.. py:data:: bool
   

   

.. py:data:: int64
   

   

.. py:data:: float64
   

   

.. py:data:: uint8
   

   

.. py:data:: uint64
   

   

.. py:data:: str_
   

   

.. py:data:: intTypes
   

   

.. py:data:: bitType
   

   

.. py:function:: check_np_dtype(dt: numpy.dtype) -> None

   Assert that numpy dtype dt is one of the dtypes supported
   by arkouda, otherwise raise TypeError.

   :raises TypeError: Raised if the dtype is not in supported dtypes or if
       dt is not a np.dtype


.. py:function:: translate_np_dtype(dt: numpy.dtype) -> Tuple[str, int]

   Split numpy dtype dt into its kind and byte size, raising
   TypeError for unsupported dtypes.

   :raises TypeError: Raised if the dtype is not in supported dtypes or if
       dt is not a np.dtype


.. py:function:: resolve_scalar_dtype(val: object) -> str

   Try to infer what dtype arkouda_server should treat val as.


.. py:data:: ARKOUDA_SUPPORTED_DTYPES
   

   

.. py:data:: bool_scalars
   

   

.. py:data:: float_scalars
   

   

.. py:data:: int_scalars
   

   

.. py:data:: numeric_scalars
   

   

.. py:data:: numpy_scalars
   

   

.. py:data:: str_scalars
   

   

.. py:data:: all_scalars
   

   The DType enum defines the supported Arkouda data types in string form.

.. py:function:: get_byteorder(dt: numpy.dtype) -> str

   Get a concrete byteorder (turns '=' into '<' or '>')


.. py:function:: get_server_byteorder() -> str

   Get the server's byteorder


.. py:class:: pdarray(name: str, mydtype: numpy.dtype, size: arkouda.dtypes.int_scalars, ndim: arkouda.dtypes.int_scalars, shape: Sequence[int], itemsize: arkouda.dtypes.int_scalars)

   The basic arkouda array class. This class contains only the
   attributies of the array; the data resides on the arkouda
   server. When a server operation results in a new array, arkouda
   will create a pdarray instance that points to the array data on
   the server. As such, the user should not initialize pdarray
   instances directly.

   .. attribute:: name

      The server-side identifier for the array

      :type: str

   .. attribute:: dtype

      The element type of the array

      :type: dtype

   .. attribute:: size

      The number of elements in the array

      :type: int_scalars

   .. attribute:: ndim

      The rank of the array (currently only rank 1 arrays supported)

      :type: int_scalars

   .. attribute:: shape

      A list or tuple containing the sizes of each dimension of the array

      :type: Sequence[int]

   .. attribute:: itemsize

      The size in bytes of each element

      :type: int_scalars

   .. py:attribute:: BinOps
      

      

   .. py:attribute:: OpEqOps
      

      

   .. py:attribute:: objtype
      :annotation: = pdarray

      

   .. py:attribute:: __array_priority__
      :annotation: = 1000

      

   .. py:method:: __del__(self)


   .. py:method:: __bool__(self) -> bool


   .. py:method:: __len__(self)


   .. py:method:: __str__(self)

      Return str(self).


   .. py:method:: __repr__(self)

      Return repr(self).


   .. py:method:: format_other(self, other: object) -> str

      Attempt to cast scalar other to the element dtype of this pdarray,
      and print the resulting value to a string (e.g. for sending to a
      server command). The user should not call this function directly.

      :param other: The scalar to be cast to the pdarray.dtype
      :type other: object

      :rtype: string representation of np.dtype corresponding to the other parameter

      :raises TypeError: Raised if the other parameter cannot be converted to
          Numpy dtype


   .. py:method:: _binop(self, other: pdarray, op: str) -> pdarray

      Executes binary operation specified by the op string

      :param other: The pdarray upon which the binop is to be executed
      :type other: pdarray
      :param op: The binop to be executed
      :type op: str

      :returns: A pdarray encapsulating the binop result
      :rtype: pdarray

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set, or if the
          pdarray sizes don't match
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype


   .. py:method:: _r_binop(self, other: pdarray, op: str) -> pdarray

      Executes reverse binary operation specified by the op string

      :param other: The pdarray upon which the reverse binop is to be executed
      :type other: pdarray
      :param op: The name of the reverse binop to be executed
      :type op: str

      :returns: A pdarray encapsulating the reverse binop result
      :rtype: pdarray

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype


   .. py:method:: __add__(self, other)


   .. py:method:: __radd__(self, other)


   .. py:method:: __sub__(self, other)


   .. py:method:: __rsub__(self, other)


   .. py:method:: __mul__(self, other)


   .. py:method:: __rmul__(self, other)


   .. py:method:: __truediv__(self, other)


   .. py:method:: __rtruediv__(self, other)


   .. py:method:: __floordiv__(self, other)


   .. py:method:: __rfloordiv__(self, other)


   .. py:method:: __mod__(self, other)


   .. py:method:: __rmod__(self, other)


   .. py:method:: __lshift__(self, other)


   .. py:method:: __rlshift__(self, other)


   .. py:method:: __rshift__(self, other)


   .. py:method:: __rrshift__(self, other)


   .. py:method:: __and__(self, other)


   .. py:method:: __rand__(self, other)


   .. py:method:: __or__(self, other)


   .. py:method:: __ror__(self, other)


   .. py:method:: __xor__(self, other)


   .. py:method:: __rxor__(self, other)


   .. py:method:: __pow__(self, other)


   .. py:method:: __rpow__(self, other)


   .. py:method:: __lt__(self, other)

      Return self<value.


   .. py:method:: __gt__(self, other)

      Return self>value.


   .. py:method:: __le__(self, other)

      Return self<=value.


   .. py:method:: __ge__(self, other)

      Return self>=value.


   .. py:method:: __eq__(self, other)

      Return self==value.


   .. py:method:: __ne__(self, other)

      Return self!=value.


   .. py:method:: __neg__(self)


   .. py:method:: __invert__(self)


   .. py:method:: opeq(self, other, op)


   .. py:method:: __iadd__(self, other)


   .. py:method:: __isub__(self, other)


   .. py:method:: __imul__(self, other)


   .. py:method:: __itruediv__(self, other)


   .. py:method:: __ifloordiv__(self, other)


   .. py:method:: __ilshift__(self, other)


   .. py:method:: __irshift__(self, other)


   .. py:method:: __iand__(self, other)


   .. py:method:: __ior__(self, other)


   .. py:method:: __ixor__(self, other)


   .. py:method:: __ipow__(self, other)


   .. py:method:: __iter__(self)
      :abstractmethod:


   .. py:method:: __getitem__(self, key)


   .. py:method:: __setitem__(self, key, value)


   .. py:method:: fill(self, value: arkouda.dtypes.numeric_scalars) -> None

      Fill the array (in place) with a constant value.

      :param value:
      :type value: numeric_scalars

      :raises TypeError: Raised if value is not an int, int64, float, or float64


   .. py:method:: any(self) -> numpy.bool_

      Return True iff any element of the array evaluates to True.


   .. py:method:: all(self) -> numpy.bool_

      Return True iff all elements of the array evaluate to True.


   .. py:method:: is_registered(self) -> numpy.bool_

      Return True iff the object is contained in the registry

      :param None:

      :returns: Indicates if the object is contained in the registry
      :rtype: bool

      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: _list_component_names(self) -> List[str]

      Internal Function that returns a list of all component names

      :param None:

      :returns: List of all component names
      :rtype: List[str]


   .. py:method:: info(self) -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str


   .. py:method:: pretty_print_info(self) -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None


   .. py:method:: is_sorted(self) -> numpy.bool_

      Return True iff the array is monotonically non-decreasing.

      :param None:

      :returns: Indicates if the array is monotonically non-decreasing
      :rtype: bool

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: sum(self) -> arkouda.dtypes.numeric_and_bool_scalars

      Return the sum of all elements in the array.


   .. py:method:: prod(self) -> numpy.float64

      Return the product of all elements in the array. Return value is
      always a np.float64 or np.int64.


   .. py:method:: min(self) -> arkouda.dtypes.numpy_scalars

      Return the minimum value of the array.


   .. py:method:: max(self) -> arkouda.dtypes.numpy_scalars

      Return the maximum value of the array.


   .. py:method:: argmin(self) -> numpy.int64

      Return the index of the first occurrence of the array min value


   .. py:method:: argmax(self) -> numpy.int64

      Return the index of the first occurrence of the array max value.


   .. py:method:: mean(self) -> numpy.float64

      Return the mean of the array.


   .. py:method:: var(self, ddof: arkouda.dtypes.int_scalars = 0) -> numpy.float64

      Compute the variance. See ``arkouda.var`` for details.

      :param ddof: "Delta Degrees of Freedom" used in calculating var
      :type ddof: int_scalars

      :returns: The scalar variance of the array
      :rtype: np.float64

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises ValueError: Raised if the ddof >= pdarray size
      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: std(self, ddof: arkouda.dtypes.int_scalars = 0) -> numpy.float64

      Compute the standard deviation. See ``arkouda.std`` for details.

      :param ddof: "Delta Degrees of Freedom" used in calculating std
      :type ddof: int_scalars

      :returns: The scalar standard deviation of the array
      :rtype: np.float64

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: mink(self, k: arkouda.dtypes.int_scalars) -> pdarray

      Compute the minimum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: The maximum `k` values from pda
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray


   .. py:method:: maxk(self, k: arkouda.dtypes.int_scalars) -> pdarray

      Compute the maximum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: The maximum `k` values from pda
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray


   .. py:method:: argmink(self, k: arkouda.dtypes.int_scalars) -> pdarray

      Compute the minimum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: Indices corresponding to the maximum `k` values from pda
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray


   .. py:method:: argmaxk(self, k: arkouda.dtypes.int_scalars) -> pdarray

      Finds the indices corresponding to the maximum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: Indices corresponding to the  maximum `k` values, sorted
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray


   .. py:method:: popcount(self) -> pdarray

      Find the population (number of bits set) in each element. See `ak.popcount`.


   .. py:method:: parity(self) -> pdarray

      Find the parity (XOR of all bits) in each element. See `ak.parity`.


   .. py:method:: clz(self) -> pdarray

      Count the number of leading zeros in each element. See `ak.clz`.


   .. py:method:: ctz(self) -> pdarray

      Count the number of trailing zeros in each element. See `ak.ctz`.


   .. py:method:: rotl(self, other) -> pdarray

      Rotate bits left by <other>.


   .. py:method:: rotr(self, other) -> pdarray

      Rotate bits right by <other>.


   .. py:method:: astype(self, dtype) -> pdarray

      Cast values of pdarray to provided dtype

      :param dtype: Dtype to cast to
      :type dtype: np.dtype or str

      :returns: An arkouda pdarray with values converted to the specified data type
      :rtype: ak.pdarray

      .. rubric:: Notes

      This is essentially shorthand for ak.cast(x, '<dtype>') where x is a pdarray.


   .. py:method:: reshape(self, *shape, order='row_major')

      Gives a new shape to an array without changing its data.

      :param shape: The new shape should be compatible with the original shape.
      :type shape: int, tuple of ints, or pdarray
      :param order: Read the elements of the pdarray in this index order
                    By default, read the elements in row_major or C-like order where the last index changes the fastest
                    If 'column_major' or 'F', read the elements in column_major or Fortran-like order where the first index changes the fastest
      :type order: str {'row_major' | 'C' | 'column_major' | 'F'}

      :returns: An arrayview object with the data from the array but with the new shape
      :rtype: ArrayView


   .. py:method:: to_ndarray(self) -> numpy.ndarray

      Convert the array to a np.ndarray, transferring array data from the
      Arkouda server to client-side Python. Note: if the pdarray size exceeds
      client.maxTransferBytes, a RuntimeError is raised.

      :returns: A numpy ndarray with the same attributes and data as the pdarray
      :rtype: np.ndarray

      :raises RuntimeError: Raised if there is a server-side error thrown, if the pdarray size
          exceeds the built-in client.maxTransferBytes size limit, or if the bytes
          received does not match expected number of bytes

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_ndarray()
      array([0, 1, 2, 3, 4])

      >>> type(a.to_ndarray())
      numpy.ndarray


   .. py:method:: to_cuda(self)

      Convert the array to a Numba DeviceND array, transferring array data from the
      arkouda server to Python via ndarray. If the array exceeds a builtin size limit,
      a RuntimeError is raised.

      :returns: A Numba ndarray with the same attributes and data as the pdarray; on GPU
      :rtype: numba.DeviceNDArray

      :raises ImportError: Raised if CUDA is not available
      :raises ModuleNotFoundError: Raised if Numba is either not installed or not enabled
      :raises RuntimeError: Raised if there is a server-side error thrown in the course of retrieving
          the pdarray.

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_cuda()
      array([0, 1, 2, 3, 4])

      >>> type(a.to_cuda())
      numpy.devicendarray


   .. py:method:: save(self, prefix_path: str, dataset: str = 'array', mode: str = 'truncate', compressed: bool = False, file_format: str = 'HDF5') -> str

      Save the pdarray to HDF5 or Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param compressed: Defaults to False. When True, files will be written with Snappy compression
                         and RLE bit packing. This is currently only supported on Parquet files and will
                         not impact the generated files when writing HDF5 files.
      :type compressed: bool
      :param file_format: By default, saved files will be written to the HDF5 file format. If
                          'Parquet', the files will be written to the Parquet file format. This
                          is case insensitive.
      :type file_format: str {'HDF5', 'Parquet'}

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray
      :raises ValueError: Raised if there is an error in parsing the prefix path pointing to
          file write location or if the mode parameter is neither truncate
          nor append
      :raises TypeError: Raised if any one of the prefix_path, dataset, or mode parameters
          is not a string

      .. seealso:: :obj:`save_all`, :obj:`load`, :obj:`read`

      .. rubric:: Notes

      The prefix_path must be visible to the arkouda server and the user must
      have write permission.

      Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales``. If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.

      .. rubric:: Examples

      >>> a = ak.arange(0, 100, 1)
      >>> a.save('arkouda_range', dataset='array')
      >>> a.save('arkouda_range_parquet', dataset='array', file_format='Parquet')

      Array is saved in numLocales files with names like ``tmp/arkouda_range_LOCALE0``

      The array can be read back in as follows

      >>> b = ak.read('arkouda_range', dataset='array')
      >>> (a == b).all()
      True

      >>> c = ak.read_parquet('arkouda_range_parquet*')
      >>> (c == b).all()
      True


   .. py:method:: save_parquet(self, prefix_path: str, dataset: str = 'array', mode: str = 'truncate', compressed: bool = False) -> str

      Save the pdarray to Parquet. The result is a collection of Parquet files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in Parquet files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
      :type mode: str {'truncate', 'append'}
      :param compressed: By default, write without Snappy compression and RLE encoding.
      :type compressed: bool

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray
      :raises ValueError: Raised if there is an error in parsing the prefix path pointing to
          file write location or if the mode parameter is neither truncate
          nor append
      :raises TypeError: Raised if any one of the prefix_path, dataset, or mode parameters
          is not a string

      .. seealso:: :obj:`save`, :obj:`save_all`, :obj:`load`, :obj:`read`

      .. rubric:: Notes

      The prefix_path must be visible to the arkouda server and the user must
      have write permission.

      Output files have names of the form ``<prefix_path>_LOCALE<i>.parquet``, where ``<i>``
      ranges from 0 to ``numLocales``. If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.

      .. rubric:: Examples

      >>> a = ak.arange(0, 100, 1)
      >>> a.save_parquet('arkouda_range')

      Array is saved in numLocales files with names like ``arkouda_range_LOCALE0000.parquet``

      The array can be read back in as follows

      >>> b = ak.read('arkouda_range')
      >>> (a == b).all()
      True


   .. py:method:: save_hdf(self, prefix_path: str, dataset: str = 'array', mode: str = 'truncate') -> str

      Save the pdarray to HDF5. The result is a collection of HDF5 files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in HDF5 files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
      :type mode: str {'truncate', 'append'}
      :param compressed: By default, write without Snappy compression and RLE encoding.
      :type compressed: bool

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray
      :raises ValueError: Raised if there is an error in parsing the prefix path pointing to
          file write location or if the mode parameter is neither truncate
          nor append
      :raises TypeError: Raised if any one of the prefix_path, dataset, or mode parameters
          is not a string

      .. seealso:: :obj:`save`, :obj:`save_all`, :obj:`load`, :obj:`read`

      .. rubric:: Notes

      The prefix_path must be visible to the arkouda server and the user must
      have write permission.

      Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales``. If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.

      .. rubric:: Examples

      >>> a = ak.arange(0, 100, 1)
      >>> a.save_hdf('arkouda_range')

      Array is saved in numLocales files with names like ``arkouda_range_LOCALE0000``

      The array can be read back in as follows

      >>> b = ak.read('arkouda_range')
      >>> (a == b).all()
      True


   .. py:method:: register(self, user_defined_name: str) -> pdarray

      Register this pdarray with a user defined name in the arkouda server
      so it can be attached to later using pdarray.attach()
      This is an in-place operation, registering a pdarray more than once will
      update the name in the registry and remove the previously registered name.
      A name can only be registered to one pdarray at a time.

      :param user_defined_name: user defined name array is to be registered under
      :type user_defined_name: str

      :returns: The same pdarray which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support a fluid programming style.
                Please note you cannot register two different pdarrays with the same name.
      :rtype: pdarray

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the pdarray with the user_defined_name
          If the user is attempting to register more than one pdarray with the same name, the former should be
          unregistered first to free up the registration name.

      .. seealso:: :obj:`attach`, :obj:`unregister`, :obj:`is_registered`, :obj:`list_registry`, :obj:`unregister_pdarray_by_name`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion
      until they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()


   .. py:method:: unregister(self) -> None

      Unregister a pdarray in the arkouda server which was previously
      registered using register() and/or attahced to using attach()


      :rtype: None

      :raises RuntimeError: Raised if the server could not find the internal name/symbol to remove

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion until
      they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()


   .. py:method:: attach(user_defined_name: str) -> pdarray
      :staticmethod:

      class method to return a pdarray attached to the registered name in the arkouda
      server which was registered using register()

      :param user_defined_name: user defined name which array was registered under
      :type user_defined_name: str

      :returns: pdarray which is bound to corresponding server side component that was registered with user_defined_name
      :rtype: pdarray

      :raises TypeError: Raised if user_defined_name is not a str

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion
      until they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()


   .. py:method:: _get_grouping_keys(self) -> List[pdarray]

      Private method for generating grouping keys used by GroupBy.

      API: this method must be defined by all groupable arrays, and it
      must return a list of arrays that can be (co)argsorted.



.. py:function:: clear() -> None

   Send a clear message to clear all unregistered data from the server symbol table

   :rtype: None

   :raises RuntimeError: Raised if there is a server-side error in executing clear request


.. py:function:: any(pda: pdarray) -> numpy.bool_

   Return True iff any element of the array evaluates to True.

   :param pda: The pdarray instance to be evaluated
   :type pda: pdarray

   :returns: Indicates if 1..n pdarray elements evaluate to True
   :rtype: bool

   :raises TypeError: Raised if pda is not a pdarray instance
   :raises RuntimeError: Raised if there's a server-side error thrown


.. py:function:: all(pda: pdarray) -> numpy.bool_

   Return True iff all elements of the array evaluate to True.

   :param pda: The pdarray instance to be evaluated
   :type pda: pdarray

   :returns: Indicates if all pdarray elements evaluate to True
   :rtype: bool

   :raises TypeError: Raised if pda is not a pdarray instance
   :raises RuntimeError: Raised if there's a server-side error thrown


.. py:function:: is_sorted(pda: pdarray) -> numpy.bool_

   Return True iff the array is monotonically non-decreasing.

   :param pda: The pdarray instance to be evaluated
   :type pda: pdarray

   :returns: Indicates if the array is monotonically non-decreasing
   :rtype: bool

   :raises TypeError: Raised if pda is not a pdarray instance
   :raises RuntimeError: Raised if there's a server-side error thrown


.. py:function:: sum(pda: pdarray) -> numpy.float64

   Return the sum of all elements in the array.

   :param pda: Values for which to calculate the sum
   :type pda: pdarray

   :returns: The sum of all elements in the array
   :rtype: np.float64

   :raises TypeError: Raised if pda is not a pdarray instance
   :raises RuntimeError: Raised if there's a server-side error thrown


.. py:function:: prod(pda: pdarray) -> numpy.float64

   Return the product of all elements in the array. Return value is
   always a np.float64 or np.int64

   :param pda: Values for which to calculate the product
   :type pda: pdarray

   :returns: The product calculated from the pda
   :rtype: numpy_scalars

   :raises TypeError: Raised if pda is not a pdarray instance
   :raises RuntimeError: Raised if there's a server-side error thrown


.. py:function:: min(pda: pdarray) -> arkouda.dtypes.numpy_scalars

   Return the minimum value of the array.

   :param pda: Values for which to calculate the min
   :type pda: pdarray

   :returns: The min calculated from the pda
   :rtype: numpy_scalars

   :raises TypeError: Raised if pda is not a pdarray instance
   :raises RuntimeError: Raised if there's a server-side error thrown


.. py:function:: max(pda: pdarray) -> arkouda.dtypes.numpy_scalars

   Return the maximum value of the array.

   :param pda: Values for which to calculate the max
   :type pda: pdarray

   :returns: The max calculated from the pda
   :rtype: numpy_scalars

   :raises TypeError: Raised if pda is not a pdarray instance
   :raises RuntimeError: Raised if there's a server-side error thrown


.. py:function:: argmin(pda: pdarray) -> numpy.int64

   Return the index of the first occurrence of the array min value.

   :param pda: Values for which to calculate the argmin
   :type pda: pdarray

   :returns: The index of the argmin calculated from the pda
   :rtype: np.int64

   :raises TypeError: Raised if pda is not a pdarray instance
   :raises RuntimeError: Raised if there's a server-side error thrown


.. py:function:: argmax(pda: pdarray) -> numpy.int64

   Return the index of the first occurrence of the array max value.

   :param pda: Values for which to calculate the argmax
   :type pda: pdarray

   :returns: The index of the argmax calculated from the pda
   :rtype: np.int64

   :raises TypeError: Raised if pda is not a pdarray instance
   :raises RuntimeError: Raised if there's a server-side error thrown


.. py:function:: mean(pda: pdarray) -> numpy.float64

   Return the mean of the array.

   :param pda: Values for which to calculate the mean
   :type pda: pdarray

   :returns: The mean calculated from the pda sum and size
   :rtype: np.float64

   :raises TypeError: Raised if pda is not a pdarray instance
   :raises RuntimeError: Raised if there's a server-side error thrown


.. py:function:: var(pda: pdarray, ddof: arkouda.dtypes.int_scalars = 0) -> numpy.float64

   Return the variance of values in the array.

   :param pda: Values for which to calculate the variance
   :type pda: pdarray
   :param ddof: "Delta Degrees of Freedom" used in calculating var
   :type ddof: int_scalars

   :returns: The scalar variance of the array
   :rtype: np.float64

   :raises TypeError: Raised if pda is not a pdarray instance
   :raises ValueError: Raised if the ddof >= pdarray size
   :raises RuntimeError: Raised if there's a server-side error thrown

   .. seealso:: :obj:`mean`, :obj:`std`

   .. rubric:: Notes

   The variance is the average of the squared deviations from the mean,
   i.e.,  ``var = mean((x - x.mean())**2)``.

   The mean is normally calculated as ``x.sum() / N``, where ``N = len(x)``.
   If, however, `ddof` is specified, the divisor ``N - ddof`` is used
   instead.  In standard statistical practice, ``ddof=1`` provides an
   unbiased estimator of the variance of a hypothetical infinite population.
   ``ddof=0`` provides a maximum likelihood estimate of the variance for
   normally distributed variables.


.. py:function:: std(pda: pdarray, ddof: arkouda.dtypes.int_scalars = 0) -> numpy.float64

   Return the standard deviation of values in the array. The standard
   deviation is implemented as the square root of the variance.

   :param pda: values for which to calculate the standard deviation
   :type pda: pdarray
   :param ddof: "Delta Degrees of Freedom" used in calculating std
   :type ddof: int_scalars

   :returns: The scalar standard deviation of the array
   :rtype: np.float64

   :raises TypeError: Raised if pda is not a pdarray instance or ddof is not an integer
   :raises ValueError: Raised if ddof is an integer < 0
   :raises RuntimeError: Raised if there's a server-side error thrown

   .. seealso:: :obj:`mean`, :obj:`var`

   .. rubric:: Notes

   The standard deviation is the square root of the average of the squared
   deviations from the mean, i.e., ``std = sqrt(mean((x - x.mean())**2))``.

   The average squared deviation is normally calculated as
   ``x.sum() / N``, where ``N = len(x)``.  If, however, `ddof` is specified,
   the divisor ``N - ddof`` is used instead. In standard statistical
   practice, ``ddof=1`` provides an unbiased estimator of the variance
   of the infinite population. ``ddof=0`` provides a maximum likelihood
   estimate of the variance for normally distributed variables. The
   standard deviation computed in this function is the square root of
   the estimated variance, so even with ``ddof=1``, it will not be an
   unbiased estimate of the standard deviation per se.


.. py:function:: mink(pda: pdarray, k: arkouda.dtypes.int_scalars) -> pdarray

   Find the `k` minimum values of an array.

   Returns the smallest `k` values of an array, sorted

   :param pda: Input array.
   :type pda: pdarray
   :param k: The desired count of minimum values to be returned by the output.
   :type k: int_scalars

   :returns: The minimum `k` values from pda, sorted
   :rtype: pdarray

   :raises TypeError: Raised if pda is not a pdarray
   :raises ValueError: Raised if the pda is empty or k < 1

   .. rubric:: Notes

   This call is equivalent in value to:

       a[ak.argsort(a)[:k]]

   and generally outperforms this operation.

   This reduction will see a significant drop in performance as `k` grows
   beyond a certain value. This value is system dependent, but generally
   about a `k` of 5 million is where performance degredation has been observed.

   .. rubric:: Examples

   >>> A = ak.array([10,5,1,3,7,2,9,0])
   >>> ak.mink(A, 3)
   array([0, 1, 2])
   >>> ak.mink(A, 4)
   array([0, 1, 2, 3])


.. py:function:: maxk(pda: pdarray, k: arkouda.dtypes.int_scalars) -> pdarray

   Find the `k` maximum values of an array.

   Returns the largest `k` values of an array, sorted

   :param pda: Input array.
   :type pda: pdarray
   :param k: The desired count of maximum values to be returned by the output.
   :type k: int_scalars

   :returns: The maximum `k` values from pda, sorted
   :rtype: pdarray, int

   :raises TypeError: Raised if pda is not a pdarray or k is not an integer
   :raises ValueError: Raised if the pda is empty or k < 1

   .. rubric:: Notes

   This call is equivalent in value to:

       a[ak.argsort(a)[k:]]

   and generally outperforms this operation.

   This reduction will see a significant drop in performance as `k` grows
   beyond a certain value. This value is system dependent, but generally
   about a `k` of 5 million is where performance degredation has been observed.

   .. rubric:: Examples

   >>> A = ak.array([10,5,1,3,7,2,9,0])
   >>> ak.maxk(A, 3)
   array([7, 9, 10])
   >>> ak.maxk(A, 4)
   array([5, 7, 9, 10])


.. py:function:: argmink(pda: pdarray, k: arkouda.dtypes.int_scalars) -> pdarray

   Finds the indices corresponding to the `k` minimum values of an array.

   :param pda: Input array.
   :type pda: pdarray
   :param k: The desired count of indices corresponding to minimum array values
   :type k: int_scalars

   :returns: The indices of the minimum `k` values from the pda, sorted
   :rtype: pdarray, int

   :raises TypeError: Raised if pda is not a pdarray or k is not an integer
   :raises ValueError: Raised if the pda is empty or k < 1

   .. rubric:: Notes

   This call is equivalent in value to:

       ak.argsort(a)[:k]

   and generally outperforms this operation.

   This reduction will see a significant drop in performance as `k` grows
   beyond a certain value. This value is system dependent, but generally
   about a `k` of 5 million is where performance degradation has been observed.

   .. rubric:: Examples

   >>> A = ak.array([10,5,1,3,7,2,9,0])
   >>> ak.argmink(A, 3)
   array([7, 2, 5])
   >>> ak.argmink(A, 4)
   array([7, 2, 5, 3])


.. py:function:: argmaxk(pda: pdarray, k: arkouda.dtypes.int_scalars) -> pdarray

   Find the indices corresponding to the `k` maximum values of an array.

   Returns the largest `k` values of an array, sorted

   :param pda: Input array.
   :type pda: pdarray
   :param k: The desired count of indices corresponding to maxmum array values
   :type k: int_scalars

   :returns: The indices of the maximum `k` values from the pda, sorted
   :rtype: pdarray, int

   :raises TypeError: Raised if pda is not a pdarray or k is not an integer
   :raises ValueError: Raised if the pda is empty or k < 1

   .. rubric:: Notes

   This call is equivalent in value to:

       ak.argsort(a)[k:]

   and generally outperforms this operation.

   This reduction will see a significant drop in performance as `k` grows
   beyond a certain value. This value is system dependent, but generally
   about a `k` of 5 million is where performance degradation has been observed.

   .. rubric:: Examples

   >>> A = ak.array([10,5,1,3,7,2,9,0])
   >>> ak.argmaxk(A, 3)
   array([4, 6, 0])
   >>> ak.argmaxk(A, 4)
   array([1, 4, 6, 0])


.. py:function:: popcount(pda: pdarray) -> pdarray

   Find the population (number of bits set) for each integer in an array.

   :param pda: Input array (must be integral).
   :type pda: pdarray, int64, uint64

   :returns: **population** -- The number of bits set (1) in each element
   :rtype: pdarray

   :raises TypeError: If input array is not int64 or uint64

   .. rubric:: Examples

   >>> A = ak.arange(10)
   >>> ak.popcount(A)
   array([0, 1, 1, 2, 1, 2, 2, 3, 1, 2])


.. py:function:: parity(pda: pdarray) -> pdarray

   Find the bit parity (XOR of all bits) for each integer in an array.

   :param pda: Input array (must be integral).
   :type pda: pdarray, int64, uint64

   :returns: **parity** -- The parity of each element: 0 if even number of bits set, 1 if odd.
   :rtype: pdarray

   :raises TypeError: If input array is not int64 or uint64

   .. rubric:: Examples

   >>> A = ak.arange(10)
   >>> ak.parity(A)
   array([0, 1, 1, 0, 1, 0, 0, 1, 1, 0])


.. py:function:: clz(pda: pdarray) -> pdarray

   Count leading zeros for each integer in an array.

   :param pda: Input array (must be integral).
   :type pda: pdarray, int64, uint64

   :returns: **lz** -- The number of leading zeros of each element.
   :rtype: pdarray

   :raises TypeError: If input array is not int64 or uint64

   .. rubric:: Examples

   >>> A = ak.arange(10)
   >>> ak.clz(A)
   array([64, 63, 62, 62, 61, 61, 61, 61, 60, 60])


.. py:function:: ctz(pda: pdarray) -> pdarray

   Count trailing zeros for each integer in an array.

   :param pda: Input array (must be integral).
   :type pda: pdarray, int64, uint64

   :returns: **lz** -- The number of trailing zeros of each element.
   :rtype: pdarray

   .. rubric:: Notes

   ctz(0) is defined to be zero.

   :raises TypeError: If input array is not int64 or uint64

   .. rubric:: Examples

   >>> A = ak.arange(10)
   >>> ak.ctz(A)
   array([0, 0, 1, 0, 2, 0, 1, 0, 3, 0])


.. py:function:: rotl(x, rot) -> pdarray

   Rotate bits of <x> to the left by <rot>.

   :param x: Value(s) to rotate left.
   :type x: pdarray(int64/uint64) or integer
   :param rot: Amount(s) to rotate by.
   :type rot: pdarray(int64/uint64) or integer

   :returns: **rotated** -- The rotated elements of x.
   :rtype: pdarray(int64/uint64)

   :raises TypeError: If input array is not int64 or uint64

   .. rubric:: Examples

   >>> A = ak.arange(10)
   >>> ak.rotl(A, A)
   array([0, 2, 8, 24, 64, 160, 384, 896, 2048, 4608])


.. py:function:: rotr(x, rot) -> pdarray

   Rotate bits of <x> to the left by <rot>.

   :param x: Value(s) to rotate left.
   :type x: pdarray(int64/uint64) or integer
   :param rot: Amount(s) to rotate by.
   :type rot: pdarray(int64/uint64) or integer

   :returns: **rotated** -- The rotated elements of x.
   :rtype: pdarray(int64/uint64)

   :raises TypeError: If input array is not int64 or uint64

   .. rubric:: Examples

   >>> A = ak.arange(10)
   >>> ak.rotr(1024 * A, A)
   array([0, 512, 512, 384, 256, 160, 96, 56, 32, 18])


.. py:function:: attach_pdarray(user_defined_name: str) -> pdarray

   class method to return a pdarray attached to the registered name in the arkouda
   server which was registered using register()

   :param user_defined_name: user defined name which array was registered under
   :type user_defined_name: str

   :returns: pdarray which is bound to corresponding server side component that was registered with user_defined_name
   :rtype: pdarray

   :raises TypeError: Raised if user_defined_name is not a str

   .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

   .. rubric:: Notes

   Registered names/pdarrays in the server are immune to deletion
   until they are unregistered.

   .. rubric:: Examples

   >>> a = zeros(100)
   >>> a.register("my_zeros")
   >>> # potentially disconnect from server and reconnect to server
   >>> b = ak.attach_pdarray("my_zeros")
   >>> # ...other work...
   >>> b.unregister()


.. py:function:: unregister_pdarray_by_name(user_defined_name: str) -> None

   Unregister a named pdarray in the arkouda server which was previously
   registered using register() and/or attahced to using attach_pdarray()

   :param user_defined_name: user defined name which array was registered under
   :type user_defined_name: str

   :rtype: None

   :raises RuntimeError: Raised if the server could not find the internal name/symbol to remove

   .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`list_registry`, :obj:`attach`

   .. rubric:: Notes

   Registered names/pdarrays in the server are immune to deletion until
   they are unregistered.

   .. rubric:: Examples

   >>> a = zeros(100)
   >>> a.register("my_zeros")
   >>> # potentially disconnect from server and reconnect to server
   >>> b = ak.attach_pdarray("my_zeros")
   >>> # ...other work...
   >>> ak.unregister_pdarray_by_name(b)


.. py:exception:: RegistrationError

   Bases: :py:obj:`Exception`

   Error/Exception used when the Arkouda Server cannot register an object


.. py:function:: argsort(pda: Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, arkouda.categorical.Categorical], algorithm: SortingAlgorithm = SortingAlgorithm.RadixSortLSD) -> arkouda.pdarrayclass.pdarray

   Return the permutation that sorts the array.

   :param pda: The array to sort (int64, uint64, or float64)
   :type pda: pdarray or Strings or Categorical

   :returns: The indices such that ``pda[indices]`` is sorted
   :rtype: pdarray, int64

   :raises TypeError: Raised if the parameter is other than a pdarray or Strings

   .. seealso:: :obj:`coargsort`

   .. rubric:: Notes

   Uses a least-significant-digit radix sort, which is stable and
   resilient to non-uniformity in data but communication intensive.

   .. rubric:: Examples

   >>> a = ak.randint(0, 10, 10)
   >>> perm = ak.argsort(a)
   >>> a[perm]
   array([0, 1, 1, 3, 4, 5, 7, 8, 8, 9])


.. py:function:: coargsort(arrays: Sequence[Union[arkouda.strings.Strings, arkouda.pdarrayclass.pdarray, arkouda.categorical.Categorical]], algorithm: SortingAlgorithm = SortingAlgorithm.RadixSortLSD) -> arkouda.pdarrayclass.pdarray

   Return the permutation that groups the rows (left-to-right), if the
   input arrays are treated as columns. The permutation sorts numeric
   columns, but not strings/Categoricals -- strings/Categoricals are grouped, but not ordered.

   :param arrays: The columns (int64, uint64, float64, Strings, or Categorical) to sort by row
   :type arrays: Sequence[Union[Strings, pdarray, Categorical]]

   :returns: The indices that permute the rows to grouped order
   :rtype: pdarray, int64

   :raises ValueError: Raised if the pdarrays are not of the same size or if the parameter
       is not an Iterable containing pdarrays, Strings, or Categoricals

   .. seealso:: :obj:`argsort`

   .. rubric:: Notes

   Uses a least-significant-digit radix sort, which is stable and resilient
   to non-uniformity in data but communication intensive. Starts with the
   last array and moves forward. This sort operates directly on numeric types,
   but for Strings, it operates on a hash. Thus, while grouping of equivalent
   strings is guaranteed, lexicographic ordering of the groups is not. For Categoricals,
   coargsort sorts based on Categorical.codes which guarantees grouping of equivalent categories
   but not lexicographic ordering of those groups.

   .. rubric:: Examples

   >>> a = ak.array([0, 1, 0, 1])
   >>> b = ak.array([1, 1, 0, 0])
   >>> perm = ak.coargsort([a, b])
   >>> perm
   array([2, 0, 3, 1])
   >>> a[perm]
   array([0, 0, 1, 1])
   >>> b[perm]
   array([0, 1, 0, 1])


.. py:function:: sort(pda: arkouda.pdarrayclass.pdarray, algorithm: SortingAlgorithm = SortingAlgorithm.RadixSortLSD) -> arkouda.pdarrayclass.pdarray

   Return a sorted copy of the array. Only sorts numeric arrays;
   for Strings, use argsort.

   :param pda: The array to sort (int64, uint64, or float64)
   :type pda: pdarray or Categorical

   :returns: The sorted copy of pda
   :rtype: pdarray, int64, uint64, or float64

   :raises TypeError: Raised if the parameter is not a pdarray
   :raises ValueError: Raised if sort attempted on a pdarray with an unsupported dtype
       such as bool

   .. seealso:: :obj:`argsort`

   .. rubric:: Notes

   Uses a least-significant-digit radix sort, which is stable and resilient
   to non-uniformity in data but communication intensive.

   .. rubric:: Examples

   >>> a = ak.randint(0, 10, 10)
   >>> sorted = ak.sort(a)
   >>> a
   array([0, 1, 1, 3, 4, 5, 7, 8, 8, 9])


.. py:data:: SortingAlgorithm
   

   

.. py:function:: in1d(pda1: Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, Categorical], pda2: Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, Categorical], invert: bool = False) -> arkouda.pdarrayclass.pdarray

   Test whether each element of a 1-D array is also present in a second array.

   Returns a boolean array the same length as `pda1` that is True
   where an element of `pda1` is in `pda2` and False otherwise.

   :param pda1: Input array.
   :type pda1: pdarray or Strings or Categorical
   :param pda2: The values against which to test each value of `pda1`. Must be the
                same type as `pda1`.
   :type pda2: pdarray or Strings or Categorical
   :param invert: If True, the values in the returned array are inverted (that is,
                  False where an element of `pda1` is in `pda2` and True otherwise).
                  Default is False. ``ak.in1d(a, b, invert=True)`` is equivalent
                  to (but is faster than) ``~ak.in1d(a, b)``.
   :type invert: bool, optional

   :returns: The values `pda1[in1d]` are in `pda2`.
   :rtype: pdarray, bool

   :raises TypeError: Raised if either pda1 or pda2 is not a pdarray, Strings, or
       Categorical object or if invert is not a bool
   :raises RuntimeError: Raised if the dtype of either array is not supported

   .. seealso:: :obj:`unique`, :obj:`intersect1d`, :obj:`union1d`

   .. rubric:: Notes

   `in1d` can be considered as an element-wise function version of the
   python keyword `in`, for 1-D sequences. ``in1d(a, b)`` is logically
   equivalent to ``ak.array([item in b for item in a])``, but is much
   faster and scales to arbitrarily large ``a``.

   ak.in1d is not supported for bool or float64 pdarrays

   .. rubric:: Examples

   >>> ak.in1d(ak.array([-1, 0, 1]), ak.array([-2, 0, 2]))
   array([False, True, False])

   >>> ak.in1d(ak.array(['one','two']),ak.array(['two', 'three','four','five']))
   array([False, True])


.. py:function:: concatenate(arrays: Sequence[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, Categorical]], ordered: bool = True) -> Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, Categorical]

   Concatenate a list or tuple of ``pdarray`` or ``Strings`` objects into
   one ``pdarray`` or ``Strings`` object, respectively.

   :param arrays: The arrays to concatenate. Must all have same dtype.
   :type arrays: Sequence[Union[pdarray,Strings,Categorical]]
   :param ordered: If True (default), the arrays will be appended in the
                   order given. If False, array data may be interleaved
                   in blocks, which can greatly improve performance but
                   results in non-deterministic ordering of elements.
   :type ordered: bool

   :returns: Single pdarray or Strings object containing all values, returned in
             the original order
   :rtype: Union[pdarray,Strings,Categorical]

   :raises ValueError: Raised if arrays is empty or if 1..n pdarrays have
       differing dtypes
   :raises TypeError: Raised if arrays is not a pdarrays or Strings python Sequence such as a
       list or tuple
   :raises RuntimeError: Raised if 1..n array elements are dtypes for which
       concatenate has not been implemented.

   .. rubric:: Examples

   >>> ak.concatenate([ak.array([1, 2, 3]), ak.array([4, 5, 6])])
   array([1, 2, 3, 4, 5, 6])

   >>> ak.concatenate([ak.array([True,False,True]),ak.array([False,True,True])])
   array([True, False, True, False, True, True])

   >>> ak.concatenate([ak.array(['one','two']),ak.array(['three','four','five'])])
   array(['one', 'two', 'three', 'four', 'five'])


.. py:function:: union1d(pda1: Union[arkouda.pdarrayclass.pdarray, Sequence[arkouda.groupbyclass.groupable_element_type]], pda2: Union[arkouda.pdarrayclass.pdarray, Sequence[arkouda.groupbyclass.groupable_element_type]]) -> Union[arkouda.pdarrayclass.pdarray, arkouda.groupbyclass.groupable]

   Find the union of two arrays/List of Arrays.

   Return the unique, sorted array of values that are in either
   of the two input arrays.

   :param pda1: Input array/Sequence of groupable objects
   :type pda1: pdarray/Sequence[pdarray, Strings, Categorical]
   :param pda2: Input array/sequence of groupable objects
   :type pda2: pdarray/List

   :returns: Unique, sorted union of the input arrays.
   :rtype: pdarray/groupable

   :raises TypeError: Raised if either pda1 or pda2 is not a pdarray
   :raises RuntimeError: Raised if the dtype of either array is not supported

   .. seealso:: :obj:`intersect1d`, :obj:`unique`

   .. rubric:: Notes

   ak.union1d is not supported for bool or float64 pdarrays

   .. rubric:: Examples

   # 1D Example
   >>> ak.union1d(ak.array([-1, 0, 1]), ak.array([-2, 0, 2]))
   array([-2, -1, 0, 1, 2])

   #Multi-Array Example
   >>> a = ak.arange(1, 6)
   >>> b = ak.array([1, 5, 3, 4, 2])
   >>> c = ak.array([1, 4, 3, 2, 5])
   >>> d = ak.array([1, 2, 3, 5, 4])
   >>> multia = [a, a, a]
   >>> multib = [b, c, d]
   >>> ak.union1d(multia, multib)
   [array[1, 2, 2, 3, 4, 4, 5, 5], array[1, 2, 5, 3, 2, 4, 4, 5], array[1, 2, 4, 3, 5, 4, 2, 5]]


.. py:function:: intersect1d(pda1: arkouda.groupbyclass.groupable, pda2: arkouda.groupbyclass.groupable, assume_unique: bool = False) -> Union[arkouda.pdarrayclass.pdarray, arkouda.groupbyclass.groupable]

   Find the intersection of two arrays.

   Return the sorted, unique values that are in both of the input arrays.

   :param pda1: Input array/Sequence of groupable objects
   :type pda1: pdarray/Sequence[pdarray, Strings, Categorical]
   :param pda2: Input array/sequence of groupable objects
   :type pda2: pdarray/List
   :param assume_unique: If True, the input arrays are both assumed to be unique, which
                         can speed up the calculation.  Default is False.
   :type assume_unique: bool

   :returns: Sorted 1D array/List of sorted pdarrays of common and unique elements.
   :rtype: pdarray/groupable

   :raises TypeError: Raised if either pda1 or pda2 is not a pdarray
   :raises RuntimeError: Raised if the dtype of either pdarray is not supported

   .. seealso:: :obj:`unique`, :obj:`union1d`

   .. rubric:: Notes

   ak.intersect1d is not supported for bool or float64 pdarrays

   .. rubric:: Examples

   # 1D Example
   >>> ak.intersect1d([1, 3, 4, 3], [3, 1, 2, 1])
   array([1, 3])

   # Multi-Array Example
   >>> a = ak.arange(5)
   >>> b = ak.array([1, 5, 3, 4, 2])
   >>> c = ak.array([1, 4, 3, 2, 5])
   >>> d = ak.array([1, 2, 3, 5, 4])
   >>> multia = [a, a, a]
   >>> multib = [b, c, d]
   >>> ak.intersect1d(multia, multib)
   [array([1, 3]), array([1, 3]), array([1, 3])]


.. py:function:: setdiff1d(pda1: arkouda.groupbyclass.groupable, pda2: arkouda.groupbyclass.groupable, assume_unique: bool = False) -> Union[arkouda.pdarrayclass.pdarray, arkouda.groupbyclass.groupable]

   Find the set difference of two arrays.

   Return the sorted, unique values in `pda1` that are not in `pda2`.

   :param pda1: Input array/Sequence of groupable objects
   :type pda1: pdarray/Sequence[pdarray, Strings, Categorical]
   :param pda2: Input array/sequence of groupable objects
   :type pda2: pdarray/List
   :param assume_unique: If True, the input arrays are both assumed to be unique, which
                         can speed up the calculation.  Default is False.
   :type assume_unique: bool

   :returns: Sorted 1D array/List of sorted pdarrays of values in `pda1` that are not in `pda2`.
   :rtype: pdarray/groupable

   :raises TypeError: Raised if either pda1 or pda2 is not a pdarray
   :raises RuntimeError: Raised if the dtype of either pdarray is not supported

   .. seealso:: :obj:`unique`, :obj:`setxor1d`

   .. rubric:: Notes

   ak.setdiff1d is not supported for bool or float64 pdarrays

   .. rubric:: Examples

   >>> a = ak.array([1, 2, 3, 2, 4, 1])
   >>> b = ak.array([3, 4, 5, 6])
   >>> ak.setdiff1d(a, b)
   array([1, 2])

   #Multi-Array Example
   >>> a = ak.arange(1, 6)
   >>> b = ak.array([1, 5, 3, 4, 2])
   >>> c = ak.array([1, 4, 3, 2, 5])
   >>> d = ak.array([1, 2, 3, 5, 4])
   >>> multia = [a, a, a]
   >>> multib = [b, c, d]
   >>> ak.setdiff1d(multia, multib)
   [array([2, 4, 5]), array([2, 4, 5]), array([2, 4, 5])]


.. py:function:: setxor1d(pda1: arkouda.groupbyclass.groupable, pda2: arkouda.groupbyclass.groupable, assume_unique: bool = False) -> Union[arkouda.pdarrayclass.pdarray, arkouda.groupbyclass.groupable]

   Find the set exclusive-or (symmetric difference) of two arrays.

   Return the sorted, unique values that are in only one (not both) of the
   input arrays.

   :param pda1: Input array/Sequence of groupable objects
   :type pda1: pdarray/Sequence[pdarray, Strings, Categorical]
   :param pda2: Input array/sequence of groupable objects
   :type pda2: pdarray/List
   :param assume_unique: If True, the input arrays are both assumed to be unique, which
                         can speed up the calculation.  Default is False.
   :type assume_unique: bool

   :returns: Sorted 1D array/List of sorted pdarrays of unique values that are in only one of the input
             arrays.
   :rtype: pdarray/groupable

   :raises TypeError: Raised if either pda1 or pda2 is not a pdarray
   :raises RuntimeError: Raised if the dtype of either pdarray is not supported

   .. rubric:: Notes

   ak.setxor1d is not supported for bool or float64 pdarrays

   .. rubric:: Examples

   >>> a = ak.array([1, 2, 3, 2, 4])
   >>> b = ak.array([2, 3, 5, 7, 5])
   >>> ak.setxor1d(a,b)
   array([1, 4, 5, 7])

   #Multi-Array Example
   >>> a = ak.arange(1, 6)
   >>> b = ak.array([1, 5, 3, 4, 2])
   >>> c = ak.array([1, 4, 3, 2, 5])
   >>> d = ak.array([1, 2, 3, 5, 4])
   >>> multia = [a, a, a]
   >>> multib = [b, c, d]
   >>> ak.setxor1d(multia, multib)
   [array([2, 2, 4, 4, 5, 5]), array([2, 5, 2, 4, 4, 5]), array([2, 4, 5, 4, 2, 5])]


.. py:function:: array(a: Union[arkouda.pdarrayclass.pdarray, numpy.ndarray, Iterable], dtype: Union[numpy.dtype, type, str] = None) -> Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]

   Convert a Python or Numpy Iterable to a pdarray or Strings object, sending
   the corresponding data to the arkouda server.

   :param a: Rank-1 array of a supported dtype
   :type a: Union[pdarray, np.ndarray]
   :param dtype: The target dtype to cast values to
   :type dtype: np.dtype, type, or str

   :returns: A pdarray instance stored on arkouda server or Strings instance, which
             is composed of two pdarrays stored on arkouda server
   :rtype: pdarray or Strings

   :raises TypeError: Raised if a is not a pdarray, np.ndarray, or Python Iterable such as a
       list, array, tuple, or deque
   :raises RuntimeError: Raised if a is not one-dimensional, nbytes > maxTransferBytes, a.dtype is
       not supported (not in DTypes), or if the product of a size and
       a.itemsize > maxTransferBytes
   :raises ValueError: Raised if the returned message is malformed or does not contain the fields
       required to generate the array.

   .. seealso:: :obj:`pdarray.to_ndarray`

   .. rubric:: Notes

   The number of bytes in the input array cannot exceed `arkouda.maxTransferBytes`,
   otherwise a RuntimeError will be raised. This is to protect the user
   from overwhelming the connection between the Python client and the arkouda
   server, under the assumption that it is a low-bandwidth connection. The user
   may override this limit by setting ak.maxTransferBytes to a larger value,
   but should proceed with caution.

   If the pdrray or ndarray is of type U, this method is called twice recursively
   to create the Strings object and the two corresponding pdarrays for string
   bytes and offsets, respectively.

   .. rubric:: Examples

   >>> ak.array(np.arange(1,10))
   array([1, 2, 3, 4, 5, 6, 7, 8, 9])

   >>> ak.array(range(1,10))
   array([1, 2, 3, 4, 5, 6, 7, 8, 9])

   >>> strings = ak.array(['string {}'.format(i) for i in range(0,5)])
   >>> type(strings)
   <class 'arkouda.strings.Strings'>


.. py:function:: zeros(size: Union[arkouda.dtypes.int_scalars, str], dtype: Union[numpy.dtype, type, str] = float64) -> arkouda.pdarrayclass.pdarray

   Create a pdarray filled with zeros.

   :param size: Size of the array (only rank-1 arrays supported)
   :type size: int_scalars
   :param dtype: Type of resulting array, default float64
   :type dtype: all_scalars

   :returns: Zeros of the requested size and dtype
   :rtype: pdarray

   :raises TypeError: Raised if the supplied dtype is not supported or if the size
       parameter is neither an int nor a str that is parseable to an int.

   .. seealso:: :obj:`ones`, :obj:`zeros_like`

   .. rubric:: Examples

   >>> ak.zeros(5, dtype=ak.int64)
   array([0, 0, 0, 0, 0])

   >>> ak.zeros(5, dtype=ak.float64)
   array([0, 0, 0, 0, 0])

   >>> ak.zeros(5, dtype=ak.bool)
   array([False, False, False, False, False])


.. py:function:: ones(size: Union[arkouda.dtypes.int_scalars, str], dtype: Union[numpy.dtype, type, str] = float64) -> arkouda.pdarrayclass.pdarray

   Create a pdarray filled with ones.

   :param size: Size of the array (only rank-1 arrays supported)
   :type size: int_scalars
   :param dtype: Resulting array type, default float64
   :type dtype: Union[float64, int64, bool]

   :returns: Ones of the requested size and dtype
   :rtype: pdarray

   :raises TypeError: Raised if the supplied dtype is not supported or if the size
       parameter is neither an int nor a str that is parseable to an int.

   .. seealso:: :obj:`zeros`, :obj:`ones_like`

   .. rubric:: Examples

   >>> ak.ones(5, dtype=ak.int64)
   array([1, 1, 1, 1, 1])

   >>> ak.ones(5, dtype=ak.float64)
   array([1, 1, 1, 1, 1])

   >>> ak.ones(5, dtype=ak.bool)
   array([True, True, True, True, True])


.. py:function:: full(size: Union[arkouda.dtypes.int_scalars, str], fill_value: arkouda.dtypes.int_scalars, dtype: Union[numpy.dtype, type, str] = float64) -> arkouda.pdarrayclass.pdarray

   Create a pdarray filled with fill_value.

   :param size: Size of the array (only rank-1 arrays supported)
   :type size: int_scalars
   :param fill_value: Value with which the array will be filled
   :type fill_value: int_scalars
   :param dtype: Resulting array type, default float64
   :type dtype: all_scalars

   :returns: array of the requested size and dtype filled with fill_value
   :rtype: pdarray

   :raises TypeError: Raised if the supplied dtype is not supported or if the size
       parameter is neither an int nor a str that is parseable to an int.

   .. seealso:: :obj:`zeros`, :obj:`ones`

   .. rubric:: Examples

   >>> ak.full(5, 7, dtype=ak.int64)
   array([7, 7, 7, 7, 7])

   >>> ak.full(5, 9, dtype=ak.float64)
   array([9, 9, 9, 9, 9])

   >>> ak.full(5, 5, dtype=ak.bool)
   array([True, True, True, True, True])


.. py:function:: zeros_like(pda: arkouda.pdarrayclass.pdarray) -> arkouda.pdarrayclass.pdarray

   Create a zero-filled pdarray of the same size and dtype as an existing
   pdarray.

   :param pda: Array to use for size and dtype
   :type pda: pdarray

   :returns: Equivalent to ak.zeros(pda.size, pda.dtype)
   :rtype: pdarray

   :raises TypeError: Raised if the pda parameter is not a pdarray.

   .. seealso:: :obj:`zeros`, :obj:`ones_like`

   .. rubric:: Examples

   >>> zeros = ak.zeros(5, dtype=ak.int64)
   >>> ak.zeros_like(zeros)
   array([0, 0, 0, 0, 0])

   >>> zeros = ak.zeros(5, dtype=ak.float64)
   >>> ak.zeros_like(zeros)
   array([0, 0, 0, 0, 0])

   >>> zeros = ak.zeros(5, dtype=ak.bool)
   >>> ak.zeros_like(zeros)
   array([False, False, False, False, False])


.. py:function:: ones_like(pda: arkouda.pdarrayclass.pdarray) -> arkouda.pdarrayclass.pdarray

   Create a one-filled pdarray of the same size and dtype as an existing
   pdarray.

   :param pda: Array to use for size and dtype
   :type pda: pdarray

   :returns: Equivalent to ak.ones(pda.size, pda.dtype)
   :rtype: pdarray

   :raises TypeError: Raised if the pda parameter is not a pdarray.

   .. seealso:: :obj:`ones`, :obj:`zeros_like`

   .. rubric:: Notes

   Logic for generating the pdarray is delegated to the ak.ones method.
   Accordingly, the supported dtypes match are defined by the ak.ones method.

   .. rubric:: Examples

   >>> ones = ak.ones(5, dtype=ak.int64)
    >>> ak.ones_like(ones)
   array([1, 1, 1, 1, 1])

   >>> ones = ak.ones(5, dtype=ak.float64)
   >>> ak.ones_like(ones)
   array([1, 1, 1, 1, 1])

   >>> ones = ak.ones(5, dtype=ak.bool)
   >>> ak.ones_like(ones)
   array([True, True, True, True, True])


.. py:function:: full_like(pda: arkouda.pdarrayclass.pdarray, fill_value: arkouda.dtypes.int_scalars) -> arkouda.pdarrayclass.pdarray

   Create a pdarray filled with fill_value of the same size and dtype as an existing
   pdarray.

   :param pda: Array to use for size and dtype
   :type pda: pdarray
   :param fill_value: Value with which the array will be filled
   :type fill_value: int_scalars

   :returns: Equivalent to ak.full(pda.size, fill_value, pda.dtype)
   :rtype: pdarray

   :raises TypeError: Raised if the pda parameter is not a pdarray.

   .. seealso:: :obj:`ones_like`, :obj:`zeros_like`

   .. rubric:: Notes

   Logic for generating the pdarray is delegated to the ak.full method.
   Accordingly, the supported dtypes match are defined by the ak.full method.

   .. rubric:: Examples

   >>> full = ak.full(5, 7, dtype=ak.int64)
   >>> ak.full_like(full)
   array([7, 7, 7, 7, 7])

   >>> full = ak.full(5, 9, dtype=ak.float64)
   >>> ak.full_like(full)
   array([9, 9, 9, 9, 9])

   >>> full = ak.full(5, 5, dtype=ak.bool)
   >>> ak.full_like(full)
   array([True, True, True, True, True])


.. py:function:: arange(*args, **kwargs) -> arkouda.pdarrayclass.pdarray

   arange([start,] stop[, stride,] dtype=int64)

   Create a pdarray of consecutive integers within the interval [start, stop).
   If only one arg is given then arg is the stop parameter. If two args are
   given, then the first arg is start and second is stop. If three args are
   given, then the first arg is start, second is stop, third is stride.

   The return value is cast to type dtype

   :param start: Starting value (inclusive)
   :type start: int_scalars, optional
   :param stop: Stopping value (exclusive)
   :type stop: int_scalars
   :param stride: The difference between consecutive elements, the default stride is 1,
                  if stride is specified then start must also be specified.
   :type stride: int_scalars, optional
   :param dtype: The target dtype to cast values to
   :type dtype: np.dtype, type, or str

   :returns: Integers from start (inclusive) to stop (exclusive) by stride
   :rtype: pdarray, dtype

   :raises TypeError: Raised if start, stop, or stride is not an int object
   :raises ZeroDivisionError: Raised if stride == 0

   .. seealso:: :obj:`linspace`, :obj:`zeros`, :obj:`ones`, :obj:`randint`

   .. rubric:: Notes

   Negative strides result in decreasing values. Currently, only int64
   pdarrays can be created with this method. For float64 arrays, use
   the linspace method.

   .. rubric:: Examples

   >>> ak.arange(0, 5, 1)
   array([0, 1, 2, 3, 4])

   >>> ak.arange(5, 0, -1)
   array([5, 4, 3, 2, 1])

   >>> ak.arange(0, 10, 2)
   array([0, 2, 4, 6, 8])

   >>> ak.arange(-5, -10, -1)
   array([-5, -6, -7, -8, -9])


.. py:function:: linspace(start: arkouda.dtypes.numeric_scalars, stop: arkouda.dtypes.numeric_scalars, length: arkouda.dtypes.int_scalars) -> arkouda.pdarrayclass.pdarray

   Create a pdarray of linearly-spaced floats in a closed interval.

   :param start: Start of interval (inclusive)
   :type start: numeric_scalars
   :param stop: End of interval (inclusive)
   :type stop: numeric_scalars
   :param length: Number of points
   :type length: int_scalars

   :returns: Array of evenly spaced float values along the interval
   :rtype: pdarray, float64

   :raises TypeError: Raised if start or stop is not a float or int or if length is not an int

   .. seealso:: :obj:`arange`

   .. rubric:: Notes

   If that start is greater than stop, the pdarray values are generated
   in descending order.

   .. rubric:: Examples

   >>> ak.linspace(0, 1, 5)
   array([0, 0.25, 0.5, 0.75, 1])

   >>> ak.linspace(start=1, stop=0, length=5)
   array([1, 0.75, 0.5, 0.25, 0])

   >>> ak.linspace(start=-5, stop=0, length=5)
   array([-5, -3.75, -2.5, -1.25, 0])


.. py:function:: randint(low: arkouda.dtypes.numeric_scalars, high: arkouda.dtypes.numeric_scalars, size: arkouda.dtypes.int_scalars, dtype=int64, seed: arkouda.dtypes.int_scalars = None) -> arkouda.pdarrayclass.pdarray

   Generate a pdarray of randomized int, float, or bool values in a
   specified range bounded by the low and high parameters.

   :param low: The low value (inclusive) of the range
   :type low: numeric_scalars
   :param high: The high value (exclusive for int, inclusive for float) of the range
   :type high: numeric_scalars
   :param size: The length of the returned array
   :type size: int_scalars
   :param dtype: The dtype of the array
   :type dtype: Union[int64, float64, bool]
   :param seed: Index for where to pull the first returned value
   :type seed: int_scalars

   :returns: Values drawn uniformly from the specified range having the desired dtype
   :rtype: pdarray

   :raises TypeError: Raised if dtype.name not in DTypes, size is not an int, low or high is
       not an int or float, or seed is not an int
   :raises ValueError: Raised if size < 0 or if high < low

   .. rubric:: Notes

   Calling randint with dtype=float64 will result in uniform non-integral
   floating point values.

   Ranges >= 2**64 in size is undefined behavior because
   it exceeds the maximum value that can be stored on the server (uint64)

   .. rubric:: Examples

   >>> ak.randint(0, 10, 5)
   array([5, 7, 4, 8, 3])

   >>> ak.randint(0, 1, 3, dtype=ak.float64)
   array([0.92176432277231968, 0.083130710959903542, 0.68894208386667544])

   >>> ak.randint(0, 1, 5, dtype=ak.bool)
   array([True, False, True, True, True])

   >>> ak.randint(1, 5, 10, seed=2)
   array([4, 3, 1, 3, 4, 4, 2, 4, 3, 2])

   >>> ak.randint(1, 5, 3, dtype=ak.float64, seed=2)
   array([2.9160772326374946, 4.353429832157099, 4.5392023718621486])

   >>> ak.randint(1, 5, 10, dtype=ak.bool, seed=2)
   array([False, True, True, True, True, False, True, True, True, True])


.. py:function:: uniform(size: arkouda.dtypes.int_scalars, low: arkouda.dtypes.numeric_scalars = float(0.0), high: arkouda.dtypes.numeric_scalars = 1.0, seed: Union[None, arkouda.dtypes.int_scalars] = None) -> arkouda.pdarrayclass.pdarray

   Generate a pdarray with uniformly distributed random float values
   in a specified range.

   :param low: The low value (inclusive) of the range, defaults to 0.0
   :type low: float_scalars
   :param high: The high value (inclusive) of the range, defaults to 1.0
   :type high: float_scalars
   :param size: The length of the returned array
   :type size: int_scalars
   :param seed: Value used to initialize the random number generator
   :type seed: int_scalars, optional

   :returns: Values drawn uniformly from the specified range
   :rtype: pdarray, float64

   :raises TypeError: Raised if dtype.name not in DTypes, size is not an int, or if
       either low or high is not an int or float
   :raises ValueError: Raised if size < 0 or if high < low

   .. rubric:: Notes

   The logic for uniform is delegated to the ak.randint method which
   is invoked with a dtype of float64

   .. rubric:: Examples

   >>> ak.uniform(3)
   array([0.92176432277231968, 0.083130710959903542, 0.68894208386667544])

   >>> ak.uniform(size=3,low=0,high=5,seed=0)
   array([0.30013431967121934, 0.47383036230759112, 1.0441791878997098])


.. py:function:: standard_normal(size: arkouda.dtypes.int_scalars, seed: Union[None, arkouda.dtypes.int_scalars] = None) -> arkouda.pdarrayclass.pdarray

   Draw real numbers from the standard normal distribution.

   :param size: The number of samples to draw (size of the returned array)
   :type size: int_scalars
   :param seed: Value used to initialize the random number generator
   :type seed: int_scalars

   :returns: The array of random numbers
   :rtype: pdarray, float64

   :raises TypeError: Raised if size is not an int
   :raises ValueError: Raised if size < 0

   .. seealso:: :obj:`randint`

   .. rubric:: Notes

   For random samples from :math:`N(\mu, \sigma^2)`, use:

   ``(sigma * standard_normal(size)) + mu``

   .. rubric:: Examples

   >>> ak.standard_normal(3,1)
   array([-0.68586185091150265, 1.1723810583573375, 0.567584107142031])


.. py:function:: random_strings_uniform(minlen: arkouda.dtypes.int_scalars, maxlen: arkouda.dtypes.int_scalars, size: arkouda.dtypes.int_scalars, characters: str = 'uppercase', seed: Union[None, arkouda.dtypes.int_scalars] = None) -> arkouda.strings.Strings

   Generate random strings with lengths uniformly distributed between
   minlen and maxlen, and with characters drawn from a specified set.

   :param minlen: The minimum allowed length of string
   :type minlen: int_scalars
   :param maxlen: The maximum allowed length of string
   :type maxlen: int_scalars
   :param size: The number of strings to generate
   :type size: int_scalars
   :param characters: The set of characters to draw from
   :type characters: (uppercase, lowercase, numeric, printable, binary)
   :param seed: Value used to initialize the random number generator
   :type seed: Union[None, int_scalars], optional

   :returns: The array of random strings
   :rtype: Strings

   :raises ValueError: Raised if minlen < 0, maxlen < minlen, or size < 0

   .. seealso:: :obj:`random_strings_lognormal`, :obj:`randint`

   .. rubric:: Examples

   >>> ak.random_strings_uniform(minlen=1, maxlen=5, seed=1, size=5)
   array(['TVKJ', 'EWAB', 'CO', 'HFMD', 'U'])

   >>> ak.random_strings_uniform(minlen=1, maxlen=5, seed=1, size=5,
   ... characters='printable')
   array(['+5"f', '-P]3', '4k', '~HFF', 'F'])


.. py:function:: random_strings_lognormal(logmean: arkouda.dtypes.numeric_scalars, logstd: arkouda.dtypes.numeric_scalars, size: arkouda.dtypes.int_scalars, characters: str = 'uppercase', seed: Optional[arkouda.dtypes.int_scalars] = None) -> arkouda.strings.Strings

   Generate random strings with log-normally distributed lengths and
   with characters drawn from a specified set.

   :param logmean: The log-mean of the length distribution
   :type logmean: numeric_scalars
   :param logstd: The log-standard-deviation of the length distribution
   :type logstd: numeric_scalars
   :param size: The number of strings to generate
   :type size: int_scalars
   :param characters: The set of characters to draw from
   :type characters: (uppercase, lowercase, numeric, printable, binary)
   :param seed: Value used to initialize the random number generator
   :type seed: int_scalars, optional

   :returns: The Strings object encapsulating a pdarray of random strings
   :rtype: Strings

   :raises TypeError: Raised if logmean is neither a float nor a int, logstd is not a float,
       size is not an int, or if characters is not a str
   :raises ValueError: Raised if logstd <= 0 or size < 0

   .. seealso:: :obj:`random_strings_lognormal`, :obj:`randint`

   .. rubric:: Notes

   The lengths of the generated strings are distributed $Lognormal(\mu, \sigma^2)$,
   with :math:`\mu = logmean` and :math:`\sigma = logstd`. Thus, the strings will
   have an average length of :math:`exp(\mu + 0.5*\sigma^2)`, a minimum length of
   zero, and a heavy tail towards longer strings.

   .. rubric:: Examples

   >>> ak.random_strings_lognormal(2, 0.25, 5, seed=1)
   array(['TVKJTE', 'ABOCORHFM', 'LUDMMGTB', 'KWOQNPHZ', 'VSXRRL'])

   >>> ak.random_strings_lognormal(2, 0.25, 5, seed=1, characters='printable')
   array(['+5"fp-', ']3Q4kC~HF', '=F=`,IE!', 'DjkBa'9(', '5oZ1)='])


.. py:function:: from_series(series: pandas.Series, dtype: Optional[Union[type, str]] = None) -> Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]

   Converts a Pandas Series to an Arkouda pdarray or Strings object. If
   dtype is None, the dtype is inferred from the Pandas Series. Otherwise,
   the dtype parameter is set if the dtype of the Pandas Series is to be
   overridden or is  unknown (for example, in situations where the Series
   dtype is object).

   :param series: The Pandas Series with a dtype of bool, float64, int64, or string
   :type series: Pandas Series
   :param dtype: The valid dtype types are np.bool, np.float64, np.int64, and np.str
   :type dtype: Optional[type]

   :rtype: Union[pdarray,Strings]

   :raises TypeError: Raised if series is not a Pandas Series object
   :raises ValueError: Raised if the Series dtype is not bool, float64, int64, string, datetime, or timedelta

   .. rubric:: Examples

   >>> ak.from_series(pd.Series(np.random.randint(0,10,5)))
   array([9, 0, 4, 7, 9])

   >>> ak.from_series(pd.Series(['1', '2', '3', '4', '5']),dtype=np.int64)
   array([1, 2, 3, 4, 5])

   >>> ak.from_series(pd.Series(np.random.uniform(low=0.0,high=1.0,size=3)))
   array([0.57600036956445599, 0.41619265571741659, 0.6615356693784662])

   >>> ak.from_series(pd.Series(['0.57600036956445599', '0.41619265571741659',
                      '0.6615356693784662']), dtype=np.float64)
   array([0.57600036956445599, 0.41619265571741659, 0.6615356693784662])

   >>> ak.from_series(pd.Series(np.random.choice([True, False],size=5)))
   array([True, False, True, True, True])

   >>> ak.from_series(pd.Series(['True', 'False', 'False', 'True', 'True']), dtype=np.bool)
   array([True, True, True, True, True])

   >>> ak.from_series(pd.Series(['a', 'b', 'c', 'd', 'e'], dtype="string"))
   array(['a', 'b', 'c', 'd', 'e'])

   >>> ak.from_series(pd.Series(['a', 'b', 'c', 'd', 'e']),dtype=np.str)
   array(['a', 'b', 'c', 'd', 'e'])

   >>> ak.from_series(pd.Series(pd.to_datetime(['1/1/2018', np.datetime64('2018-01-01')])))
   array([1514764800000000000, 1514764800000000000])

   .. rubric:: Notes

   The supported datatypes are bool, float64, int64, string, and datetime64[ns]. The
   data type is either inferred from the the Series or is set via the dtype parameter.

   Series of datetime or timedelta are converted to Arkouda arrays of dtype int64 (nanoseconds)

   A Pandas Series containing strings has a dtype of object. Arkouda assumes the Series
   contains strings and sets the dtype to str


.. py:function:: ls(filename: str) -> List[str]

   This function calls the h5ls utility on a HDF5 file visible to the
   arkouda server or calls a function that imitates the result of h5ls
   on a Parquet file.

   :param filename: The name of the file to pass to the server
   :type filename: str

   :returns: The string output of the datasets from the server
   :rtype: str

   :raises TypeError: Raised if filename is not a str
   :raises ValueError: Raised if filename is empty or contains only whitespace
   :raises RuntimeError: Raised if error occurs in executing ls on an HDF5 file


.. py:function:: read(filenames: Union[str, List[str]], datasets: Optional[Union[str, List[str]]] = None, iterative: bool = False, strictTypes: bool = True, allow_errors: bool = False, calc_string_offsets=False, file_format: str = 'infer') -> Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, Mapping[str, Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]]

   Read datasets from HDF5 or Parquet files.

   :param filenames: Either a list of filenames or shell expression
   :type filenames: list or str
   :param datasets: (List of) name(s) of dataset(s) to read (default: all available)
   :type datasets: list or str or None
   :param iterative: Iterative (True) or Single (False) function call(s) to server
   :type iterative: bool
   :param strictTypes: If True (default), require all dtypes of a given dataset to have the
                       same precision and sign. If False, allow dtypes of different
                       precision and sign across different files. For example, if one
                       file contains a uint32 dataset and another contains an int64
                       dataset with the same name, the contents of both will be read
                       into an int64 pdarray.
   :type strictTypes: bool
   :param allow_errors: Default False, if True will allow files with read errors to be skipped
                        instead of failing.  A warning will be included in the return containing
                        the total number of files skipped due to failure and up to 10 filenames.
   :type allow_errors: bool
   :param calc_string_offsets: Default False, if True this will tell the server to calculate the
                               offsets/segments array on the server versus loading them from HDF5 files.
                               In the future this option may be set to True as the default.
   :type calc_string_offsets: bool
   :param file_format: Default 'infer', if 'HDF5' or 'Parquet' (case insensitive), the file
                       type checking will be skipped and will execute expecting all files in
                       filenames to be of the specified type. Otherwise, will infer filetype
                       based off of first file in filenames, expanded if a glob expression.
   :type file_format: str

   :returns: * *For a single dataset returns an Arkouda pdarray or Arkouda Strings object*
             * *and for multiple datasets returns a dictionary of Arkouda pdarrays or*
             * *Arkouda Strings.* -- Dictionary of {datasetName: pdarray or String}

   :raises ValueError: Raised if all datasets are not present in all hdf5 files or if one or
       more of the specified files do not exist
   :raises RuntimeError: Raised if one or more of the specified files cannot be opened.
       If `allow_errors` is true this may be raised if no values are returned
       from the server.
   :raises TypeError: Raised if we receive an unknown arkouda_type returned from the server

   .. seealso:: :obj:`read`, :obj:`get_datasets`, :obj:`ls`

   .. rubric:: Notes

   If filenames is a string, it is interpreted as a shell expression
   (a single filename is a valid expression, so it will work) and is
   expanded with glob to read all matching files.

   If iterative == True each dataset name and file names are passed to
   the server as independent sequential strings while if iterative == False
   all dataset names and file names are passed to the server in a single
   string.

   If datasets is None, infer the names of datasets from the first file
   and read all of them. Use ``get_datasets`` to show the names of datasets
   to HDF5 files.


.. py:function:: load(path_prefix: str, file_format: str = 'HDF5', dataset: str = 'array', calc_string_offsets: bool = False) -> Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, Mapping[str, Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]]

   Load a pdarray previously saved with ``pdarray.save()``.

   :param path_prefix: Filename prefix used to save the original pdarray
   :type path_prefix: str
   :param file_format: 'HDF5' or 'Parquet'. Used to indicate the file type being loaded.
   :type file_format: str
   :param dataset: Dataset name where the pdarray was saved, defaults to 'array'
   :type dataset: str
   :param calc_string_offsets: If True the server will ignore Segmented Strings 'offsets' array and derive
                               it from the null-byte terminators.  Defaults to False currently
   :type calc_string_offsets: bool

   :returns: The pdarray or Strings that was previously saved
   :rtype: Union[pdarray, Strings]

   :raises TypeError: Raised if either path_prefix or dataset is not a str
   :raises ValueError: Raised if invalid file_format or if the dataset is not present in all hdf5 files or if the
       path_prefix does not correspond to files accessible to Arkouda
   :raises RuntimeError: Raised if the hdf5 files are present but there is an error in opening
       one or more of them

   .. seealso:: :obj:`save`, :obj:`load_all`, :obj:`read`


.. py:function:: get_datasets(filename: str) -> List[str]

   Get the names of datasets in an HDF5 file.

   :param filename: Name of an HDF5/Parquet file visible to the arkouda server
   :type filename: str

   :returns: Names of the datasets in the file
   :rtype: List[str]

   :raises TypeError: Raised if filename is not a str
   :raises ValueError: Raised if filename is empty or contains only whitespace
   :raises RuntimeError: Raised if error occurs in executing ls on an HDF5 file

   .. seealso:: :obj:`ls`


.. py:function:: load_all(path_prefix: str, file_format: str = 'HDF5') -> Mapping[str, Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, arkouda.categorical.Categorical]]

   Load multiple pdarrays or Strings previously saved with ``save_all()``.

   :param path_prefix: Filename prefix used to save the original pdarray
   :type path_prefix: str
   :param file_format: 'HDF5' or 'Parquet'. Indicates the format being loaded. Used to assign the appropriate file extension.
                       Defaults to 'HDF5'
   :type file_format: str

   :returns: Dictionary of {datsetName: pdarray} with the previously saved pdarrays
   :rtype: Mapping[str,pdarray]

   :raises TypeError:: Raised if path_prefix is not a str
   :raises ValueError: Raised if file_format/extension is encountered that is not hdf5 or parquet or
       if all datasets are not present in all hdf5/parquet files or if the
       path_prefix does not correspond to files accessible to Arkouda
   :raises RuntimeError: Raised if the hdf5 files are present but there is an error in opening
       one or more of them

   .. seealso:: :obj:`save_all`, :obj:`load`, :obj:`read`

   .. rubric:: Notes

   This function has been updated to determine the file extension based on the file format variable


.. py:function:: save_all(columns: Union[Mapping[str, arkouda.pdarrayclass.pdarray], List[arkouda.pdarrayclass.pdarray]], prefix_path: str, names: List[str] = None, file_format='HDF5', mode: str = 'truncate') -> None

   Save multiple named pdarrays to HDF5 files.

   :param columns: Collection of arrays to save
   :type columns: dict or list of pdarrays
   :param prefix_path: Directory and filename prefix for output files
   :type prefix_path: str
   :param names: Dataset names for the pdarrays
   :type names: list of str
   :param file_format: 'HDF5' or 'Parquet'. Defaults to hdf5
   :type file_format: str
   :param mode: By default, truncate (overwrite) the output files if they exist.
                If 'append', attempt to create new dataset in existing files.
   :type mode: {'truncate' | 'append'}

   :rtype: None

   :raises ValueError: Raised if (1) the lengths of columns and values differ or (2) the mode
       is not 'truncate' or 'append'

   .. seealso:: :obj:`save`, :obj:`load_all`

   .. rubric:: Notes

   Creates one file per locale containing that locale's chunk of each pdarray.
   If columns is a dictionary, the keys are used as the HDF5 dataset names.
   Otherwise, if no names are supplied, 0-up integers are used. By default,
   any existing files at path_prefix will be overwritten, unless the user
   specifies the 'append' mode, in which case arkouda will attempt to add
   <columns> as new datasets to existing files. If the wrong number of files
   is present or dataset names already exist, a RuntimeError is raised.


.. py:function:: get_filetype(filenames: Union[str, List[str]]) -> str

   Get the type of a file accessible to the server. Supported
   file types and possible return strings are 'HDF5' and 'Parquet'.

   :param filenames: A file or list of files visible to the arkouda server
   :type filenames: Union[str, List[str]]

   :returns: Type of the file returned as a string, either 'HDF5' or 'Parquet'
   :rtype: str

   :raises ValueError: Raised if filename is empty or contains only whitespace

   .. seealso:: :obj:`read`


.. py:function:: get_null_indices(filenames, datasets) -> Union[arkouda.pdarrayclass.pdarray, Mapping[str, arkouda.pdarrayclass.pdarray]]

   Get null indices of a string column in a Parquet file.

   :param filenames: Either a list of filenames or shell expression
   :type filenames: list or str
   :param datasets: (List of) name(s) of dataset(s) to read. Each dataset must be a string
                    column. There is no default value for this funciton, the datasets to be
                    read must be specified.
   :type datasets: list or str or None

   :returns: * *For a single dataset returns an Arkouda pdarray and for multiple datasets*
             * *returns a dictionary of Arkouda pdarrays* -- Dictionary of {datasetName: pdarray}

   :raises RuntimeError: Raised if one or more of the specified files cannot be opened.
   :raises TypeError: Raised if we receive an unknown arkouda_type returned from the server

   .. seealso:: :obj:`get_datasets`, :obj:`ls`


.. py:function:: unique(pda: groupable, return_groups: bool = False) -> Union[groupable, Tuple[groupable, arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray, int]]

   Find the unique elements of an array.

   Returns the unique elements of an array, sorted if the values are integers.
   There is an optional output in addition to the unique elements: the number
   of times each unique value comes up in the input array.

   :param pda: Input array.
   :type pda: (list of) pdarray, Strings, or Categorical
   :param return_groups: If True, also return grouping information for the array.
   :type return_groups: bool, optional

   :returns: * **unique** (*(list of) pdarray, Strings, or Categorical*) -- The unique values. If input dtype is int64, return values will be sorted.
             * **permutation** (*pdarray, optional*) -- Permutation that groups equivalent values together (only when return_groups=True)
             * **segments** (*pdarray, optional*) -- The offset of each group in the permuted array (only when return_groups=True)

   :raises TypeError: Raised if pda is not a pdarray or Strings object
   :raises RuntimeError: Raised if the pdarray or Strings dtype is unsupported

   .. rubric:: Notes

   For integer arrays, this function checks to see whether `pda` is sorted
   and, if so, whether it is already unique. This step can save considerable
   computation. Otherwise, this function will sort `pda`.

   .. rubric:: Examples

   >>> A = ak.array([3, 2, 1, 1, 2, 3])
   >>> ak.unique(A)
   array([1, 2, 3])


.. py:class:: GroupBy(keys: groupable, assume_sorted: bool = False, hash_strings: bool = True)

   Group an array or list of arrays by value, usually in preparation
   for aggregating the within-group values of another array.

   :param keys: The array to group by value, or if list, the column arrays to group by row
   :type keys: (list of) pdarray, Strings, or Categorical
   :param assume_sorted: If True, assume keys is already sorted (Default: False)
   :type assume_sorted: bool

   .. attribute:: nkeys

      The number of key arrays (columns)

      :type: int

   .. attribute:: size

      The length of the input array(s), i.e. number of rows

      :type: int

   .. attribute:: permutation

      The permutation that sorts the keys array(s) by value (row)

      :type: pdarray

   .. attribute:: unique_keys

      The unique values of the keys array(s), in grouped order

      :type: (list of) pdarray, Strings, or Categorical

   .. attribute:: ngroups

      The length of the unique_keys array(s), i.e. number of groups

      :type: int

   .. attribute:: segments

      The start index of each group in the grouped array(s)

      :type: pdarray

   .. attribute:: logger

      Used for all logging operations

      :type: ArkoudaLogger

   :raises TypeError: Raised if keys is a pdarray with a dtype other than int64

   .. rubric:: Notes

   Integral pdarrays, Strings, and Categoricals are natively supported, but
   float64 and bool arrays are not.

   For a user-defined class to be groupable, it must inherit from pdarray
   and define or overload the grouping API:
     1) a ._get_grouping_keys() method that returns a list of pdarrays
        that can be (co)argsorted.
     2) (Optional) a .group() method that returns the permutation that
        groups the array
   If the input is a single array with a .group() method defined, method 2
   will be used; otherwise, method 1 will be used.

   .. py:attribute:: Reductions
      

      

   .. py:method:: count(self) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Count the number of elements in each group, i.e. the number of times
      each key appears.

      :param none:

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **counts** (*pdarray, int64*) -- The number of times each unique key appears

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 2, 3, 1, 2, 4, 3, 4, 3, 4])
      >>> g = ak.GroupBy(a)
      >>> keys,counts = g.count()
      >>> keys
      array([1, 2, 3, 4])
      >>> counts
      array([1, 2, 4, 3])


   .. py:method:: aggregate(self, values: groupable, operator: str, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group another
      array of values and apply a reduction to each group's values.

      :param values: The values to group and reduce
      :type values: pdarray
      :param operator: The name of the reduction operator to use
      :type operator: str

      :returns: * **unique_keys** (*groupable*) -- The unique keys, in grouped order
                * **aggregates** (*groupable*) -- One aggregate value per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if the requested operator is not supported for the
          values dtype

      .. rubric:: Examples

      >>> keys = ak.arange(0, 10)
      >>> vals = ak.linspace(-1, 1, 10)
      >>> g = ak.GroupBy(keys)
      >>> g.aggregate(vals, 'sum')
      (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([-1, -0.77777777777777768,
      -0.55555555555555536, -0.33333333333333348, -0.11111111111111116,
      0.11111111111111116, 0.33333333333333348, 0.55555555555555536, 0.77777777777777768,
      1]))
      >>> g.aggregate(vals, 'min')
      (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([-1, -0.77777777777777779,
      -0.55555555555555558, -0.33333333333333337, -0.11111111111111116, 0.11111111111111116,
      0.33333333333333326, 0.55555555555555536, 0.77777777777777768, 1]))


   .. py:method:: sum(self, values: arkouda.pdarrayclass.pdarray, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and sum each group's values.

      :param values: The values to group and sum
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_sums** (*pdarray*) -- One sum per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array

      .. rubric:: Notes

      The grouped sum of a boolean ``pdarray`` returns integers.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.sum(b)
      (array([2, 3, 4]), array([8, 14, 6]))


   .. py:method:: prod(self, values: arkouda.pdarrayclass.pdarray, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and compute the product of each group's
      values.

      :param values: The values to group and multiply
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_products** (*pdarray, float64*) -- One product per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object
      :raises ValueError: Raised if the key array size does not match the values size
          or if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if prod is not supported for the values dtype

      .. rubric:: Notes

      The return dtype is always float64.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.prod(b)
      (array([2, 3, 4]), array([12, 108.00000000000003, 8.9999999999999982]))


   .. py:method:: mean(self, values: arkouda.pdarrayclass.pdarray, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and compute the mean of each group's
      values.

      :param values: The values to group and average
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_means** (*pdarray, float64*) -- One mean value per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object
      :raises ValueError: Raised if the key array size does not match the values size
          or if the operator is not in the GroupBy.Reductions array

      .. rubric:: Notes

      The return dtype is always float64.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.mean(b)
      (array([2, 3, 4]), array([2.6666666666666665, 2.7999999999999998, 3]))


   .. py:method:: min(self, values: arkouda.pdarrayclass.pdarray, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the minimum of each group's
      values.

      :param values: The values to group and find minima
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_minima** (*pdarray*) -- One minimum per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if min is
          not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values size
          or if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if min is not supported for the values dtype

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.min(b)
      (array([2, 3, 4]), array([1, 1, 3]))


   .. py:method:: max(self, values: arkouda.pdarrayclass.pdarray, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the maximum of each
      group's values.

      :param values: The values to group and find maxima
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_maxima** (*pdarray*) -- One maximum per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if max is
          not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if max is not supported for the values dtype

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.max(b)
      (array([2, 3, 4]), array([4, 4, 3]))


   .. py:method:: argmin(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the location of the first
      minimum of each group's values.

      :param values: The values to group and find argmin
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_argminima** (*pdarray, int64*) -- One index per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if argmax
          is not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values
          size or if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if argmin is not supported for the values dtype

      .. rubric:: Notes

      The returned indices refer to the original values array as
      passed in, not the permutation applied by the GroupBy instance.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.argmin(b)
      (array([2, 3, 4]), array([5, 4, 2]))


   .. py:method:: argmax(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the location of the first
      maximum of each group's values.

      :param values: The values to group and find argmax
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_argmaxima** (*pdarray, int64*) -- One index per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if argmax
          is not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array

      .. rubric:: Notes

      The returned indices refer to the original values array as passed in,
      not the permutation applied by the GroupBy instance.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.argmax(b)
      (array([2, 3, 4]), array([9, 3, 2]))


   .. py:method:: nunique(self, values: groupable) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group another
      array of values and return the number of unique values in each group.

      :param values: The values to group and find unique values
      :type values: pdarray, int64

      :returns: * **unique_keys** (*groupable*) -- The unique keys, in grouped order
                * **group_nunique** (*groupable*) -- Number of unique values per unique key in the GroupBy instance

      :raises TypeError: Raised if the dtype(s) of values array(s) does/do not support
          the nunique method
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if nunique is not supported for the values dtype

      .. rubric:: Examples

      >>> data = ak.array([3, 4, 3, 1, 1, 4, 3, 4, 1, 4])
      >>> data
      array([3, 4, 3, 1, 1, 4, 3, 4, 1, 4])
      >>> labels = ak.array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4])
      >>> labels
      ak.array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4])
      >>> g = ak.GroupBy(labels)
      >>> g.keys
      ak.array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4])
      >>> g.nunique(data)
      array([1,2,3,4]), array([2, 2, 3, 1])
      #    Group (1,1,1) has values [3,4,3] -> there are 2 unique values 3&4
      #    Group (2,2,2) has values [1,1,4] -> 2 unique values 1&4
      #    Group (3,3,3) has values [3,4,1] -> 3 unique values
      #    Group (4) has values [4] -> 1 unique value


   .. py:method:: any(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[Union[arkouda.pdarrayclass.pdarray, List[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]], arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group another
      array of values and perform an "or" reduction on each group.

      :param values: The values to group and reduce with "or"
      :type values: pdarray, bool

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_any** (*pdarray, bool*) -- One bool per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not bool
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array


   .. py:method:: all(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[Union[arkouda.pdarrayclass.pdarray, List[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]], arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform an "and" reduction on
      each group.

      :param values: The values to group and reduce with "and"
      :type values: pdarray, bool

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_any** (*pdarray, bool*) -- One bool per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not bool
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype


   .. py:method:: OR(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[Union[arkouda.pdarrayclass.pdarray, List[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]], arkouda.pdarrayclass.pdarray]

      Bitwise OR of values in each segment.

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform a bitwise OR reduction on
      each group.

      :param values: The values to group and reduce with OR
      :type values: pdarray, int64

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **result** (*pdarray, int64*) -- Bitwise OR of values in segments corresponding to keys

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not int64
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype


   .. py:method:: AND(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[Union[arkouda.pdarrayclass.pdarray, List[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]], arkouda.pdarrayclass.pdarray]

      Bitwise AND of values in each segment.

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform a bitwise AND reduction on
      each group.

      :param values: The values to group and reduce with AND
      :type values: pdarray, int64

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **result** (*pdarray, int64*) -- Bitwise AND of values in segments corresponding to keys

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not int64
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype


   .. py:method:: XOR(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[Union[arkouda.pdarrayclass.pdarray, List[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]], arkouda.pdarrayclass.pdarray]

      Bitwise XOR of values in each segment.

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform a bitwise XOR reduction on
      each group.

      :param values: The values to group and reduce with XOR
      :type values: pdarray, int64

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **result** (*pdarray, int64*) -- Bitwise XOR of values in segments corresponding to keys

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not int64
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype


   .. py:method:: broadcast(self, values: arkouda.pdarrayclass.pdarray, permute: bool = True) -> arkouda.pdarrayclass.pdarray

      Fill each group's segment with a constant value.

      :param values: The values to put in each group's segment
      :type values: pdarray
      :param permute: If True (default), permute broadcast values back to the ordering
                      of the original array on which GroupBy was called. If False, the
                      broadcast values are grouped by value.
      :type permute: bool

      :returns: The broadcast values
      :rtype: pdarray

      :raises TypeError: Raised if value is not a pdarray object
      :raises ValueError: Raised if the values array does not have one
          value per segment

      .. rubric:: Notes

      This function is a sparse analog of ``np.broadcast``. If a
      GroupBy object represents a sparse matrix (tensor), then
      this function takes a (dense) column vector and replicates
      each value to the non-zero elements in the corresponding row.

      .. rubric:: Examples

      >>> a = ak.array([0, 1, 0, 1, 0])
      >>> values = ak.array([3, 5])
      >>> g = ak.GroupBy(a)
      # By default, result is in original order
      >>> g.broadcast(values)
      array([3, 5, 3, 5, 3])

      # With permute=False, result is in grouped order
      >>> g.broadcast(values, permute=False)
      array([3, 3, 3, 5, 5]

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 1, 4, 4, 4, 1, 3, 3, 2, 2])
      >>> g = ak.GroupBy(a)
      >>> keys,counts = g.count()
      >>> g.broadcast(counts > 2)
      array([True False True True True False True True False False])
      >>> g.broadcast(counts == 3)
      array([True False True True True False True True False False])
      >>> g.broadcast(counts < 4)
      array([True True True True True True True True True True])



.. py:function:: broadcast(segments: arkouda.pdarrayclass.pdarray, values: arkouda.pdarrayclass.pdarray, size: Union[int, numpy.int64, numpy.uint64] = -1, permutation: Union[arkouda.pdarrayclass.pdarray, None] = None)

   Broadcast a dense column vector to the rows of a sparse matrix or grouped array.

   :param segments: Offsets of the start of each row in the sparse matrix or grouped array.
                    Must be sorted in ascending order.
   :type segments: pdarray, int64
   :param values: The values to broadcast, one per row (or group)
   :type values: pdarray
   :param size: The total number of nonzeros in the matrix. If permutation is given, this
                argument is ignored and the size is inferred from the permutation array.
   :type size: int
   :param permutation: The permutation to go from the original ordering of nonzeros to the ordering
                       grouped by row. To broadcast values back to the original ordering, this
                       permutation will be inverted. If no permutation is supplied, it is assumed
                       that the original nonzeros were already grouped by row. In this case, the
                       size argument must be given.
   :type permutation: pdarray, int64

   :returns: The broadcast values, one per nonzero
   :rtype: pdarray

   :raises ValueError: - If segments and values are different sizes
       - If segments are empty
       - If number of nonzeros (either user-specified or inferred from permutation)
         is less than one

   .. rubric:: Examples

   # Define a sparse matrix with 3 rows and 7 nonzeros
   >>> row_starts = ak.array([0, 2, 5])
   >>> nnz = 7
   # Broadcast the row number to each nonzero element
   >>> row_number = ak.arange(3)
   >>> ak.broadcast(row_starts, row_number, nnz)
   array([0 0 1 1 1 2 2])

   # If the original nonzeros were in reverse order...
   >>> permutation = ak.arange(6, -1, -1)
   >>> ak.broadcast(row_starts, row_number, permutation=permutation)
   array([2 2 1 1 1 0 0])


.. py:data:: GROUPBY_REDUCTION_TYPES
   

   

.. py:class:: Strings(strings_pdarray: arkouda.pdarrayclass.pdarray, bytes_size: arkouda.dtypes.int_scalars)

   Represents an array of strings whose data resides on the
   arkouda server. The user should not call this class directly;
   rather its instances are created by other arkouda functions.

   .. attribute:: entry

      Encapsulation of a Segmented Strings array contained on
      the arkouda server.  This is a composite of
       - offsets array: starting indices for each string
       - bytes array: raw bytes of all strings joined by nulls

      :type: pdarray

   .. attribute:: size

      The number of strings in the array

      :type: int_scalars

   .. attribute:: nbytes

      The total number of bytes in all strings

      :type: int_scalars

   .. attribute:: ndim

      The rank of the array (currently only rank 1 arrays supported)

      :type: int_scalars

   .. attribute:: shape

      The sizes of each dimension of the array

      :type: tuple

   .. attribute:: dtype

      The dtype is ak.str

      :type: dtype

   .. attribute:: logger

      Used for all logging operations

      :type: ArkoudaLogger

   .. rubric:: Notes

   Strings is composed of two pdarrays: (1) offsets, which contains the
   starting indices for each string and (2) bytes, which contains the
   raw bytes of all strings, delimited by nulls.

   .. py:attribute:: BinOps
      

      

   .. py:attribute:: objtype
      :annotation: = str

      

   .. py:method:: from_return_msg(rep_msg: str) -> Strings
      :staticmethod:

      Factory method for creating a Strings object from an Arkouda server
      response message

      :param rep_msg: Server response message currently of form
                      `created name type size ndim shape itemsize+created bytes.size 1234`
      :type rep_msg: str

      :returns: object representing a segmented strings array on the server
      :rtype: Strings

      :raises RuntimeError: Raised if there's an error converting a server-returned str-descriptor

      .. rubric:: Notes

      We really don't have an itemsize because these are variable length strings.
      In the future we could probably use this position to store the total bytes.


   .. py:method:: from_parts(offset_attrib: Union[arkouda.pdarrayclass.pdarray, str], bytes_attrib: Union[arkouda.pdarrayclass.pdarray, str]) -> Strings
      :staticmethod:

      Factory method for creating a Strings object from an Arkouda server
      response where the arrays are separate components.

      :param offset_attrib: the array containing the offsets
      :type offset_attrib: Union[pdarray, str]
      :param bytes_attrib: the array containing the string values
      :type bytes_attrib: Union[pdarray, str]

      :returns: object representing a segmented strings array on the server
      :rtype: Strings

      :raises RuntimeError: Raised if there's an error converting a server-returned str-descriptor

      .. rubric:: Notes

      This factory method is used when we construct the parts of a Strings
      object on the client side and transfer the offsets & bytes separately
      to the server.  This results in two entries in the symbol table and we
      need to instruct the server to assemble the into a composite entity.


   .. py:method:: __iter__(self)
      :abstractmethod:


   .. py:method:: __len__(self) -> int


   .. py:method:: __str__(self) -> str

      Return str(self).


   .. py:method:: __repr__(self) -> str

      Return repr(self).


   .. py:method:: _binop(self, other: Union[Strings, arkouda.dtypes.str_scalars], op: str) -> arkouda.pdarrayclass.pdarray

      Executes the requested binop on this Strings instance and the
      parameter Strings object and returns the results within
      a pdarray object.

      :param other: the other object is a Strings object
      :type other: Strings, str_scalars
      :param op: name of the binary operation to be performed
      :type op: str

      :returns: encapsulating the results of the requested binop
      :rtype: pdarray

      :raises ValueError: Raised if (1) the op is not in the self.BinOps set, or (2) if the
          sizes of this and the other instance don't match, or (3) the other
          object is not a Strings object
      :raises RuntimeError: Raised if a server-side error is thrown while executing the
          binary operation


   .. py:method:: __eq__(self, other) -> bool

      Return self==value.


   .. py:method:: __ne__(self, other) -> bool

      Return self!=value.


   .. py:method:: __getitem__(self, key)


   .. py:method:: get_lengths(self) -> arkouda.pdarrayclass.pdarray

      Return the length of each string in the array.

      :returns: The length of each string
      :rtype: pdarray, int

      :raises RuntimeError: Raised if there is a server-side error thrown


   .. py:method:: to_lower(self) -> Strings

      Returns a new Strings with all uppercase characters from the original replaced with their lowercase equivalent

      :returns: Strings with all uppercase characters from the original replaced with their lowercase equivalent
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.to_upper`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS {i}' for i in range(5)])
      >>> strings
      array(['StrINgS 0', 'StrINgS 1', 'StrINgS 2', 'StrINgS 3', 'StrINgS 4'])
      >>> strings.to_lower()
      array(['strings 0', 'strings 1', 'strings 2', 'strings 3', 'strings 4'])


   .. py:method:: to_upper(self) -> Strings

      Returns a new Strings with all lowercase characters from the original replaced with their uppercase equivalent

      :returns: Strings with all lowercase characters from the original replaced with their uppercase equivalent
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.to_lower`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS {i}' for i in range(5)])
      >>> strings
      array(['StrINgS 0', 'StrINgS 1', 'StrINgS 2', 'StrINgS 3', 'StrINgS 4'])
      >>> strings.to_upper()
      array(['STRINGS 0', 'STRINGS 1', 'STRINGS 2', 'STRINGS 3', 'STRINGS 4'])


   .. py:method:: is_lower(self) -> arkouda.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the Strings is entirely lowercase

      :returns: True for elements that are entirely lowercase, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.is_upper`

      .. rubric:: Examples

      >>> lower = ak.array([f'strings {i}' for i in range(3)])
      >>> upper = ak.array([f'STRINGS {i}' for i in range(3)])
      >>> strings = ak.concatenate([lower, upper])
      >>> strings
      array(['strings 0', 'strings 1', 'strings 2', 'STRINGS 0', 'STRINGS 1', 'STRINGS 2'])
      >>> strings.is_lower()
      array([True True True False False False])


   .. py:method:: is_upper(self) -> arkouda.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the Strings is entirely uppercase

      :returns: True for elements that are entirely uppercase, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.is_lower`

      .. rubric:: Examples

      >>> lower = ak.array([f'strings {i}' for i in range(3)])
      >>> upper = ak.array([f'STRINGS {i}' for i in range(3)])
      >>> strings = ak.concatenate([lower, upper])
      >>> strings
      array(['strings 0', 'strings 1', 'strings 2', 'STRINGS 0', 'STRINGS 1', 'STRINGS 2'])
      >>> strings.is_upper()
      array([False False False True True True])


   .. py:method:: cached_regex_patterns(self) -> List

      Returns the regex patterns for which Match objects have been cached


   .. py:method:: purge_cached_regex_patterns(self) -> None

      purges cached regex patterns


   .. py:method:: _get_matcher(self, pattern: Union[bytes, arkouda.dtypes.str_scalars], create: bool = True)

      internal function to fetch cached Matcher objects


   .. py:method:: find_locations(self, pattern: Union[bytes, arkouda.dtypes.str_scalars]) -> Tuple[arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray]

      Finds pattern matches and returns pdarrays containing the number, start postitions, and lengths of matches

      :param pattern: The regex pattern used to find matches
      :type pattern: str_scalars

      :returns: * *pdarray, int64* -- For each original string, the number of pattern matches
                * *pdarray, int64* -- The start positons of pattern matches
                * *pdarray, int64* -- The lengths of pattern matches

      :raises TypeError: Raised if the pattern parameter is not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.findall`, :obj:`Strings.match`

      .. rubric:: Examples

      >>> strings = ak.array(['{} string {}'.format(i, i) for i in range(1, 6)])
      >>> num_matches, starts, lens = strings.find_locations('\d')
      >>> num_matches
      array([2, 2, 2, 2, 2])
      >>> starts
      array([0, 9, 0, 9, 0, 9, 0, 9, 0, 9])
      >>> lens
      array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))


   .. py:method:: search(self, pattern: Union[bytes, arkouda.dtypes.str_scalars]) -> arkouda.match.Match

      Returns a match object with the first location in each element where pattern produces a match.
      Elements match if any part of the string matches the regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: str

      :returns: Match object where elements match if any part of the string matches the regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.search('_+')
      <ak.Match object: matched=True, span=(1, 2); matched=True, span=(0, 4); matched=False; matched=True, span=(0, 2); matched=False>


   .. py:method:: match(self, pattern: Union[bytes, arkouda.dtypes.str_scalars]) -> arkouda.match.Match

      Returns a match object where elements match only if the beginning of the string matches the regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: str

      :returns: Match object where elements match only if the beginning of the string matches the regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.match('_+')
      <ak.Match object: matched=False; matched=True, span=(0, 4); matched=False; matched=True, span=(0, 2); matched=False>


   .. py:method:: fullmatch(self, pattern: Union[bytes, arkouda.dtypes.str_scalars]) -> arkouda.match.Match

      Returns a match object where elements match only if the whole string matches the regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: str

      :returns: Match object where elements match only if the whole string matches the regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.fullmatch('_+')
      <ak.Match object: matched=False; matched=True, span=(0, 4); matched=False; matched=False; matched=False>


   .. py:method:: split(self, pattern: Union[bytes, arkouda.dtypes.str_scalars], maxsplit: int = 0, return_segments: bool = False) -> Union[Strings, Tuple]

      Returns a new Strings split by the occurrences of pattern. If maxsplit is nonzero, at most maxsplit splits occur

      :param pattern: Regex used to split strings into substrings
      :type pattern: str
      :param maxsplit: The max number of pattern match occurences in each element to split.
                       The default maxsplit=0 splits on all occurences
      :type maxsplit: int
      :param return_segments: If True, return mapping of original strings to first substring
                              in return array.
      :type return_segments: bool

      :returns: * *Strings* -- Substrings with pattern matches removed
                * *pdarray, int64 (optional)* -- For each original string, the index of first corresponding substring
                  in the return array

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.split('_+', maxsplit=2, return_segments=True)
      (array(['1', '2', '', '', '', '3', '', '4', '5____6___7', '']), array([0 3 5 6 9]))


   .. py:method:: findall(self, pattern: Union[bytes, arkouda.dtypes.str_scalars], return_match_origins: bool = False) -> Union[Strings, Tuple]

      Return a new Strings containg all non-overlapping matches of pattern

      :param pattern: Regex used to find matches
      :type pattern: str_scalars
      :param return_match_origins: If True, return a pdarray containing the index of the original string each pattern match is from
      :type return_match_origins: bool

      :returns: * *Strings* -- Strings object containing only pattern matches
                * *pdarray, int64 (optional)* -- The index of the original string each pattern match is from

      :raises TypeError: Raised if the pattern parameter is not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.find_locations`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.findall('_+', return_match_origins=True)
      (array(['_', '___', '____', '__', '___', '____', '___']), array([0 0 1 3 3 3 3]))


   .. py:method:: sub(self, pattern: Union[bytes, arkouda.dtypes.str_scalars], repl: Union[bytes, arkouda.dtypes.str_scalars], count: int = 0) -> Strings

      Return new Strings obtained by replacing non-overlapping occurrences of pattern with the replacement repl.
      If count is nonzero, at most count substitutions occur

      :param pattern: The regex to substitue
      :type pattern: str_scalars
      :param repl: The substring to replace pattern matches with
      :type repl: str_scalars
      :param count: The max number of pattern match occurences in each element to replace.
                    The default count=0 replaces all occurences of pattern with repl
      :type count: int

      :returns: Strings with pattern matches replaced
      :rtype: Strings

      :raises TypeError: Raised if pattern or repl are not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.subn`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.sub(pattern='_+', repl='-', count=2)
      array(['1-2-', '-', '3', '-4-5____6___7', ''])


   .. py:method:: subn(self, pattern: Union[bytes, arkouda.dtypes.str_scalars], repl: Union[bytes, arkouda.dtypes.str_scalars], count: int = 0) -> Tuple

      Perform the same operation as sub(), but return a tuple (new_Strings, number_of_substitions)

      :param pattern: The regex to substitue
      :type pattern: str_scalars
      :param repl: The substring to replace pattern matches with
      :type repl: str_scalars
      :param count: The max number of pattern match occurences in each element to replace.
                    The default count=0 replaces all occurences of pattern with repl
      :type count: int

      :returns: * *Strings* -- Strings with pattern matches replaced
                * *pdarray, int64* -- The number of substitutions made for each element of Strings

      :raises TypeError: Raised if pattern or repl are not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.sub`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.subn(pattern='_+', repl='-', count=2)
      (array(['1-2-', '-', '3', '-4-5____6___7', '']), array([2 1 0 2 0]))


   .. py:method:: contains(self, substr: Union[bytes, arkouda.dtypes.str_scalars], regex: bool = False) -> arkouda.pdarrayclass.pdarray

      Check whether each element contains the given substring.

      :param substr: The substring in the form of string or byte array to search for
      :type substr: str_scalars
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2 (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: True for elements that contain substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not bytes or str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.startswith`, :obj:`Strings.endswith`

      .. rubric:: Examples

      >>> strings = ak.array(['{} string {}'.format(i, i) for i in range(1, 6)])
      >>> strings
      array(['1 string 1', '2 string 2', '3 string 3', '4 string 4', '5 string 5'])
      >>> strings.contains('string')
      array([True, True, True, True, True])
      >>> strings.contains('string \d', regex=True)
      array([True, True, True, True, True])


   .. py:method:: startswith(self, substr: Union[bytes, arkouda.dtypes.str_scalars], regex: bool = False) -> arkouda.pdarrayclass.pdarray

      Check whether each element starts with the given substring.

      :param substr: The prefix to search for
      :type substr: Union[bytes, str_scalars]
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2 (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: True for elements that start with substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not a bytes ior str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.contains`, :obj:`Strings.endswith`

      .. rubric:: Examples

      >>> strings_end = ak.array(['string {}'.format(i) for i in range(1, 6)])
      >>> strings_end
      array(['string 1', 'string 2', 'string 3', 'string 4', 'string 5'])
      >>> strings_end.startswith('string')
      array([True, True, True, True, True])
      >>> strings_start = ak.array(['{} string'.format(i) for i in range(1,6)])
      >>> strings_start
      array(['1 string', '2 string', '3 string', '4 string', '5 string'])
      >>> strings_start.startswith('\d str', regex = True)
      array([True, True, True, True, True])


   .. py:method:: endswith(self, substr: Union[bytes, arkouda.dtypes.str_scalars], regex: bool = False) -> arkouda.pdarrayclass.pdarray

      Check whether each element ends with the given substring.

      :param substr: The suffix to search for
      :type substr: Union[bytes, str_scalars]
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2 (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: True for elements that end with substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not bytes or str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.contains`, :obj:`Strings.startswith`

      .. rubric:: Examples

      >>> strings_start = ak.array(['{} string'.format(i) for i in range(1,6)])
      >>> strings_start
      array(['1 string', '2 string', '3 string', '4 string', '5 string'])
      >>> strings_start.endswith('ing')
      array([True, True, True, True, True])
      >>> strings_end = ak.array(['string {}'.format(i) for i in range(1, 6)])
      >>> strings_end
      array(['string 1', 'string 2', 'string 3', 'string 4', 'string 5'])
      >>> strings_end.endswith('ing \d', regex = True)
      array([True, True, True, True, True])


   .. py:method:: flatten(self, delimiter: str, return_segments: bool = False, regex: bool = False) -> Union[Strings, Tuple]

      Unpack delimiter-joined substrings into a flat array.

      :param delimiter: Characters used to split strings into substrings
      :type delimiter: str
      :param return_segments: If True, also return mapping of original strings to first substring
                              in return array.
      :type return_segments: bool
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2 (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: * *Strings* -- Flattened substrings with delimiters removed
                * *pdarray, int64 (optional)* -- For each original string, the index of first corresponding substring
                  in the return array

      .. seealso:: :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> orig = ak.array(['one|two', 'three|four|five', 'six'])
      >>> orig.flatten('|')
      array(['one', 'two', 'three', 'four', 'five', 'six'])
      >>> flat, map = orig.flatten('|', return_segments=True)
      >>> map
      array([0, 2, 5])
      >>> under = ak.array(['one_two', 'three_____four____five', 'six'])
      >>> under_flat, under_map = under.flatten('_+', return_segments=True, regex=True)
      >>> under_flat
      array(['one', 'two', 'three', 'four', 'five', 'six'])
      >>> under_map
      array([0, 2, 5])


   .. py:method:: peel(self, delimiter: Union[bytes, arkouda.dtypes.str_scalars], times: arkouda.dtypes.int_scalars = 1, includeDelimiter: bool = False, keepPartial: bool = False, fromRight: bool = False, regex: bool = False) -> Tuple

      Peel off one or more delimited fields from each string (similar
      to string.partition), returning two new arrays of strings.
      *Warning*: This function is experimental and not guaranteed to work.

      :param delimiter: The separator where the split will occur
      :type delimiter: Union[bytes, str_scalars]
      :param times: The number of times the delimiter is sought, i.e. skip over
                    the first (times-1) delimiters
      :type times: Union[int, np.int64]
      :param includeDelimiter: If true, append the delimiter to the end of the first return
                               array. By default, it is prepended to the beginning of the
                               second return array.
      :type includeDelimiter: bool
      :param keepPartial: If true, a string that does not contain <times> instances of
                          the delimiter will be returned in the first array. By default,
                          such strings are returned in the second array.
      :type keepPartial: bool
      :param fromRight: If true, peel from the right instead of the left (see also rpeel)
      :type fromRight: bool
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2 (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns:

                left: Strings
                    The field(s) peeled from the end of each string (unless
                    fromRight is true)
                right: Strings
                    The remainder of each string after peeling (unless fromRight
                    is true)
      :rtype: Tuple[Strings, Strings]

      :raises TypeError: Raised if the delimiter parameter is not byte or str_scalars, if
          times is not int64, or if includeDelimiter, keepPartial, or
          fromRight is not bool
      :raises ValueError: Raised if times is < 1 or if delimiter is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`rpeel`, :obj:`stick`, :obj:`lstick`

      .. rubric:: Examples

      >>> s = ak.array(['a.b', 'c.d', 'e.f.g'])
      >>> s.peel('.')
      (array(['a', 'c', 'e']), array(['b', 'd', 'f.g']))
      >>> s.peel('.', includeDelimiter=True)
      (array(['a.', 'c.', 'e.']), array(['b', 'd', 'f.g']))
      >>> s.peel('.', times=2)
      (array(['', '', 'e.f']), array(['a.b', 'c.d', 'g']))
      >>> s.peel('.', times=2, keepPartial=True)
      (array(['a.b', 'c.d', 'e.f']), array(['', '', 'g']))


   .. py:method:: rpeel(self, delimiter: Union[bytes, arkouda.dtypes.str_scalars], times: arkouda.dtypes.int_scalars = 1, includeDelimiter: bool = False, keepPartial: bool = False, regex: bool = False)

      Peel off one or more delimited fields from the end of each string
      (similar to string.rpartition), returning two new arrays of strings.
      *Warning*: This function is experimental and not guaranteed to work.

      :param delimiter: The separator where the split will occur
      :type delimiter: Union[bytes, str_scalars]
      :param times: The number of times the delimiter is sought, i.e. skip over
                    the last (times-1) delimiters
      :type times: Union[int, np.int64]
      :param includeDelimiter: If true, prepend the delimiter to the start of the first return
                               array. By default, it is appended to the end of the
                               second return array.
      :type includeDelimiter: bool
      :param keepPartial: If true, a string that does not contain <times> instances of
                          the delimiter will be returned in the second array. By default,
                          such strings are returned in the first array.
      :type keepPartial: bool
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2 (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns:

                left: Strings
                    The remainder of the string after peeling
                right: Strings
                    The field(s) that were peeled from the right of each string
      :rtype: Tuple[Strings, Strings]

      :raises TypeError: Raised if the delimiter parameter is not bytes or str_scalars or
          if times is not int64
      :raises ValueError: Raised if times is < 1 or if delimiter is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`peel`, :obj:`stick`, :obj:`lstick`

      .. rubric:: Examples

      >>> s = ak.array(['a.b', 'c.d', 'e.f.g'])
      >>> s.rpeel('.')
      (array(['a', 'c', 'e.f']), array(['b', 'd', 'g']))
      # Compared against peel
      >>> s.peel('.')
      (array(['a', 'c', 'e']), array(['b', 'd', 'f.g']))


   .. py:method:: stick(self, other: Strings, delimiter: Union[bytes, arkouda.dtypes.str_scalars] = '', toLeft: bool = False) -> Strings

      Join the strings from another array onto one end of the strings
      of this array, optionally inserting a delimiter.
      *Warning*: This function is experimental and not guaranteed to work.

      :param other: The strings to join onto self's strings
      :type other: Strings
      :param delimiter: String inserted between self and other
      :type delimiter: str
      :param toLeft: If true, join other strings to the left of self. By default,
                     other is joined to the right of self.
      :type toLeft: bool

      :returns: The array of joined strings
      :rtype: Strings

      :raises TypeError: Raised if the delimiter parameter is not bytes or str_scalars
          or if the other parameter is not a Strings instance
      :raises ValueError: Raised if times is < 1
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`lstick`, :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> s = ak.array(['a', 'c', 'e'])
      >>> t = ak.array(['b', 'd', 'f'])
      >>> s.stick(t, delimiter='.')
      array(['a.b', 'c.d', 'e.f'])


   .. py:method:: __add__(self, other: Strings) -> Strings


   .. py:method:: lstick(self, other: Strings, delimiter: Union[bytes, arkouda.dtypes.str_scalars] = '') -> Strings

      Join the strings from another array onto the left of the strings
      of this array, optionally inserting a delimiter.
      *Warning*: This function is experimental and not guaranteed to work.

      :param other: The strings to join onto self's strings
      :type other: Strings
      :param delimiter: String inserted between self and other
      :type delimiter: Union[bytes,str_scalars]

      :returns: The array of joined strings, as other + self
      :rtype: Strings

      :raises TypeError: Raised if the delimiter parameter is neither bytes nor a str
          or if the other parameter is not a Strings instance
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`stick`, :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> s = ak.array(['a', 'c', 'e'])
      >>> t = ak.array(['b', 'd', 'f'])
      >>> s.lstick(t, delimiter='.')
      array(['b.a', 'd.c', 'f.e'])


   .. py:method:: __radd__(self, other: Strings) -> Strings


   .. py:method:: hash(self) -> Tuple[arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray]

      Compute a 128-bit hash of each string.

      :returns: A tuple of two int64 pdarrays. The ith hash value is the concatenation
                of the ith values from each array.
      :rtype: Tuple[pdarray,pdarray]

      .. rubric:: Notes

      The implementation uses SipHash128, a fast and balanced hash function (used
      by Python for dictionaries and sets). For realistic numbers of strings (up
      to about 10**15), the probability of a collision between two 128-bit hash
      values is negligible.


   .. py:method:: group(self) -> arkouda.pdarrayclass.pdarray

      Return the permutation that groups the array, placing equivalent
      strings together. All instances of the same string are guaranteed to lie
      in one contiguous block of the permuted array, but the blocks are not
      necessarily ordered.

      :returns: The permutation that groups the array by value
      :rtype: pdarray

      .. seealso:: :obj:`GroupBy`, :obj:`unique`

      .. rubric:: Notes

      If the arkouda server is compiled with "-sSegmentedArray.useHash=true",
      then arkouda uses 128-bit hash values to group strings, rather than sorting
      the strings directly. This method is fast, but the resulting permutation
      merely groups equivalent strings and does not sort them. If the "useHash"
      parameter is false, then a full sort is performed.

      :raises RuntimeError: Raised if there is a server-side error in executing group request or
          creating the pdarray encapsulating the return message


   .. py:method:: _get_grouping_keys(self) -> List[arkouda.pdarrayclass.pdarray]

      Private method for generating grouping keys used by GroupBy.

      API: this method must be defined by all groupable arrays, and it
      must return a list of arrays that can be (co)argsorted.


   .. py:method:: to_ndarray(self) -> numpy.ndarray

      Convert the array to a np.ndarray, transferring array data from the
      arkouda server to Python. If the array exceeds a built-in size limit,
      a RuntimeError is raised.

      :returns: A numpy ndarray with the same strings as this array
      :rtype: np.ndarray

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``arkouda.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting ak.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`

      .. rubric:: Examples

      >>> a = ak.array(["hello", "my", "world"])
      >>> a.to_ndarray()
      array(['hello', 'my', 'world'], dtype='<U5')
      >>> type(a.to_ndarray())
      numpy.ndarray


   .. py:method:: _comp_to_ndarray(self, comp: str) -> numpy.ndarray

      This is an internal helper function to perform the to_ndarray for one
      of the string components.

      :param comp: The strings component to request
      :type comp: str

      :returns: A numpy ndarray with the same attributes and data as the pdarray
      :rtype: np.ndarray

      :raises RuntimeError: Raised if there is a server-side error thrown, if the pdarray size
          exceeds the built-in client.maxTransferBytes size limit, or if the bytes
          received does not match expected number of bytes

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.


   .. py:method:: astype(self, dtype) -> arkouda.pdarrayclass.pdarray

      Cast values of Strings object to provided dtype

      :param dtype: Dtype to cast to
      :type dtype: np.dtype or str

      :returns: An arkouda pdarray with values converted to the specified data type
      :rtype: ak.pdarray

      .. rubric:: Notes

      This is essentially shorthand for ak.cast(x, '<dtype>') where x is a pdarray.


   .. py:method:: save(self, prefix_path: str, dataset: str = 'strings_array', mode: str = 'truncate', save_offsets: bool = True, compressed: bool = False, file_format: str = 'HDF5') -> str

      Save the Strings object to HDF5 or Parquet. The result is a collection of
      files, one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the Strings array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: The name of the Strings dataset to be written, defaults to strings_array
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Strings dataset within existing files.
      :type mode: str {'truncate' | 'append'}
      :param save_offsets: Defaults to True which will instruct the server to save the offsets array to HDF5
                           If False the offsets array will not be save and will be derived from the string values
                           upon load/read. This is not supported for Parquet files.
      :type save_offsets: bool
      :param compressed: Defaults to False. When True, files will be written with Snappy compression
                         and RLE bit packing. This is currently only supported on Parquet files and will
                         not impact the generated files when writing HDF5 files.
      :type compressed: bool
      :param file_format: By default, saved files will be written to the HDF5 file format. If
                          'Parquet', the files will be written to the Parquet file format. This
                          is case insensitive.
      :type file_format: str

      :rtype: String message indicating result of save operation

      :raises ValueError: Raised if the lengths of columns and values differ, or the mode is
          neither 'truncate' nor 'append'
      :raises TypeError: Raised if prefix_path, dataset, or mode is not a str

      .. seealso:: :obj:`pdarrayIO.save`

      .. rubric:: Notes

      Important implementation notes: (1) Strings state is saved as two datasets
      within an hdf5 group: one for the string characters and one for the
      segments corresponding to the start of each string, (2) the hdf5 group is named
      via the dataset parameter.


   .. py:method:: save_parquet(self, prefix_path: str, dataset: str = 'strings_array', mode: str = 'truncate', compressed: bool = False) -> str

      Save the Strings object to Parquet. The result is a collection of Parquet files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the Strings array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: The name of the Strings dataset to be written, defaults to strings_array
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Strings dataset within existing files.
      :type mode: str {'truncate' | 'append'}
      :param compressed: Defaults to False. When True, files will be written with Snappy compression
                         and RLE bit packing.
      :type compressed: bool

      :rtype: String message indicating result of save operation

      :raises ValueError: Raised if the lengths of columns and values differ, or the mode is
          neither 'truncate' nor 'append'
      :raises TypeError: Raised if prefix_path, dataset, or mode is not a str

      .. seealso:: :obj:`strings.save`, :obj:`pdarray.save_parquet`


   .. py:method:: save_hdf(self, prefix_path: str, dataset: str = 'strings_array', mode: str = 'truncate', save_offsets: bool = True) -> str

      Save the Strings object to HDF5. The result is a collection of HDF5 files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the Strings array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: The name of the Strings dataset to be written, defaults to strings_array
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Strings dataset within existing files.
      :type mode: str {'truncate' | 'append'}
      :param save_offsets: Defaults to True which will instruct the server to save the offsets array to HDF5
                           If False the offsets array will not be save and will be derived from the string values
                           upon load/read.
      :type save_offsets: bool

      :rtype: String message indicating result of save operation

      :raises ValueError: Raised if the lengths of columns and values differ, or the mode is
          neither 'truncate' nor 'append'
      :raises TypeError: Raised if prefix_path, dataset, or mode is not a str

      .. seealso:: :obj:`strings.save`, :obj:`pdarray.save`


   .. py:method:: is_registered(self) -> numpy.bool_

      Return True iff the object is contained in the registry

      :param None:

      :returns: Indicates if the object is contained in the registry
      :rtype: bool

      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: _list_component_names(self) -> List[str]

      Internal Function that returns a list of all component names

      :param None:

      :returns: List of all component names
      :rtype: List[str]


   .. py:method:: info(self) -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str


   .. py:method:: pretty_print_info(self) -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None


   .. py:method:: register(self, user_defined_name: str) -> Strings

      Register this Strings object with a user defined name in the arkouda server
      so it can be attached to later using Strings.attach()
      This is an in-place operation, registering a Strings object more than once will
      update the name in the registry and remove the previously registered name.
      A name can only be registered to one object at a time.

      :param user_defined_name: user defined name which the Strings object is to be registered under
      :type user_defined_name: str

      :returns: The same Strings object which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support a fluid programming style.
                Please note you cannot register two different objects with the same name.
      :rtype: Strings

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the Strings object with the user_defined_name
          If the user is attempting to register more than one object with the same name, the former should be
          unregistered first to free up the registration name.

      .. seealso:: :obj:`attach`, :obj:`unregister`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion
      until they are unregistered.


   .. py:method:: unregister(self) -> None

      Unregister a Strings object in the arkouda server which was previously
      registered using register() and/or attached to using attach()


      :rtype: None

      :raises RuntimeError: Raised if the server could not find the internal name/symbol to remove

      .. seealso:: :obj:`register`, :obj:`attach`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion until
      they are unregistered.


   .. py:method:: attach(user_defined_name: str) -> Strings
      :staticmethod:

      class method to return a Strings object attached to the registered name in the arkouda
      server which was registered using register()

      :param user_defined_name: user defined name which the Strings object was registered under
      :type user_defined_name: str

      :returns: the Strings object registered with user_defined_name in the arkouda server
      :rtype: Strings object

      :raises TypeError: Raised if user_defined_name is not a str

      .. seealso:: :obj:`register`, :obj:`unregister`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion
      until they are unregistered.


   .. py:method:: unregister_strings_by_name(user_defined_name: str) -> None
      :staticmethod:

      Unregister a Strings object in the arkouda server previously registered via register()

      :param user_defined_name: The registered name of the Strings object
      :type user_defined_name: str

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`attach`, :obj:`is_registered`



.. py:function:: join_on_eq_with_dt(a1: arkouda.pdarrayclass.pdarray, a2: arkouda.pdarrayclass.pdarray, t1: arkouda.pdarrayclass.pdarray, t2: arkouda.pdarrayclass.pdarray, dt: Union[int, numpy.int64], pred: str, result_limit: Union[int, numpy.int64] = 1000) -> Tuple[arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray]

   Performs an inner-join on equality between two integer arrays where
   the time-window predicate is also true

   :param a1: pdarray to be joined
   :type a1: pdarray, int64
   :param a2: pdarray to be joined
   :type a2: pdarray, int64
   :param t1: timestamps in millis corresponding to the a1 pdarray
   :type t1: pdarray
   :param t2: timestamps in millis corresponding to the a2 pdarray
   :type t2: pdarray,
   :param dt: time delta
   :type dt: Union[int,np.int64]
   :param pred: time window predicate
   :type pred: str
   :param result_limit: size limit for returned result
   :type result_limit: Union[int,np.int64]

   :returns: * **result_array_one** (*pdarray, int64*) -- a1 indices where a1 == a2
             * **result_array_one** (*pdarray, int64*) -- a2 indices where a2 == a1

   :raises TypeError: Raised if a1, a2, t1, or t2 is not a pdarray, or if dt or
       result_limit is not an int
   :raises ValueError: if a1, a2, t1, or t2 dtype is not int64, pred is not
       'true_dt', 'abs_dt', or 'pos_dt', or result_limit is < 0


.. py:class:: Categorical(values, **kwargs)

   Represents an array of values belonging to named categories. Converting a
   Strings object to Categorical often saves memory and speeds up operations,
   especially if there are many repeated values, at the cost of some one-time
   work in initialization.

   :param values: String values to convert to categories
   :type values: Strings
   :param NAvalue: The value to use to represent missing/null data
   :type NAvalue: str scalar

   .. attribute:: categories

      The set of category labels (determined automatically)

      :type: Strings

   .. attribute:: codes

      The category indices of the values or -1 for N/A

      :type: pdarray, int64

   .. attribute:: permutation

      The permutation that groups the values in the same order as categories

      :type: pdarray, int64

   .. attribute:: segments

      When values are grouped, the starting offset of each group

      :type: pdarray, int64

   .. attribute:: size

      The number of items in the array

      :type: Union[int,np.int64]

   .. attribute:: nlevels

      The number of distinct categories

      :type: Union[int,np.int64]

   .. attribute:: ndim

      The rank of the array (currently only rank 1 arrays supported)

      :type: Union[int,np.int64]

   .. attribute:: shape

      The sizes of each dimension of the array

      :type: tuple

   .. py:attribute:: BinOps
      

      

   .. py:attribute:: RegisterablePieces
      

      

   .. py:attribute:: RequiredPieces
      

      

   .. py:attribute:: objtype
      :annotation: = category

      

   .. py:attribute:: permutation
      

      

   .. py:attribute:: segments
      

      

   .. py:method:: from_codes(cls, codes: arkouda.pdarrayclass.pdarray, categories: arkouda.strings.Strings, permutation=None, segments=None, **kwargs) -> Categorical
      :classmethod:

      Make a Categorical from codes and categories arrays. If codes and
      categories have already been pre-computed, this constructor saves
      time. If not, please use the normal constructor.

      :param codes: Category indices of each value
      :type codes: pdarray, int64
      :param categories: Unique category labels
      :type categories: Strings
      :param permutation: The permutation that groups the values in the same order
                          as categories
      :type permutation: pdarray, int64
      :param segments: When values are grouped, the starting offset of each group
      :type segments: pdarray, int64

      :returns: The Categorical object created from the input parameters
      :rtype: Categorical

      :raises TypeError: Raised if codes is not a pdarray of int64 objects or if
          categories is not a Strings object


   .. py:method:: standardize_categories(cls, arrays, NAvalue='N/A')
      :classmethod:

      Standardize an array of Categoricals so that they share the same categories.

      :param arrays: The Categoricals to standardize
      :type arrays: sequence of Categoricals
      :param NAvalue: The value to use to represent missing/null data
      :type NAvalue: str scalar

      :returns: A list of the original Categoricals remapped to the shared categories.
      :rtype: List of Categoricals


   .. py:method:: set_categories(self, new_categories, NAvalue=None)

      Set categories to user-defined values.

      :param new_categories: The array of new categories to use. Must be unique.
      :type new_categories: Strings
      :param NAvalue: The value to use to represent missing/null data
      :type NAvalue: str scalar

      :returns: A new Categorical with the user-defined categories. Old values present
                in new categories will appear unchanged. Old values not present will
                be assigned the NA value.
      :rtype: Categorical


   .. py:method:: to_ndarray(self) -> numpy.ndarray

      Convert the array to a np.ndarray, transferring array data from
      the arkouda server to Python. This conversion discards category
      information and produces an ndarray of strings. If the arrays
      exceeds a built-in size limit, a RuntimeError is raised.

      :returns: A numpy ndarray of strings corresponding to the values in
                this array
      :rtype: np.ndarray

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``arkouda.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting ak.maxTransferBytes to a larger
      value, but proceed with caution.


   .. py:method:: __iter__(self)
      :abstractmethod:


   .. py:method:: __len__(self)


   .. py:method:: __str__(self)

      Return str(self).


   .. py:method:: __repr__(self)

      Return repr(self).


   .. py:method:: _binop(self, other: Union[Categorical, arkouda.dtypes.str_scalars], op: arkouda.dtypes.str_scalars) -> arkouda.pdarrayclass.pdarray

      Executes the requested binop on this Categorical instance and returns
      the results within a pdarray object.

      :param other: the other object is a Categorical object or string scalar
      :type other: Union[Categorical,str_scalars]
      :param op: name of the binary operation to be performed
      :type op: str_scalars

      :returns: encapsulating the results of the requested binop
      :rtype: pdarray

      :raises ValueError: Raised if (1) the op is not in the self.BinOps set, or (2) if the
          sizes of this and the other instance don't match
      :raises RuntimeError: Raised if a server-side error is thrown while executing the
          binary operation


   .. py:method:: _r_binop(self, other: Union[Categorical, arkouda.dtypes.str_scalars], op: arkouda.dtypes.str_scalars) -> arkouda.pdarrayclass.pdarray

          Executes the requested reverse binop on this Categorical instance and
          returns the results within a pdarray object.

          Parameters
          ----------
          other : Union[Categorical,str_scalars]
              the other object is a Categorical object or string scalar
          op : str_scalars
              name of the binary operation to be performed

          Returns
          -------
          pdarray
              encapsulating the results of the requested binop

          Raises
      -   -----
          ValueError
              Raised if (1) the op is not in the self.BinOps set, or (2) if the
              sizes of this and the other instance don't match
          RuntimeError
              Raised if a server-side error is thrown while executing the
              binary operation



   .. py:method:: __eq__(self, other)

      Return self==value.


   .. py:method:: __ne__(self, other)

      Return self!=value.


   .. py:method:: __getitem__(self, key) -> Categorical


   .. py:method:: isna(self)

      Find where values are missing or null (as defined by self.NAvalue)


   .. py:method:: reset_categories(self) -> Categorical

      Recompute the category labels, discarding any unused labels. This
      method is often useful after slicing or indexing a Categorical array,
      when the resulting array only contains a subset of the original
      categories. In this case, eliminating unused categories can speed up
      other operations.

      :returns: A Categorical object generated from the current instance
      :rtype: Categorical


   .. py:method:: contains(self, substr: str) -> arkouda.pdarrayclass.pdarray

      Check whether each element contains the given substring.

      :param substr: The substring to search for
      :type substr: str

      :returns: True for elements that contain substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if substr is not a str

      .. rubric:: Notes

      This method can be significantly faster than the corresponding method
      on Strings objects, because it searches the unique category labels
      instead of the full array.

      .. seealso:: :obj:`Categorical.startswith`, :obj:`Categorical.endswith`


   .. py:method:: startswith(self, substr: str) -> arkouda.pdarrayclass.pdarray

      Check whether each element starts with the given substring.

      :param substr: The substring to search for
      :type substr: str

      :raises TypeError: Raised if substr is not a str

      :returns: True for elements that contain substr, False otherwise
      :rtype: pdarray, bool

      .. rubric:: Notes

      This method can be significantly faster than the corresponding
      method on Strings objects, because it searches the unique category
      labels instead of the full array.

      .. seealso:: :obj:`Categorical.contains`, :obj:`Categorical.endswith`


   .. py:method:: endswith(self, substr: str) -> arkouda.pdarrayclass.pdarray

      Check whether each element ends with the given substring.

      :param substr: The substring to search for
      :type substr: str

      :raises TypeError: Raised if substr is not a str

      :returns: True for elements that contain substr, False otherwise
      :rtype: pdarray, bool

      .. rubric:: Notes

      This method can be significantly faster than the corresponding method
      on Strings objects, because it searches the unique category labels
      instead of the full array.

      .. seealso:: :obj:`Categorical.startswith`, :obj:`Categorical.contains`


   .. py:method:: in1d(self, test: Union[arkouda.strings.Strings, Categorical]) -> arkouda.pdarrayclass.pdarray

      Test whether each element of the Categorical object is
      also present in the test Strings or Categorical object.

      Returns a boolean array the same length as `self` that is True
      where an element of `self` is in `test` and False otherwise.

      :param test: The values against which to test each value of 'self`.
      :type test: Union[Strings,Categorical]

      :returns: The values `self[in1d]` are in the `test` Strings or Categorical object.
      :rtype: pdarray, bool

      :raises TypeError: Raised if test is not a Strings or Categorical object

      .. seealso:: :obj:`unique`, :obj:`intersect1d`, :obj:`union1d`

      .. rubric:: Notes

      `in1d` can be considered as an element-wise function version of the
      python keyword `in`, for 1-D sequences. ``in1d(a, b)`` is logically
      equivalent to ``ak.array([item in b for item in a])``, but is much
      faster and scales to arbitrarily large ``a``.

      .. rubric:: Examples

      >>> strings = ak.array(['String {}'.format(i) for i in range(0,5)])
      >>> cat = ak.Categorical(strings)
      >>> ak.in1d(cat,strings)
      array([True, True, True, True, True])
      >>> strings = ak.array(['String {}'.format(i) for i in range(5,9)])
      >>> catTwo = ak.Categorical(strings)
      >>> ak.in1d(cat,catTwo)
      array([False, False, False, False, False])


   .. py:method:: unique(self) -> Categorical


   .. py:method:: group(self) -> arkouda.pdarrayclass.pdarray

      Return the permutation that groups the array, placing equivalent
      categories together. All instances of the same category are guaranteed
      to lie in one contiguous block of the permuted array, but the blocks
      are not necessarily ordered.

      :returns: The permutation that groups the array by value
      :rtype: pdarray

      .. seealso:: :obj:`GroupBy`, :obj:`unique`

      .. rubric:: Notes

      This method is faster than the corresponding Strings method. If the
      Categorical was created from a Strings object, then this function
      simply returns the cached permutation. Even if the Categorical was
      created using from_codes(), this function will be faster than
      Strings.group() because it sorts dense integer values, rather than
      128-bit hash values.


   .. py:method:: _get_grouping_keys(self)

      Private method for generating grouping keys used by GroupBy.

      API: this method must be defined by all groupable arrays, and it
      must return a list of arrays that can be (co)argsorted.


   .. py:method:: argsort(self)


   .. py:method:: sort(self)


   .. py:method:: concatenate(self, others: Sequence[Categorical], ordered: bool = True) -> Categorical

      Merge this Categorical with other Categorical objects in the array,
      concatenating the arrays and synchronizing the categories.

      :param others: The Categorical arrays to concatenate and merge with this one
      :type others: Sequence[Categorical]
      :param ordered: If True (default), the arrays will be appended in the
                      order given. If False, array data may be interleaved
                      in blocks, which can greatly improve performance but
                      results in non-deterministic ordering of elements.
      :type ordered: bool

      :returns: The merged Categorical object
      :rtype: Categorical

      :raises TypeError: Raised if any others array objects are not Categorical objects

      .. rubric:: Notes

      This operation can be expensive -- slower than concatenating Strings.


   .. py:method:: save(self, prefix_path: str, dataset: str = 'categorical_array', file_format: str = 'HDF5', mode: str = 'truncate') -> str

      Save the Categorical object to HDF5. The result is a collection of HDF5 files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path and dataset. Each locale saves its chunk of the Strings array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in HDF5 files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Categorical dataset within existing files.
      :type mode: str {'truncate' | 'append'}

      :rtype: String message indicating result of save operation

      :raises ValueError: Raised if the lengths of columns and values differ, or the mode is
          neither 'truncate' nor 'append'
      :raises TypeError: Raised if prefix_path, dataset, or mode is not a str

      .. seealso:: :obj:`pdarrayIO.save`, :obj:`pdarrayIO.load_all`

      .. rubric:: Notes

      Important implementation notes: (1) Strings state is saved as two datasets
      within an hdf5 group: one for the string characters and one for the
      segments corresponding to the start of each string, (2) the hdf5 group is named
      via the dataset parameter.


   .. py:method:: register(self, user_defined_name: str) -> Categorical

      Register this Categorical object and underlying components with the Arkouda server

      :param user_defined_name: user defined name the Categorical is to be registered under,
                                this will be the root name for underlying components
      :type user_defined_name: str

      :returns: The same Categorical which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support a fluid programming style.
                Please note you cannot register two different Categoricals with the same name.
      :rtype: Categorical

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the Categorical with the user_defined_name

      .. seealso:: :obj:`unregister`, :obj:`attach`, :obj:`unregister_categorical_by_name`, :obj:`is_registered`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.


   .. py:method:: unregister(self) -> None

      Unregister this Categorical object in the arkouda server which was previously
      registered using register() and/or attached to using attach()

      :raises RegistrationError: If the object is already unregistered or if there is a server error
          when attempting to unregister

      .. seealso:: :obj:`register`, :obj:`attach`, :obj:`unregister_categorical_by_name`, :obj:`is_registered`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.


   .. py:method:: is_registered(self) -> numpy.bool_

       Return True iff the object is contained in the registry

      :returns: Indicates if the object is contained in the registry
      :rtype: numpy.bool

      :raises RegistrationError: Raised if there's a server-side error or a mis-match of registered components

      .. seealso:: :obj:`register`, :obj:`attach`, :obj:`unregister`, :obj:`unregister_categorical_by_name`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.


   .. py:method:: _get_components_dict(self) -> Dict

      Internal function that returns a dictionary with all required or non-None components of self

      Required Categorical components (Codes and Categories) are always included in returned components_dict
      Optional Categorical components (Permutation and Segments) are only included if they've been set (are not None)

      :returns:

                Dictionary of all required or non-None components of self
                    Keys: component names (Codes, Categories, Permutation, Segments)
                    Values: components of self
      :rtype: Dict


   .. py:method:: _list_component_names(self) -> List[str]

      Internal function that returns a list of all component names

      :param None:

      :returns: List of all component names
      :rtype: List[str]


   .. py:method:: info(self) -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str


   .. py:method:: pretty_print_info(self) -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None


   .. py:method:: attach(user_defined_name: str) -> Categorical
      :staticmethod:

       Function to return a Categorical object attached to the registered name in the
       arkouda server which was registered using register()

       Parameters
       ----------
       user_defined_name : str
           user defined name which Categorical object was registered under

       Returns
       -------
       Categorical
              The Categorical object created by re-attaching to the corresponding server components

      :raises TypeError:     if user_defined_name is not a string
          
          .. seealso:: :obj:`register`, :obj:`is_registered`, :obj:`unregister`, :obj:`unregister_categorical_by_name`


   .. py:method:: unregister_categorical_by_name(user_defined_name: str) -> None
      :staticmethod:

      Function to unregister Categorical object by name which was registered
      with the arkouda server via register()

      :param user_defined_name: Name under which the Categorical object was registered
      :type user_defined_name: str

      :raises TypeError: if user_defined_name is not a string
      :raises RegistrationError: if there is an issue attempting to unregister any underlying components

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`attach`, :obj:`is_registered`


   .. py:method:: parse_hdf_categoricals(d: Mapping[str, Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]) -> Tuple[List[str], Dict[str, Categorical]]
      :staticmethod:

      This function should be used in conjunction with the load_all function which reads hdf5 files and reconstitutes
      Categorical objects.  Categorical objects use a naming convention and HDF5 structure so they can be identified
      and constructed for the user.

      In general you should not call this method directly

      :param d:
      :type d: Dictionary of String to either Pdarray or Strings object

      :returns: * *2-Tuple of List of strings containing key names which should be removed and Dictionary of base name to*
                * *Categorical object*

      .. seealso:: :obj:`Categorical.save`, :obj:`load_all`



.. py:function:: enableVerbose() -> None

   Enables verbose logging (DEBUG log level) for all ArkoudaLoggers


.. py:function:: disableVerbose(logLevel: LogLevel = LogLevel.INFO) -> None

   Disables verbose logging (DEBUG log level) for all ArkoudaLoggers, setting
   the log level for each to the logLevel parameter

   :param logLevel: The new log level, defaultts to LogLevel.INFO
   :type logLevel: LogLevel

   :raises TypeError: Raised if logLevel is not a LogLevel enum


.. py:class:: pdarray(name: str, mydtype: numpy.dtype, size: arkouda.dtypes.int_scalars, ndim: arkouda.dtypes.int_scalars, shape: Sequence[int], itemsize: arkouda.dtypes.int_scalars)

   The basic arkouda array class. This class contains only the
   attributies of the array; the data resides on the arkouda
   server. When a server operation results in a new array, arkouda
   will create a pdarray instance that points to the array data on
   the server. As such, the user should not initialize pdarray
   instances directly.

   .. attribute:: name

      The server-side identifier for the array

      :type: str

   .. attribute:: dtype

      The element type of the array

      :type: dtype

   .. attribute:: size

      The number of elements in the array

      :type: int_scalars

   .. attribute:: ndim

      The rank of the array (currently only rank 1 arrays supported)

      :type: int_scalars

   .. attribute:: shape

      A list or tuple containing the sizes of each dimension of the array

      :type: Sequence[int]

   .. attribute:: itemsize

      The size in bytes of each element

      :type: int_scalars

   .. py:attribute:: BinOps
      

      

   .. py:attribute:: OpEqOps
      

      

   .. py:attribute:: objtype
      :annotation: = pdarray

      

   .. py:attribute:: __array_priority__
      :annotation: = 1000

      

   .. py:method:: __del__(self)


   .. py:method:: __bool__(self) -> bool


   .. py:method:: __len__(self)


   .. py:method:: __str__(self)

      Return str(self).


   .. py:method:: __repr__(self)

      Return repr(self).


   .. py:method:: format_other(self, other: object) -> str

      Attempt to cast scalar other to the element dtype of this pdarray,
      and print the resulting value to a string (e.g. for sending to a
      server command). The user should not call this function directly.

      :param other: The scalar to be cast to the pdarray.dtype
      :type other: object

      :rtype: string representation of np.dtype corresponding to the other parameter

      :raises TypeError: Raised if the other parameter cannot be converted to
          Numpy dtype


   .. py:method:: _binop(self, other: pdarray, op: str) -> pdarray

      Executes binary operation specified by the op string

      :param other: The pdarray upon which the binop is to be executed
      :type other: pdarray
      :param op: The binop to be executed
      :type op: str

      :returns: A pdarray encapsulating the binop result
      :rtype: pdarray

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set, or if the
          pdarray sizes don't match
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype


   .. py:method:: _r_binop(self, other: pdarray, op: str) -> pdarray

      Executes reverse binary operation specified by the op string

      :param other: The pdarray upon which the reverse binop is to be executed
      :type other: pdarray
      :param op: The name of the reverse binop to be executed
      :type op: str

      :returns: A pdarray encapsulating the reverse binop result
      :rtype: pdarray

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype


   .. py:method:: __add__(self, other)


   .. py:method:: __radd__(self, other)


   .. py:method:: __sub__(self, other)


   .. py:method:: __rsub__(self, other)


   .. py:method:: __mul__(self, other)


   .. py:method:: __rmul__(self, other)


   .. py:method:: __truediv__(self, other)


   .. py:method:: __rtruediv__(self, other)


   .. py:method:: __floordiv__(self, other)


   .. py:method:: __rfloordiv__(self, other)


   .. py:method:: __mod__(self, other)


   .. py:method:: __rmod__(self, other)


   .. py:method:: __lshift__(self, other)


   .. py:method:: __rlshift__(self, other)


   .. py:method:: __rshift__(self, other)


   .. py:method:: __rrshift__(self, other)


   .. py:method:: __and__(self, other)


   .. py:method:: __rand__(self, other)


   .. py:method:: __or__(self, other)


   .. py:method:: __ror__(self, other)


   .. py:method:: __xor__(self, other)


   .. py:method:: __rxor__(self, other)


   .. py:method:: __pow__(self, other)


   .. py:method:: __rpow__(self, other)


   .. py:method:: __lt__(self, other)

      Return self<value.


   .. py:method:: __gt__(self, other)

      Return self>value.


   .. py:method:: __le__(self, other)

      Return self<=value.


   .. py:method:: __ge__(self, other)

      Return self>=value.


   .. py:method:: __eq__(self, other)

      Return self==value.


   .. py:method:: __ne__(self, other)

      Return self!=value.


   .. py:method:: __neg__(self)


   .. py:method:: __invert__(self)


   .. py:method:: opeq(self, other, op)


   .. py:method:: __iadd__(self, other)


   .. py:method:: __isub__(self, other)


   .. py:method:: __imul__(self, other)


   .. py:method:: __itruediv__(self, other)


   .. py:method:: __ifloordiv__(self, other)


   .. py:method:: __ilshift__(self, other)


   .. py:method:: __irshift__(self, other)


   .. py:method:: __iand__(self, other)


   .. py:method:: __ior__(self, other)


   .. py:method:: __ixor__(self, other)


   .. py:method:: __ipow__(self, other)


   .. py:method:: __iter__(self)
      :abstractmethod:


   .. py:method:: __getitem__(self, key)


   .. py:method:: __setitem__(self, key, value)


   .. py:method:: fill(self, value: arkouda.dtypes.numeric_scalars) -> None

      Fill the array (in place) with a constant value.

      :param value:
      :type value: numeric_scalars

      :raises TypeError: Raised if value is not an int, int64, float, or float64


   .. py:method:: any(self) -> numpy.bool_

      Return True iff any element of the array evaluates to True.


   .. py:method:: all(self) -> numpy.bool_

      Return True iff all elements of the array evaluate to True.


   .. py:method:: is_registered(self) -> numpy.bool_

      Return True iff the object is contained in the registry

      :param None:

      :returns: Indicates if the object is contained in the registry
      :rtype: bool

      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: _list_component_names(self) -> List[str]

      Internal Function that returns a list of all component names

      :param None:

      :returns: List of all component names
      :rtype: List[str]


   .. py:method:: info(self) -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str


   .. py:method:: pretty_print_info(self) -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None


   .. py:method:: is_sorted(self) -> numpy.bool_

      Return True iff the array is monotonically non-decreasing.

      :param None:

      :returns: Indicates if the array is monotonically non-decreasing
      :rtype: bool

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: sum(self) -> arkouda.dtypes.numeric_and_bool_scalars

      Return the sum of all elements in the array.


   .. py:method:: prod(self) -> numpy.float64

      Return the product of all elements in the array. Return value is
      always a np.float64 or np.int64.


   .. py:method:: min(self) -> arkouda.dtypes.numpy_scalars

      Return the minimum value of the array.


   .. py:method:: max(self) -> arkouda.dtypes.numpy_scalars

      Return the maximum value of the array.


   .. py:method:: argmin(self) -> numpy.int64

      Return the index of the first occurrence of the array min value


   .. py:method:: argmax(self) -> numpy.int64

      Return the index of the first occurrence of the array max value.


   .. py:method:: mean(self) -> numpy.float64

      Return the mean of the array.


   .. py:method:: var(self, ddof: arkouda.dtypes.int_scalars = 0) -> numpy.float64

      Compute the variance. See ``arkouda.var`` for details.

      :param ddof: "Delta Degrees of Freedom" used in calculating var
      :type ddof: int_scalars

      :returns: The scalar variance of the array
      :rtype: np.float64

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises ValueError: Raised if the ddof >= pdarray size
      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: std(self, ddof: arkouda.dtypes.int_scalars = 0) -> numpy.float64

      Compute the standard deviation. See ``arkouda.std`` for details.

      :param ddof: "Delta Degrees of Freedom" used in calculating std
      :type ddof: int_scalars

      :returns: The scalar standard deviation of the array
      :rtype: np.float64

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: mink(self, k: arkouda.dtypes.int_scalars) -> pdarray

      Compute the minimum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: The maximum `k` values from pda
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray


   .. py:method:: maxk(self, k: arkouda.dtypes.int_scalars) -> pdarray

      Compute the maximum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: The maximum `k` values from pda
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray


   .. py:method:: argmink(self, k: arkouda.dtypes.int_scalars) -> pdarray

      Compute the minimum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: Indices corresponding to the maximum `k` values from pda
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray


   .. py:method:: argmaxk(self, k: arkouda.dtypes.int_scalars) -> pdarray

      Finds the indices corresponding to the maximum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: Indices corresponding to the  maximum `k` values, sorted
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray


   .. py:method:: popcount(self) -> pdarray

      Find the population (number of bits set) in each element. See `ak.popcount`.


   .. py:method:: parity(self) -> pdarray

      Find the parity (XOR of all bits) in each element. See `ak.parity`.


   .. py:method:: clz(self) -> pdarray

      Count the number of leading zeros in each element. See `ak.clz`.


   .. py:method:: ctz(self) -> pdarray

      Count the number of trailing zeros in each element. See `ak.ctz`.


   .. py:method:: rotl(self, other) -> pdarray

      Rotate bits left by <other>.


   .. py:method:: rotr(self, other) -> pdarray

      Rotate bits right by <other>.


   .. py:method:: astype(self, dtype) -> pdarray

      Cast values of pdarray to provided dtype

      :param dtype: Dtype to cast to
      :type dtype: np.dtype or str

      :returns: An arkouda pdarray with values converted to the specified data type
      :rtype: ak.pdarray

      .. rubric:: Notes

      This is essentially shorthand for ak.cast(x, '<dtype>') where x is a pdarray.


   .. py:method:: reshape(self, *shape, order='row_major')

      Gives a new shape to an array without changing its data.

      :param shape: The new shape should be compatible with the original shape.
      :type shape: int, tuple of ints, or pdarray
      :param order: Read the elements of the pdarray in this index order
                    By default, read the elements in row_major or C-like order where the last index changes the fastest
                    If 'column_major' or 'F', read the elements in column_major or Fortran-like order where the first index changes the fastest
      :type order: str {'row_major' | 'C' | 'column_major' | 'F'}

      :returns: An arrayview object with the data from the array but with the new shape
      :rtype: ArrayView


   .. py:method:: to_ndarray(self) -> numpy.ndarray

      Convert the array to a np.ndarray, transferring array data from the
      Arkouda server to client-side Python. Note: if the pdarray size exceeds
      client.maxTransferBytes, a RuntimeError is raised.

      :returns: A numpy ndarray with the same attributes and data as the pdarray
      :rtype: np.ndarray

      :raises RuntimeError: Raised if there is a server-side error thrown, if the pdarray size
          exceeds the built-in client.maxTransferBytes size limit, or if the bytes
          received does not match expected number of bytes

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_ndarray()
      array([0, 1, 2, 3, 4])

      >>> type(a.to_ndarray())
      numpy.ndarray


   .. py:method:: to_cuda(self)

      Convert the array to a Numba DeviceND array, transferring array data from the
      arkouda server to Python via ndarray. If the array exceeds a builtin size limit,
      a RuntimeError is raised.

      :returns: A Numba ndarray with the same attributes and data as the pdarray; on GPU
      :rtype: numba.DeviceNDArray

      :raises ImportError: Raised if CUDA is not available
      :raises ModuleNotFoundError: Raised if Numba is either not installed or not enabled
      :raises RuntimeError: Raised if there is a server-side error thrown in the course of retrieving
          the pdarray.

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_cuda()
      array([0, 1, 2, 3, 4])

      >>> type(a.to_cuda())
      numpy.devicendarray


   .. py:method:: save(self, prefix_path: str, dataset: str = 'array', mode: str = 'truncate', compressed: bool = False, file_format: str = 'HDF5') -> str

      Save the pdarray to HDF5 or Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param compressed: Defaults to False. When True, files will be written with Snappy compression
                         and RLE bit packing. This is currently only supported on Parquet files and will
                         not impact the generated files when writing HDF5 files.
      :type compressed: bool
      :param file_format: By default, saved files will be written to the HDF5 file format. If
                          'Parquet', the files will be written to the Parquet file format. This
                          is case insensitive.
      :type file_format: str {'HDF5', 'Parquet'}

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray
      :raises ValueError: Raised if there is an error in parsing the prefix path pointing to
          file write location or if the mode parameter is neither truncate
          nor append
      :raises TypeError: Raised if any one of the prefix_path, dataset, or mode parameters
          is not a string

      .. seealso:: :obj:`save_all`, :obj:`load`, :obj:`read`

      .. rubric:: Notes

      The prefix_path must be visible to the arkouda server and the user must
      have write permission.

      Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales``. If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.

      .. rubric:: Examples

      >>> a = ak.arange(0, 100, 1)
      >>> a.save('arkouda_range', dataset='array')
      >>> a.save('arkouda_range_parquet', dataset='array', file_format='Parquet')

      Array is saved in numLocales files with names like ``tmp/arkouda_range_LOCALE0``

      The array can be read back in as follows

      >>> b = ak.read('arkouda_range', dataset='array')
      >>> (a == b).all()
      True

      >>> c = ak.read_parquet('arkouda_range_parquet*')
      >>> (c == b).all()
      True


   .. py:method:: save_parquet(self, prefix_path: str, dataset: str = 'array', mode: str = 'truncate', compressed: bool = False) -> str

      Save the pdarray to Parquet. The result is a collection of Parquet files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in Parquet files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
      :type mode: str {'truncate', 'append'}
      :param compressed: By default, write without Snappy compression and RLE encoding.
      :type compressed: bool

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray
      :raises ValueError: Raised if there is an error in parsing the prefix path pointing to
          file write location or if the mode parameter is neither truncate
          nor append
      :raises TypeError: Raised if any one of the prefix_path, dataset, or mode parameters
          is not a string

      .. seealso:: :obj:`save`, :obj:`save_all`, :obj:`load`, :obj:`read`

      .. rubric:: Notes

      The prefix_path must be visible to the arkouda server and the user must
      have write permission.

      Output files have names of the form ``<prefix_path>_LOCALE<i>.parquet``, where ``<i>``
      ranges from 0 to ``numLocales``. If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.

      .. rubric:: Examples

      >>> a = ak.arange(0, 100, 1)
      >>> a.save_parquet('arkouda_range')

      Array is saved in numLocales files with names like ``arkouda_range_LOCALE0000.parquet``

      The array can be read back in as follows

      >>> b = ak.read('arkouda_range')
      >>> (a == b).all()
      True


   .. py:method:: save_hdf(self, prefix_path: str, dataset: str = 'array', mode: str = 'truncate') -> str

      Save the pdarray to HDF5. The result is a collection of HDF5 files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in HDF5 files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
      :type mode: str {'truncate', 'append'}
      :param compressed: By default, write without Snappy compression and RLE encoding.
      :type compressed: bool

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray
      :raises ValueError: Raised if there is an error in parsing the prefix path pointing to
          file write location or if the mode parameter is neither truncate
          nor append
      :raises TypeError: Raised if any one of the prefix_path, dataset, or mode parameters
          is not a string

      .. seealso:: :obj:`save`, :obj:`save_all`, :obj:`load`, :obj:`read`

      .. rubric:: Notes

      The prefix_path must be visible to the arkouda server and the user must
      have write permission.

      Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales``. If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.

      .. rubric:: Examples

      >>> a = ak.arange(0, 100, 1)
      >>> a.save_hdf('arkouda_range')

      Array is saved in numLocales files with names like ``arkouda_range_LOCALE0000``

      The array can be read back in as follows

      >>> b = ak.read('arkouda_range')
      >>> (a == b).all()
      True


   .. py:method:: register(self, user_defined_name: str) -> pdarray

      Register this pdarray with a user defined name in the arkouda server
      so it can be attached to later using pdarray.attach()
      This is an in-place operation, registering a pdarray more than once will
      update the name in the registry and remove the previously registered name.
      A name can only be registered to one pdarray at a time.

      :param user_defined_name: user defined name array is to be registered under
      :type user_defined_name: str

      :returns: The same pdarray which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support a fluid programming style.
                Please note you cannot register two different pdarrays with the same name.
      :rtype: pdarray

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the pdarray with the user_defined_name
          If the user is attempting to register more than one pdarray with the same name, the former should be
          unregistered first to free up the registration name.

      .. seealso:: :obj:`attach`, :obj:`unregister`, :obj:`is_registered`, :obj:`list_registry`, :obj:`unregister_pdarray_by_name`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion
      until they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()


   .. py:method:: unregister(self) -> None

      Unregister a pdarray in the arkouda server which was previously
      registered using register() and/or attahced to using attach()


      :rtype: None

      :raises RuntimeError: Raised if the server could not find the internal name/symbol to remove

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion until
      they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()


   .. py:method:: attach(user_defined_name: str) -> pdarray
      :staticmethod:

      class method to return a pdarray attached to the registered name in the arkouda
      server which was registered using register()

      :param user_defined_name: user defined name which array was registered under
      :type user_defined_name: str

      :returns: pdarray which is bound to corresponding server side component that was registered with user_defined_name
      :rtype: pdarray

      :raises TypeError: Raised if user_defined_name is not a str

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion
      until they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()


   .. py:method:: _get_grouping_keys(self) -> List[pdarray]

      Private method for generating grouping keys used by GroupBy.

      API: this method must be defined by all groupable arrays, and it
      must return a list of arrays that can be (co)argsorted.



.. py:data:: int64
   

   

.. py:data:: intTypes
   

   

.. py:function:: isSupportedInt(num)


.. py:function:: from_series(series: pandas.Series, dtype: Optional[Union[type, str]] = None) -> Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]

   Converts a Pandas Series to an Arkouda pdarray or Strings object. If
   dtype is None, the dtype is inferred from the Pandas Series. Otherwise,
   the dtype parameter is set if the dtype of the Pandas Series is to be
   overridden or is  unknown (for example, in situations where the Series
   dtype is object).

   :param series: The Pandas Series with a dtype of bool, float64, int64, or string
   :type series: Pandas Series
   :param dtype: The valid dtype types are np.bool, np.float64, np.int64, and np.str
   :type dtype: Optional[type]

   :rtype: Union[pdarray,Strings]

   :raises TypeError: Raised if series is not a Pandas Series object
   :raises ValueError: Raised if the Series dtype is not bool, float64, int64, string, datetime, or timedelta

   .. rubric:: Examples

   >>> ak.from_series(pd.Series(np.random.randint(0,10,5)))
   array([9, 0, 4, 7, 9])

   >>> ak.from_series(pd.Series(['1', '2', '3', '4', '5']),dtype=np.int64)
   array([1, 2, 3, 4, 5])

   >>> ak.from_series(pd.Series(np.random.uniform(low=0.0,high=1.0,size=3)))
   array([0.57600036956445599, 0.41619265571741659, 0.6615356693784662])

   >>> ak.from_series(pd.Series(['0.57600036956445599', '0.41619265571741659',
                      '0.6615356693784662']), dtype=np.float64)
   array([0.57600036956445599, 0.41619265571741659, 0.6615356693784662])

   >>> ak.from_series(pd.Series(np.random.choice([True, False],size=5)))
   array([True, False, True, True, True])

   >>> ak.from_series(pd.Series(['True', 'False', 'False', 'True', 'True']), dtype=np.bool)
   array([True, True, True, True, True])

   >>> ak.from_series(pd.Series(['a', 'b', 'c', 'd', 'e'], dtype="string"))
   array(['a', 'b', 'c', 'd', 'e'])

   >>> ak.from_series(pd.Series(['a', 'b', 'c', 'd', 'e']),dtype=np.str)
   array(['a', 'b', 'c', 'd', 'e'])

   >>> ak.from_series(pd.Series(pd.to_datetime(['1/1/2018', np.datetime64('2018-01-01')])))
   array([1514764800000000000, 1514764800000000000])

   .. rubric:: Notes

   The supported datatypes are bool, float64, int64, string, and datetime64[ns]. The
   data type is either inferred from the the Series or is set via the dtype parameter.

   Series of datetime or timedelta are converted to Arkouda arrays of dtype int64 (nanoseconds)

   A Pandas Series containing strings has a dtype of object. Arkouda assumes the Series
   contains strings and sets the dtype to str


.. py:function:: ak_array(a: Union[arkouda.pdarrayclass.pdarray, numpy.ndarray, Iterable], dtype: Union[numpy.dtype, type, str] = None) -> Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]

   Convert a Python or Numpy Iterable to a pdarray or Strings object, sending
   the corresponding data to the arkouda server.

   :param a: Rank-1 array of a supported dtype
   :type a: Union[pdarray, np.ndarray]
   :param dtype: The target dtype to cast values to
   :type dtype: np.dtype, type, or str

   :returns: A pdarray instance stored on arkouda server or Strings instance, which
             is composed of two pdarrays stored on arkouda server
   :rtype: pdarray or Strings

   :raises TypeError: Raised if a is not a pdarray, np.ndarray, or Python Iterable such as a
       list, array, tuple, or deque
   :raises RuntimeError: Raised if a is not one-dimensional, nbytes > maxTransferBytes, a.dtype is
       not supported (not in DTypes), or if the product of a size and
       a.itemsize > maxTransferBytes
   :raises ValueError: Raised if the returned message is malformed or does not contain the fields
       required to generate the array.

   .. seealso:: :obj:`pdarray.to_ndarray`

   .. rubric:: Notes

   The number of bytes in the input array cannot exceed `arkouda.maxTransferBytes`,
   otherwise a RuntimeError will be raised. This is to protect the user
   from overwhelming the connection between the Python client and the arkouda
   server, under the assumption that it is a low-bandwidth connection. The user
   may override this limit by setting ak.maxTransferBytes to a larger value,
   but should proceed with caution.

   If the pdrray or ndarray is of type U, this method is called twice recursively
   to create the Strings object and the two corresponding pdarrays for string
   bytes and offsets, respectively.

   .. rubric:: Examples

   >>> ak.array(np.arange(1,10))
   array([1, 2, 3, 4, 5, 6, 7, 8, 9])

   >>> ak.array(range(1,10))
   array([1, 2, 3, 4, 5, 6, 7, 8, 9])

   >>> strings = ak.array(['string {}'.format(i) for i in range(0,5)])
   >>> type(strings)
   <class 'arkouda.strings.Strings'>


.. py:data:: _BASE_UNIT
   :annotation: = ns

   

.. py:data:: _unit2normunit
   

   

.. py:data:: _unit2factor
   

   

.. py:function:: _get_factor(unit: str) -> int


.. py:function:: _identity(x, **kwargs)


.. py:class:: _Timescalar(scalar)


.. py:class:: _AbstractBaseTime(array, unit: str = _BASE_UNIT)

   Bases: :py:obj:`arkouda.pdarrayclass.pdarray`

   Base class for Datetime and Timedelta; not user-facing. Arkouda handles
   time similar to Pandas (albeit with less functionality), in that all absolute
   and relative times are represented in nanoseconds as int64 behind the scenes.
   Datetime and Timedelta can be constructed from Arkouda, NumPy, or Pandas arrays;
   in each case, the input values are normalized to nanoseconds on initialization,
   so that all resulting operations are transparent.

   .. py:method:: _get_callback(cls, other, op)
      :classmethod:


   .. py:method:: floor(self, freq)

      Round times down to the nearest integer of a given frequency.

      :param freq: Frequency to round to
      :type freq: str {'d', 'm', 'h', 's', 'ms', 'us', 'ns'}

      :returns: Values rounded down to nearest frequency
      :rtype: self.__class__


   .. py:method:: ceil(self, freq)

      Round times up to the nearest integer of a given frequency.

      :param freq: Frequency to round to
      :type freq: str {'d', 'm', 'h', 's', 'ms', 'us', 'ns'}

      :returns: Values rounded up to nearest frequency
      :rtype: self.__class__


   .. py:method:: round(self, freq)

      Round times to the nearest integer of a given frequency. Midpoint
      values will be rounded to nearest even integer.

      :param freq: Frequency to round to
      :type freq: str {'d', 'm', 'h', 's', 'ms', 'us', 'ns'}

      :returns: Values rounded to nearest frequency
      :rtype: self.__class__


   .. py:method:: to_ndarray(self)

      Convert the array to a np.ndarray, transferring array data from the
      Arkouda server to client-side Python. Note: if the pdarray size exceeds
      client.maxTransferBytes, a RuntimeError is raised.

      :returns: A numpy ndarray with the same attributes and data as the pdarray
      :rtype: np.ndarray

      :raises RuntimeError: Raised if there is a server-side error thrown, if the pdarray size
          exceeds the built-in client.maxTransferBytes size limit, or if the bytes
          received does not match expected number of bytes

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_ndarray()
      array([0, 1, 2, 3, 4])

      >>> type(a.to_ndarray())
      numpy.ndarray


   .. py:method:: __str__(self)

      Return str(self).


   .. py:method:: __repr__(self) -> str

      Return repr(self).


   .. py:method:: _binop(self, other, op)

      Executes binary operation specified by the op string

      :param other: The pdarray upon which the binop is to be executed
      :type other: pdarray
      :param op: The binop to be executed
      :type op: str

      :returns: A pdarray encapsulating the binop result
      :rtype: pdarray

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set, or if the
          pdarray sizes don't match
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype


   .. py:method:: _r_binop(self, other, op)

      Executes reverse binary operation specified by the op string

      :param other: The pdarray upon which the reverse binop is to be executed
      :type other: pdarray
      :param op: The name of the reverse binop to be executed
      :type op: str

      :returns: A pdarray encapsulating the reverse binop result
      :rtype: pdarray

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype


   .. py:method:: opeq(self, other, op)


   .. py:method:: _is_datetime_scalar(scalar)
      :staticmethod:


   .. py:method:: _is_timedelta_scalar(scalar)
      :staticmethod:


   .. py:method:: _scalar_callback(self, key)


   .. py:method:: __getitem__(self, key)


   .. py:method:: __setitem__(self, key, value)


   .. py:method:: min(self)

      Return the minimum value of the array.


   .. py:method:: max(self)

      Return the maximum value of the array.


   .. py:method:: mink(self, k)

      Compute the minimum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: The maximum `k` values from pda
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray


   .. py:method:: maxk(self, k)

      Compute the maximum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: The maximum `k` values from pda
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray



.. py:class:: Datetime(array, unit: str = _BASE_UNIT)

   Bases: :py:obj:`_AbstractBaseTime`

   Represents a date and/or time.

   Datetime is the Arkouda analog to pandas DatetimeIndex and
   other timeseries data types.

   :param array:
   :type array: int64 pdarray, pd.DatetimeIndex, pd.Series, or np.datetime64 array
   :param uint: For int64 pdarray, denotes the unit of the input. Ignored for pandas
                and numpy arrays, which carry their own unit. Not case-sensitive;
                prefixes of full names (like 'sec') are accepted.

                Possible values:

                * 'weeks' or 'w'
                * 'days' or 'd'
                * 'hours' or 'h'
                * 'minutes', 'm', or 't'
                * 'seconds' or 's'
                * 'milliseconds', 'ms', or 'l'
                * 'microseconds', 'us', or 'u'
                * 'nanoseconds', 'ns', or 'n'

                Unlike in pandas, units cannot be combined or mixed with integers
   :type uint: str, default 'ns'

   .. rubric:: Notes

   The ``.values`` attribute is always in nanoseconds with int64 dtype.

   .. py:attribute:: supported_with_datetime
      

      

   .. py:attribute:: supported_with_r_datetime
      

      

   .. py:attribute:: supported_with_timedelta
      

      

   .. py:attribute:: supported_with_r_timedelta
      

      

   .. py:attribute:: supported_opeq
      

      

   .. py:attribute:: supported_with_pdarray
      

      

   .. py:attribute:: supported_with_r_pdarray
      

      

   .. py:method:: _get_callback(cls, otherclass, op)
      :classmethod:


   .. py:method:: _scalar_callback(self, scalar)


   .. py:method:: _is_supported_scalar(scalar)
      :staticmethod:


   .. py:method:: to_pandas(self)

      Convert array to a pandas DatetimeIndex. Note: if the array size
      exceeds client.maxTransferBytes, a RuntimeError is raised.

      .. seealso:: :obj:`to_ndarray`


   .. py:method:: sum(self)

      Return the sum of all elements in the array.



.. py:class:: Timedelta(array, unit: str = _BASE_UNIT)

   Bases: :py:obj:`_AbstractBaseTime`

   Represents a duration, the difference between two dates or times.

   Timedelta is the Arkouda equivalent of pandas.TimedeltaIndex.

   :param array:
   :type array: int64 pdarray, pd.TimedeltaIndex, pd.Series, or np.timedelta64 array
   :param unit: For int64 pdarray, denotes the unit of the input. Ignored for pandas
                and numpy arrays, which carry their own unit. Not case-sensitive;
                prefixes of full names (like 'sec') are accepted.

                Possible values:

                * 'weeks' or 'w'
                * 'days' or 'd'
                * 'hours' or 'h'
                * 'minutes', 'm', or 't'
                * 'seconds' or 's'
                * 'milliseconds', 'ms', or 'l'
                * 'microseconds', 'us', or 'u'
                * 'nanoseconds', 'ns', or 'n'

                Unlike in pandas, units cannot be combined or mixed with integers
   :type unit: str, default 'ns'

   .. rubric:: Notes

   The ``.values`` attribute is always in nanoseconds with int64 dtype.

   .. py:attribute:: supported_with_datetime
      

      

   .. py:attribute:: supported_with_r_datetime
      

      

   .. py:attribute:: supported_with_timedelta
      

      

   .. py:attribute:: supported_with_r_timedelta
      

      

   .. py:attribute:: supported_opeq
      

      

   .. py:attribute:: supported_with_pdarray
      

      

   .. py:attribute:: supported_with_r_pdarray
      

      

   .. py:method:: _get_callback(cls, otherclass, op)
      :classmethod:


   .. py:method:: _scalar_callback(self, scalar)


   .. py:method:: _is_supported_scalar(scalar)
      :staticmethod:


   .. py:method:: to_pandas(self)

      Convert array to a pandas TimedeltaIndex. Note: if the array size
      exceeds client.maxTransferBytes, a RuntimeError is raised.

      .. seealso:: :obj:`to_ndarray`


   .. py:method:: std(self, ddof: Union[int, numpy.int64, numpy.uint64] = 0)

      Returns the standard deviation as a pd.Timedelta object


   .. py:method:: sum(self)

      Return the sum of all elements in the array.


   .. py:method:: abs(self)

      Absolute value of time interval.




.. py:function:: date_range(start=None, end=None, periods=None, freq=None, tz=None, normalize=False, name=None, closed=None, **kwargs)

   Creates a fixed frequency Datetime range. Alias for
   ``ak.Datetime(pd.date_range(args))``. Subject to size limit
   imposed by client.maxTransferBytes.

   :param start: Left bound for generating dates.
   :type start: str or datetime-like, optional
   :param end: Right bound for generating dates.
   :type end: str or datetime-like, optional
   :param periods: Number of periods to generate.
   :type periods: int, optional
   :param freq: Frequency strings can have multiples, e.g. '5H'. See
                timeseries.offset_aliases for a list of
                frequency aliases.
   :type freq: str or DateOffset, default 'D'
   :param tz: Time zone name for returning localized DatetimeIndex, for example
              'Asia/Hong_Kong'. By default, the resulting DatetimeIndex is
              timezone-naive.
   :type tz: str or tzinfo, optional
   :param normalize: Normalize start/end dates to midnight before generating date range.
   :type normalize: bool, default False
   :param name: Name of the resulting DatetimeIndex.
   :type name: str, default None
   :param closed: Make the interval closed with respect to the given frequency to
                  the 'left', 'right', or both sides (None, the default).
   :type closed: {None, 'left', 'right'}, optional
   :param \*\*kwargs: For compatibility. Has no effect on the result.

   :returns: **rng**
   :rtype: DatetimeIndex

   .. rubric:: Notes

   Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,
   exactly three must be specified. If ``freq`` is omitted, the resulting
   ``DatetimeIndex`` will have ``periods`` linearly spaced elements between
   ``start`` and ``end`` (closed on both sides).

   To learn more about the frequency strings, please see `this link
   <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.


.. py:function:: timedelta_range(start=None, end=None, periods=None, freq=None, name=None, closed=None, **kwargs)

   Return a fixed frequency TimedeltaIndex, with day as the default
   frequency. Alias for ``ak.Timedelta(pd.timedelta_range(args))``.
   Subject to size limit imposed by client.maxTransferBytes.

   :param start: Left bound for generating timedeltas.
   :type start: str or timedelta-like, default None
   :param end: Right bound for generating timedeltas.
   :type end: str or timedelta-like, default None
   :param periods: Number of periods to generate.
   :type periods: int, default None
   :param freq: Frequency strings can have multiples, e.g. '5H'.
   :type freq: str or DateOffset, default 'D'
   :param name: Name of the resulting TimedeltaIndex.
   :type name: str, default None
   :param closed: Make the interval closed with respect to the given frequency to
                  the 'left', 'right', or both sides (None).
   :type closed: str, default None

   :returns: **rng**
   :rtype: TimedeltaIndex

   .. rubric:: Notes

   Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,
   exactly three must be specified. If ``freq`` is omitted, the resulting
   ``TimedeltaIndex`` will have ``periods`` linearly spaced elements between
   ``start`` and ``end`` (closed on both sides).

   To learn more about the frequency strings, please see `this link
   <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.


.. py:data:: AllSymbols
   :annotation: = __AllSymbols__

   

.. py:data:: RegisteredSymbols
   :annotation: = __RegisteredSymbols__

   

.. py:function:: information(names: Union[List[str], str] = RegisteredSymbols) -> str

   Returns JSON formatted string containing information about the objects in names

   :param names: names is either the name of an object or list of names of objects to retrieve info
                 if names is ak.AllSymbols, retrieves info for all symbols in the symbol table
                 if names is ak.RegisteredSymbols, retrieves info for all symbols in the registry
   :type names: Union[List[str], str]

   :returns: JSON formatted string containing a list of information for each object in names
   :rtype: str

   :raises RuntimeError: Raised if a server-side error is thrown in the process of
       retrieving information about the objects in names


.. py:function:: list_registry() -> List[str]

   Return a list containing the names of all registered objects

   :param None:

   :returns: List of all object names in the registry
   :rtype: list

   :raises RuntimeError: Raised if there's a server-side error thrown


.. py:function:: list_symbol_table() -> List[str]

   Return a list containing the names of all objects in the symbol table

   :param None:

   :returns: List of all object names in the symbol table
   :rtype: list

   :raises RuntimeError: Raised if there's a server-side error thrown


.. py:function:: pretty_print_information(names: Union[List[str], str] = RegisteredSymbols) -> None

   Prints verbose information for each object in names in a human readable format

   :param names: names is either the name of an object or list of names of objects to retrieve info
                 if names is ak.AllSymbols, retrieves info for all symbols in the symbol table
                 if names is ak.RegisteredSymbols, retrieves info for all symbols in the registry
   :type names: Union[List[str], str]

   :rtype: None

   :raises RuntimeError: Raised if a server-side error is thrown in the process of
       retrieving information about the objects in names


.. py:class:: pdarray(name: str, mydtype: numpy.dtype, size: arkouda.dtypes.int_scalars, ndim: arkouda.dtypes.int_scalars, shape: Sequence[int], itemsize: arkouda.dtypes.int_scalars)

   The basic arkouda array class. This class contains only the
   attributies of the array; the data resides on the arkouda
   server. When a server operation results in a new array, arkouda
   will create a pdarray instance that points to the array data on
   the server. As such, the user should not initialize pdarray
   instances directly.

   .. attribute:: name

      The server-side identifier for the array

      :type: str

   .. attribute:: dtype

      The element type of the array

      :type: dtype

   .. attribute:: size

      The number of elements in the array

      :type: int_scalars

   .. attribute:: ndim

      The rank of the array (currently only rank 1 arrays supported)

      :type: int_scalars

   .. attribute:: shape

      A list or tuple containing the sizes of each dimension of the array

      :type: Sequence[int]

   .. attribute:: itemsize

      The size in bytes of each element

      :type: int_scalars

   .. py:attribute:: BinOps
      

      

   .. py:attribute:: OpEqOps
      

      

   .. py:attribute:: objtype
      :annotation: = pdarray

      

   .. py:attribute:: __array_priority__
      :annotation: = 1000

      

   .. py:method:: __del__(self)


   .. py:method:: __bool__(self) -> bool


   .. py:method:: __len__(self)


   .. py:method:: __str__(self)

      Return str(self).


   .. py:method:: __repr__(self)

      Return repr(self).


   .. py:method:: format_other(self, other: object) -> str

      Attempt to cast scalar other to the element dtype of this pdarray,
      and print the resulting value to a string (e.g. for sending to a
      server command). The user should not call this function directly.

      :param other: The scalar to be cast to the pdarray.dtype
      :type other: object

      :rtype: string representation of np.dtype corresponding to the other parameter

      :raises TypeError: Raised if the other parameter cannot be converted to
          Numpy dtype


   .. py:method:: _binop(self, other: pdarray, op: str) -> pdarray

      Executes binary operation specified by the op string

      :param other: The pdarray upon which the binop is to be executed
      :type other: pdarray
      :param op: The binop to be executed
      :type op: str

      :returns: A pdarray encapsulating the binop result
      :rtype: pdarray

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set, or if the
          pdarray sizes don't match
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype


   .. py:method:: _r_binop(self, other: pdarray, op: str) -> pdarray

      Executes reverse binary operation specified by the op string

      :param other: The pdarray upon which the reverse binop is to be executed
      :type other: pdarray
      :param op: The name of the reverse binop to be executed
      :type op: str

      :returns: A pdarray encapsulating the reverse binop result
      :rtype: pdarray

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype


   .. py:method:: __add__(self, other)


   .. py:method:: __radd__(self, other)


   .. py:method:: __sub__(self, other)


   .. py:method:: __rsub__(self, other)


   .. py:method:: __mul__(self, other)


   .. py:method:: __rmul__(self, other)


   .. py:method:: __truediv__(self, other)


   .. py:method:: __rtruediv__(self, other)


   .. py:method:: __floordiv__(self, other)


   .. py:method:: __rfloordiv__(self, other)


   .. py:method:: __mod__(self, other)


   .. py:method:: __rmod__(self, other)


   .. py:method:: __lshift__(self, other)


   .. py:method:: __rlshift__(self, other)


   .. py:method:: __rshift__(self, other)


   .. py:method:: __rrshift__(self, other)


   .. py:method:: __and__(self, other)


   .. py:method:: __rand__(self, other)


   .. py:method:: __or__(self, other)


   .. py:method:: __ror__(self, other)


   .. py:method:: __xor__(self, other)


   .. py:method:: __rxor__(self, other)


   .. py:method:: __pow__(self, other)


   .. py:method:: __rpow__(self, other)


   .. py:method:: __lt__(self, other)

      Return self<value.


   .. py:method:: __gt__(self, other)

      Return self>value.


   .. py:method:: __le__(self, other)

      Return self<=value.


   .. py:method:: __ge__(self, other)

      Return self>=value.


   .. py:method:: __eq__(self, other)

      Return self==value.


   .. py:method:: __ne__(self, other)

      Return self!=value.


   .. py:method:: __neg__(self)


   .. py:method:: __invert__(self)


   .. py:method:: opeq(self, other, op)


   .. py:method:: __iadd__(self, other)


   .. py:method:: __isub__(self, other)


   .. py:method:: __imul__(self, other)


   .. py:method:: __itruediv__(self, other)


   .. py:method:: __ifloordiv__(self, other)


   .. py:method:: __ilshift__(self, other)


   .. py:method:: __irshift__(self, other)


   .. py:method:: __iand__(self, other)


   .. py:method:: __ior__(self, other)


   .. py:method:: __ixor__(self, other)


   .. py:method:: __ipow__(self, other)


   .. py:method:: __iter__(self)
      :abstractmethod:


   .. py:method:: __getitem__(self, key)


   .. py:method:: __setitem__(self, key, value)


   .. py:method:: fill(self, value: arkouda.dtypes.numeric_scalars) -> None

      Fill the array (in place) with a constant value.

      :param value:
      :type value: numeric_scalars

      :raises TypeError: Raised if value is not an int, int64, float, or float64


   .. py:method:: any(self) -> numpy.bool_

      Return True iff any element of the array evaluates to True.


   .. py:method:: all(self) -> numpy.bool_

      Return True iff all elements of the array evaluate to True.


   .. py:method:: is_registered(self) -> numpy.bool_

      Return True iff the object is contained in the registry

      :param None:

      :returns: Indicates if the object is contained in the registry
      :rtype: bool

      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: _list_component_names(self) -> List[str]

      Internal Function that returns a list of all component names

      :param None:

      :returns: List of all component names
      :rtype: List[str]


   .. py:method:: info(self) -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str


   .. py:method:: pretty_print_info(self) -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None


   .. py:method:: is_sorted(self) -> numpy.bool_

      Return True iff the array is monotonically non-decreasing.

      :param None:

      :returns: Indicates if the array is monotonically non-decreasing
      :rtype: bool

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: sum(self) -> arkouda.dtypes.numeric_and_bool_scalars

      Return the sum of all elements in the array.


   .. py:method:: prod(self) -> numpy.float64

      Return the product of all elements in the array. Return value is
      always a np.float64 or np.int64.


   .. py:method:: min(self) -> arkouda.dtypes.numpy_scalars

      Return the minimum value of the array.


   .. py:method:: max(self) -> arkouda.dtypes.numpy_scalars

      Return the maximum value of the array.


   .. py:method:: argmin(self) -> numpy.int64

      Return the index of the first occurrence of the array min value


   .. py:method:: argmax(self) -> numpy.int64

      Return the index of the first occurrence of the array max value.


   .. py:method:: mean(self) -> numpy.float64

      Return the mean of the array.


   .. py:method:: var(self, ddof: arkouda.dtypes.int_scalars = 0) -> numpy.float64

      Compute the variance. See ``arkouda.var`` for details.

      :param ddof: "Delta Degrees of Freedom" used in calculating var
      :type ddof: int_scalars

      :returns: The scalar variance of the array
      :rtype: np.float64

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises ValueError: Raised if the ddof >= pdarray size
      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: std(self, ddof: arkouda.dtypes.int_scalars = 0) -> numpy.float64

      Compute the standard deviation. See ``arkouda.std`` for details.

      :param ddof: "Delta Degrees of Freedom" used in calculating std
      :type ddof: int_scalars

      :returns: The scalar standard deviation of the array
      :rtype: np.float64

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: mink(self, k: arkouda.dtypes.int_scalars) -> pdarray

      Compute the minimum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: The maximum `k` values from pda
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray


   .. py:method:: maxk(self, k: arkouda.dtypes.int_scalars) -> pdarray

      Compute the maximum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: The maximum `k` values from pda
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray


   .. py:method:: argmink(self, k: arkouda.dtypes.int_scalars) -> pdarray

      Compute the minimum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: Indices corresponding to the maximum `k` values from pda
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray


   .. py:method:: argmaxk(self, k: arkouda.dtypes.int_scalars) -> pdarray

      Finds the indices corresponding to the maximum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: Indices corresponding to the  maximum `k` values, sorted
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray


   .. py:method:: popcount(self) -> pdarray

      Find the population (number of bits set) in each element. See `ak.popcount`.


   .. py:method:: parity(self) -> pdarray

      Find the parity (XOR of all bits) in each element. See `ak.parity`.


   .. py:method:: clz(self) -> pdarray

      Count the number of leading zeros in each element. See `ak.clz`.


   .. py:method:: ctz(self) -> pdarray

      Count the number of trailing zeros in each element. See `ak.ctz`.


   .. py:method:: rotl(self, other) -> pdarray

      Rotate bits left by <other>.


   .. py:method:: rotr(self, other) -> pdarray

      Rotate bits right by <other>.


   .. py:method:: astype(self, dtype) -> pdarray

      Cast values of pdarray to provided dtype

      :param dtype: Dtype to cast to
      :type dtype: np.dtype or str

      :returns: An arkouda pdarray with values converted to the specified data type
      :rtype: ak.pdarray

      .. rubric:: Notes

      This is essentially shorthand for ak.cast(x, '<dtype>') where x is a pdarray.


   .. py:method:: reshape(self, *shape, order='row_major')

      Gives a new shape to an array without changing its data.

      :param shape: The new shape should be compatible with the original shape.
      :type shape: int, tuple of ints, or pdarray
      :param order: Read the elements of the pdarray in this index order
                    By default, read the elements in row_major or C-like order where the last index changes the fastest
                    If 'column_major' or 'F', read the elements in column_major or Fortran-like order where the first index changes the fastest
      :type order: str {'row_major' | 'C' | 'column_major' | 'F'}

      :returns: An arrayview object with the data from the array but with the new shape
      :rtype: ArrayView


   .. py:method:: to_ndarray(self) -> numpy.ndarray

      Convert the array to a np.ndarray, transferring array data from the
      Arkouda server to client-side Python. Note: if the pdarray size exceeds
      client.maxTransferBytes, a RuntimeError is raised.

      :returns: A numpy ndarray with the same attributes and data as the pdarray
      :rtype: np.ndarray

      :raises RuntimeError: Raised if there is a server-side error thrown, if the pdarray size
          exceeds the built-in client.maxTransferBytes size limit, or if the bytes
          received does not match expected number of bytes

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_ndarray()
      array([0, 1, 2, 3, 4])

      >>> type(a.to_ndarray())
      numpy.ndarray


   .. py:method:: to_cuda(self)

      Convert the array to a Numba DeviceND array, transferring array data from the
      arkouda server to Python via ndarray. If the array exceeds a builtin size limit,
      a RuntimeError is raised.

      :returns: A Numba ndarray with the same attributes and data as the pdarray; on GPU
      :rtype: numba.DeviceNDArray

      :raises ImportError: Raised if CUDA is not available
      :raises ModuleNotFoundError: Raised if Numba is either not installed or not enabled
      :raises RuntimeError: Raised if there is a server-side error thrown in the course of retrieving
          the pdarray.

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_cuda()
      array([0, 1, 2, 3, 4])

      >>> type(a.to_cuda())
      numpy.devicendarray


   .. py:method:: save(self, prefix_path: str, dataset: str = 'array', mode: str = 'truncate', compressed: bool = False, file_format: str = 'HDF5') -> str

      Save the pdarray to HDF5 or Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param compressed: Defaults to False. When True, files will be written with Snappy compression
                         and RLE bit packing. This is currently only supported on Parquet files and will
                         not impact the generated files when writing HDF5 files.
      :type compressed: bool
      :param file_format: By default, saved files will be written to the HDF5 file format. If
                          'Parquet', the files will be written to the Parquet file format. This
                          is case insensitive.
      :type file_format: str {'HDF5', 'Parquet'}

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray
      :raises ValueError: Raised if there is an error in parsing the prefix path pointing to
          file write location or if the mode parameter is neither truncate
          nor append
      :raises TypeError: Raised if any one of the prefix_path, dataset, or mode parameters
          is not a string

      .. seealso:: :obj:`save_all`, :obj:`load`, :obj:`read`

      .. rubric:: Notes

      The prefix_path must be visible to the arkouda server and the user must
      have write permission.

      Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales``. If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.

      .. rubric:: Examples

      >>> a = ak.arange(0, 100, 1)
      >>> a.save('arkouda_range', dataset='array')
      >>> a.save('arkouda_range_parquet', dataset='array', file_format='Parquet')

      Array is saved in numLocales files with names like ``tmp/arkouda_range_LOCALE0``

      The array can be read back in as follows

      >>> b = ak.read('arkouda_range', dataset='array')
      >>> (a == b).all()
      True

      >>> c = ak.read_parquet('arkouda_range_parquet*')
      >>> (c == b).all()
      True


   .. py:method:: save_parquet(self, prefix_path: str, dataset: str = 'array', mode: str = 'truncate', compressed: bool = False) -> str

      Save the pdarray to Parquet. The result is a collection of Parquet files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in Parquet files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
      :type mode: str {'truncate', 'append'}
      :param compressed: By default, write without Snappy compression and RLE encoding.
      :type compressed: bool

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray
      :raises ValueError: Raised if there is an error in parsing the prefix path pointing to
          file write location or if the mode parameter is neither truncate
          nor append
      :raises TypeError: Raised if any one of the prefix_path, dataset, or mode parameters
          is not a string

      .. seealso:: :obj:`save`, :obj:`save_all`, :obj:`load`, :obj:`read`

      .. rubric:: Notes

      The prefix_path must be visible to the arkouda server and the user must
      have write permission.

      Output files have names of the form ``<prefix_path>_LOCALE<i>.parquet``, where ``<i>``
      ranges from 0 to ``numLocales``. If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.

      .. rubric:: Examples

      >>> a = ak.arange(0, 100, 1)
      >>> a.save_parquet('arkouda_range')

      Array is saved in numLocales files with names like ``arkouda_range_LOCALE0000.parquet``

      The array can be read back in as follows

      >>> b = ak.read('arkouda_range')
      >>> (a == b).all()
      True


   .. py:method:: save_hdf(self, prefix_path: str, dataset: str = 'array', mode: str = 'truncate') -> str

      Save the pdarray to HDF5. The result is a collection of HDF5 files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in HDF5 files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
      :type mode: str {'truncate', 'append'}
      :param compressed: By default, write without Snappy compression and RLE encoding.
      :type compressed: bool

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray
      :raises ValueError: Raised if there is an error in parsing the prefix path pointing to
          file write location or if the mode parameter is neither truncate
          nor append
      :raises TypeError: Raised if any one of the prefix_path, dataset, or mode parameters
          is not a string

      .. seealso:: :obj:`save`, :obj:`save_all`, :obj:`load`, :obj:`read`

      .. rubric:: Notes

      The prefix_path must be visible to the arkouda server and the user must
      have write permission.

      Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales``. If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.

      .. rubric:: Examples

      >>> a = ak.arange(0, 100, 1)
      >>> a.save_hdf('arkouda_range')

      Array is saved in numLocales files with names like ``arkouda_range_LOCALE0000``

      The array can be read back in as follows

      >>> b = ak.read('arkouda_range')
      >>> (a == b).all()
      True


   .. py:method:: register(self, user_defined_name: str) -> pdarray

      Register this pdarray with a user defined name in the arkouda server
      so it can be attached to later using pdarray.attach()
      This is an in-place operation, registering a pdarray more than once will
      update the name in the registry and remove the previously registered name.
      A name can only be registered to one pdarray at a time.

      :param user_defined_name: user defined name array is to be registered under
      :type user_defined_name: str

      :returns: The same pdarray which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support a fluid programming style.
                Please note you cannot register two different pdarrays with the same name.
      :rtype: pdarray

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the pdarray with the user_defined_name
          If the user is attempting to register more than one pdarray with the same name, the former should be
          unregistered first to free up the registration name.

      .. seealso:: :obj:`attach`, :obj:`unregister`, :obj:`is_registered`, :obj:`list_registry`, :obj:`unregister_pdarray_by_name`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion
      until they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()


   .. py:method:: unregister(self) -> None

      Unregister a pdarray in the arkouda server which was previously
      registered using register() and/or attahced to using attach()


      :rtype: None

      :raises RuntimeError: Raised if the server could not find the internal name/symbol to remove

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion until
      they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()


   .. py:method:: attach(user_defined_name: str) -> pdarray
      :staticmethod:

      class method to return a pdarray attached to the registered name in the arkouda
      server which was registered using register()

      :param user_defined_name: user defined name which array was registered under
      :type user_defined_name: str

      :returns: pdarray which is bound to corresponding server side component that was registered with user_defined_name
      :rtype: pdarray

      :raises TypeError: Raised if user_defined_name is not a str

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion
      until they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()


   .. py:method:: _get_grouping_keys(self) -> List[pdarray]

      Private method for generating grouping keys used by GroupBy.

      API: this method must be defined by all groupable arrays, and it
      must return a list of arrays that can be (co)argsorted.



.. py:function:: is_sorted(pda: pdarray) -> numpy.bool_

   Return True iff the array is monotonically non-decreasing.

   :param pda: The pdarray instance to be evaluated
   :type pda: pdarray

   :returns: Indicates if the array is monotonically non-decreasing
   :rtype: bool

   :raises TypeError: Raised if pda is not a pdarray instance
   :raises RuntimeError: Raised if there's a server-side error thrown


.. py:function:: attach_pdarray(user_defined_name: str) -> pdarray

   class method to return a pdarray attached to the registered name in the arkouda
   server which was registered using register()

   :param user_defined_name: user defined name which array was registered under
   :type user_defined_name: str

   :returns: pdarray which is bound to corresponding server side component that was registered with user_defined_name
   :rtype: pdarray

   :raises TypeError: Raised if user_defined_name is not a str

   .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

   .. rubric:: Notes

   Registered names/pdarrays in the server are immune to deletion
   until they are unregistered.

   .. rubric:: Examples

   >>> a = zeros(100)
   >>> a.register("my_zeros")
   >>> # potentially disconnect from server and reconnect to server
   >>> b = ak.attach_pdarray("my_zeros")
   >>> # ...other work...
   >>> b.unregister()


.. py:function:: isSupportedInt(num)


.. py:data:: akint64
   

   

.. py:data:: akbool
   

   

.. py:data:: str_
   

   

.. py:function:: zeros(size: Union[arkouda.dtypes.int_scalars, str], dtype: Union[numpy.dtype, type, str] = float64) -> arkouda.pdarrayclass.pdarray

   Create a pdarray filled with zeros.

   :param size: Size of the array (only rank-1 arrays supported)
   :type size: int_scalars
   :param dtype: Type of resulting array, default float64
   :type dtype: all_scalars

   :returns: Zeros of the requested size and dtype
   :rtype: pdarray

   :raises TypeError: Raised if the supplied dtype is not supported or if the size
       parameter is neither an int nor a str that is parseable to an int.

   .. seealso:: :obj:`ones`, :obj:`zeros_like`

   .. rubric:: Examples

   >>> ak.zeros(5, dtype=ak.int64)
   array([0, 0, 0, 0, 0])

   >>> ak.zeros(5, dtype=ak.float64)
   array([0, 0, 0, 0, 0])

   >>> ak.zeros(5, dtype=ak.bool)
   array([False, False, False, False, False])


.. py:function:: ones(size: Union[arkouda.dtypes.int_scalars, str], dtype: Union[numpy.dtype, type, str] = float64) -> arkouda.pdarrayclass.pdarray

   Create a pdarray filled with ones.

   :param size: Size of the array (only rank-1 arrays supported)
   :type size: int_scalars
   :param dtype: Resulting array type, default float64
   :type dtype: Union[float64, int64, bool]

   :returns: Ones of the requested size and dtype
   :rtype: pdarray

   :raises TypeError: Raised if the supplied dtype is not supported or if the size
       parameter is neither an int nor a str that is parseable to an int.

   .. seealso:: :obj:`zeros`, :obj:`ones_like`

   .. rubric:: Examples

   >>> ak.ones(5, dtype=ak.int64)
   array([1, 1, 1, 1, 1])

   >>> ak.ones(5, dtype=ak.float64)
   array([1, 1, 1, 1, 1])

   >>> ak.ones(5, dtype=ak.bool)
   array([True, True, True, True, True])


.. py:function:: array(a: Union[arkouda.pdarrayclass.pdarray, numpy.ndarray, Iterable], dtype: Union[numpy.dtype, type, str] = None) -> Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]

   Convert a Python or Numpy Iterable to a pdarray or Strings object, sending
   the corresponding data to the arkouda server.

   :param a: Rank-1 array of a supported dtype
   :type a: Union[pdarray, np.ndarray]
   :param dtype: The target dtype to cast values to
   :type dtype: np.dtype, type, or str

   :returns: A pdarray instance stored on arkouda server or Strings instance, which
             is composed of two pdarrays stored on arkouda server
   :rtype: pdarray or Strings

   :raises TypeError: Raised if a is not a pdarray, np.ndarray, or Python Iterable such as a
       list, array, tuple, or deque
   :raises RuntimeError: Raised if a is not one-dimensional, nbytes > maxTransferBytes, a.dtype is
       not supported (not in DTypes), or if the product of a size and
       a.itemsize > maxTransferBytes
   :raises ValueError: Raised if the returned message is malformed or does not contain the fields
       required to generate the array.

   .. seealso:: :obj:`pdarray.to_ndarray`

   .. rubric:: Notes

   The number of bytes in the input array cannot exceed `arkouda.maxTransferBytes`,
   otherwise a RuntimeError will be raised. This is to protect the user
   from overwhelming the connection between the Python client and the arkouda
   server, under the assumption that it is a low-bandwidth connection. The user
   may override this limit by setting ak.maxTransferBytes to a larger value,
   but should proceed with caution.

   If the pdrray or ndarray is of type U, this method is called twice recursively
   to create the Strings object and the two corresponding pdarrays for string
   bytes and offsets, respectively.

   .. rubric:: Examples

   >>> ak.array(np.arange(1,10))
   array([1, 2, 3, 4, 5, 6, 7, 8, 9])

   >>> ak.array(range(1,10))
   array([1, 2, 3, 4, 5, 6, 7, 8, 9])

   >>> strings = ak.array(['string {}'.format(i) for i in range(0,5)])
   >>> type(strings)
   <class 'arkouda.strings.Strings'>


.. py:function:: arange(*args, **kwargs) -> arkouda.pdarrayclass.pdarray

   arange([start,] stop[, stride,] dtype=int64)

   Create a pdarray of consecutive integers within the interval [start, stop).
   If only one arg is given then arg is the stop parameter. If two args are
   given, then the first arg is start and second is stop. If three args are
   given, then the first arg is start, second is stop, third is stride.

   The return value is cast to type dtype

   :param start: Starting value (inclusive)
   :type start: int_scalars, optional
   :param stop: Stopping value (exclusive)
   :type stop: int_scalars
   :param stride: The difference between consecutive elements, the default stride is 1,
                  if stride is specified then start must also be specified.
   :type stride: int_scalars, optional
   :param dtype: The target dtype to cast values to
   :type dtype: np.dtype, type, or str

   :returns: Integers from start (inclusive) to stop (exclusive) by stride
   :rtype: pdarray, dtype

   :raises TypeError: Raised if start, stop, or stride is not an int object
   :raises ZeroDivisionError: Raised if stride == 0

   .. seealso:: :obj:`linspace`, :obj:`zeros`, :obj:`ones`, :obj:`randint`

   .. rubric:: Notes

   Negative strides result in decreasing values. Currently, only int64
   pdarrays can be created with this method. For float64 arrays, use
   the linspace method.

   .. rubric:: Examples

   >>> ak.arange(0, 5, 1)
   array([0, 1, 2, 3, 4])

   >>> ak.arange(5, 0, -1)
   array([5, 4, 3, 2, 1])

   >>> ak.arange(0, 10, 2)
   array([0, 2, 4, 6, 8])

   >>> ak.arange(-5, -10, -1)
   array([-5, -6, -7, -8, -9])


.. py:function:: concatenate(arrays: Sequence[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, Categorical]], ordered: bool = True) -> Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, Categorical]

   Concatenate a list or tuple of ``pdarray`` or ``Strings`` objects into
   one ``pdarray`` or ``Strings`` object, respectively.

   :param arrays: The arrays to concatenate. Must all have same dtype.
   :type arrays: Sequence[Union[pdarray,Strings,Categorical]]
   :param ordered: If True (default), the arrays will be appended in the
                   order given. If False, array data may be interleaved
                   in blocks, which can greatly improve performance but
                   results in non-deterministic ordering of elements.
   :type ordered: bool

   :returns: Single pdarray or Strings object containing all values, returned in
             the original order
   :rtype: Union[pdarray,Strings,Categorical]

   :raises ValueError: Raised if arrays is empty or if 1..n pdarrays have
       differing dtypes
   :raises TypeError: Raised if arrays is not a pdarrays or Strings python Sequence such as a
       list or tuple
   :raises RuntimeError: Raised if 1..n array elements are dtypes for which
       concatenate has not been implemented.

   .. rubric:: Examples

   >>> ak.concatenate([ak.array([1, 2, 3]), ak.array([4, 5, 6])])
   array([1, 2, 3, 4, 5, 6])

   >>> ak.concatenate([ak.array([True,False,True]),ak.array([False,True,True])])
   array([True, False, True, False, True, True])

   >>> ak.concatenate([ak.array(['one','two']),ak.array(['three','four','five'])])
   array(['one', 'two', 'three', 'four', 'five'])


.. py:function:: unique(pda: groupable, return_groups: bool = False) -> Union[groupable, Tuple[groupable, arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray, int]]

   Find the unique elements of an array.

   Returns the unique elements of an array, sorted if the values are integers.
   There is an optional output in addition to the unique elements: the number
   of times each unique value comes up in the input array.

   :param pda: Input array.
   :type pda: (list of) pdarray, Strings, or Categorical
   :param return_groups: If True, also return grouping information for the array.
   :type return_groups: bool, optional

   :returns: * **unique** (*(list of) pdarray, Strings, or Categorical*) -- The unique values. If input dtype is int64, return values will be sorted.
             * **permutation** (*pdarray, optional*) -- Permutation that groups equivalent values together (only when return_groups=True)
             * **segments** (*pdarray, optional*) -- The offset of each group in the permuted array (only when return_groups=True)

   :raises TypeError: Raised if pda is not a pdarray or Strings object
   :raises RuntimeError: Raised if the pdarray or Strings dtype is unsupported

   .. rubric:: Notes

   For integer arrays, this function checks to see whether `pda` is sorted
   and, if so, whether it is already unique. This step can save considerable
   computation. Otherwise, this function will sort `pda`.

   .. rubric:: Examples

   >>> A = ak.array([3, 2, 1, 1, 2, 3])
   >>> ak.unique(A)
   array([1, 2, 3])


.. py:class:: GroupBy(keys: groupable, assume_sorted: bool = False, hash_strings: bool = True)

   Group an array or list of arrays by value, usually in preparation
   for aggregating the within-group values of another array.

   :param keys: The array to group by value, or if list, the column arrays to group by row
   :type keys: (list of) pdarray, Strings, or Categorical
   :param assume_sorted: If True, assume keys is already sorted (Default: False)
   :type assume_sorted: bool

   .. attribute:: nkeys

      The number of key arrays (columns)

      :type: int

   .. attribute:: size

      The length of the input array(s), i.e. number of rows

      :type: int

   .. attribute:: permutation

      The permutation that sorts the keys array(s) by value (row)

      :type: pdarray

   .. attribute:: unique_keys

      The unique values of the keys array(s), in grouped order

      :type: (list of) pdarray, Strings, or Categorical

   .. attribute:: ngroups

      The length of the unique_keys array(s), i.e. number of groups

      :type: int

   .. attribute:: segments

      The start index of each group in the grouped array(s)

      :type: pdarray

   .. attribute:: logger

      Used for all logging operations

      :type: ArkoudaLogger

   :raises TypeError: Raised if keys is a pdarray with a dtype other than int64

   .. rubric:: Notes

   Integral pdarrays, Strings, and Categoricals are natively supported, but
   float64 and bool arrays are not.

   For a user-defined class to be groupable, it must inherit from pdarray
   and define or overload the grouping API:
     1) a ._get_grouping_keys() method that returns a list of pdarrays
        that can be (co)argsorted.
     2) (Optional) a .group() method that returns the permutation that
        groups the array
   If the input is a single array with a .group() method defined, method 2
   will be used; otherwise, method 1 will be used.

   .. py:attribute:: Reductions
      

      

   .. py:method:: count(self) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Count the number of elements in each group, i.e. the number of times
      each key appears.

      :param none:

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **counts** (*pdarray, int64*) -- The number of times each unique key appears

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 2, 3, 1, 2, 4, 3, 4, 3, 4])
      >>> g = ak.GroupBy(a)
      >>> keys,counts = g.count()
      >>> keys
      array([1, 2, 3, 4])
      >>> counts
      array([1, 2, 4, 3])


   .. py:method:: aggregate(self, values: groupable, operator: str, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group another
      array of values and apply a reduction to each group's values.

      :param values: The values to group and reduce
      :type values: pdarray
      :param operator: The name of the reduction operator to use
      :type operator: str

      :returns: * **unique_keys** (*groupable*) -- The unique keys, in grouped order
                * **aggregates** (*groupable*) -- One aggregate value per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if the requested operator is not supported for the
          values dtype

      .. rubric:: Examples

      >>> keys = ak.arange(0, 10)
      >>> vals = ak.linspace(-1, 1, 10)
      >>> g = ak.GroupBy(keys)
      >>> g.aggregate(vals, 'sum')
      (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([-1, -0.77777777777777768,
      -0.55555555555555536, -0.33333333333333348, -0.11111111111111116,
      0.11111111111111116, 0.33333333333333348, 0.55555555555555536, 0.77777777777777768,
      1]))
      >>> g.aggregate(vals, 'min')
      (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([-1, -0.77777777777777779,
      -0.55555555555555558, -0.33333333333333337, -0.11111111111111116, 0.11111111111111116,
      0.33333333333333326, 0.55555555555555536, 0.77777777777777768, 1]))


   .. py:method:: sum(self, values: arkouda.pdarrayclass.pdarray, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and sum each group's values.

      :param values: The values to group and sum
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_sums** (*pdarray*) -- One sum per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array

      .. rubric:: Notes

      The grouped sum of a boolean ``pdarray`` returns integers.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.sum(b)
      (array([2, 3, 4]), array([8, 14, 6]))


   .. py:method:: prod(self, values: arkouda.pdarrayclass.pdarray, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and compute the product of each group's
      values.

      :param values: The values to group and multiply
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_products** (*pdarray, float64*) -- One product per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object
      :raises ValueError: Raised if the key array size does not match the values size
          or if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if prod is not supported for the values dtype

      .. rubric:: Notes

      The return dtype is always float64.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.prod(b)
      (array([2, 3, 4]), array([12, 108.00000000000003, 8.9999999999999982]))


   .. py:method:: mean(self, values: arkouda.pdarrayclass.pdarray, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and compute the mean of each group's
      values.

      :param values: The values to group and average
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_means** (*pdarray, float64*) -- One mean value per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object
      :raises ValueError: Raised if the key array size does not match the values size
          or if the operator is not in the GroupBy.Reductions array

      .. rubric:: Notes

      The return dtype is always float64.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.mean(b)
      (array([2, 3, 4]), array([2.6666666666666665, 2.7999999999999998, 3]))


   .. py:method:: min(self, values: arkouda.pdarrayclass.pdarray, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the minimum of each group's
      values.

      :param values: The values to group and find minima
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_minima** (*pdarray*) -- One minimum per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if min is
          not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values size
          or if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if min is not supported for the values dtype

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.min(b)
      (array([2, 3, 4]), array([1, 1, 3]))


   .. py:method:: max(self, values: arkouda.pdarrayclass.pdarray, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the maximum of each
      group's values.

      :param values: The values to group and find maxima
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_maxima** (*pdarray*) -- One maximum per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if max is
          not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if max is not supported for the values dtype

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.max(b)
      (array([2, 3, 4]), array([4, 4, 3]))


   .. py:method:: argmin(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the location of the first
      minimum of each group's values.

      :param values: The values to group and find argmin
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_argminima** (*pdarray, int64*) -- One index per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if argmax
          is not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values
          size or if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if argmin is not supported for the values dtype

      .. rubric:: Notes

      The returned indices refer to the original values array as
      passed in, not the permutation applied by the GroupBy instance.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.argmin(b)
      (array([2, 3, 4]), array([5, 4, 2]))


   .. py:method:: argmax(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the location of the first
      maximum of each group's values.

      :param values: The values to group and find argmax
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_argmaxima** (*pdarray, int64*) -- One index per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if argmax
          is not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array

      .. rubric:: Notes

      The returned indices refer to the original values array as passed in,
      not the permutation applied by the GroupBy instance.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.argmax(b)
      (array([2, 3, 4]), array([9, 3, 2]))


   .. py:method:: nunique(self, values: groupable) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group another
      array of values and return the number of unique values in each group.

      :param values: The values to group and find unique values
      :type values: pdarray, int64

      :returns: * **unique_keys** (*groupable*) -- The unique keys, in grouped order
                * **group_nunique** (*groupable*) -- Number of unique values per unique key in the GroupBy instance

      :raises TypeError: Raised if the dtype(s) of values array(s) does/do not support
          the nunique method
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if nunique is not supported for the values dtype

      .. rubric:: Examples

      >>> data = ak.array([3, 4, 3, 1, 1, 4, 3, 4, 1, 4])
      >>> data
      array([3, 4, 3, 1, 1, 4, 3, 4, 1, 4])
      >>> labels = ak.array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4])
      >>> labels
      ak.array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4])
      >>> g = ak.GroupBy(labels)
      >>> g.keys
      ak.array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4])
      >>> g.nunique(data)
      array([1,2,3,4]), array([2, 2, 3, 1])
      #    Group (1,1,1) has values [3,4,3] -> there are 2 unique values 3&4
      #    Group (2,2,2) has values [1,1,4] -> 2 unique values 1&4
      #    Group (3,3,3) has values [3,4,1] -> 3 unique values
      #    Group (4) has values [4] -> 1 unique value


   .. py:method:: any(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[Union[arkouda.pdarrayclass.pdarray, List[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]], arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group another
      array of values and perform an "or" reduction on each group.

      :param values: The values to group and reduce with "or"
      :type values: pdarray, bool

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_any** (*pdarray, bool*) -- One bool per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not bool
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array


   .. py:method:: all(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[Union[arkouda.pdarrayclass.pdarray, List[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]], arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform an "and" reduction on
      each group.

      :param values: The values to group and reduce with "and"
      :type values: pdarray, bool

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_any** (*pdarray, bool*) -- One bool per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not bool
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype


   .. py:method:: OR(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[Union[arkouda.pdarrayclass.pdarray, List[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]], arkouda.pdarrayclass.pdarray]

      Bitwise OR of values in each segment.

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform a bitwise OR reduction on
      each group.

      :param values: The values to group and reduce with OR
      :type values: pdarray, int64

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **result** (*pdarray, int64*) -- Bitwise OR of values in segments corresponding to keys

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not int64
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype


   .. py:method:: AND(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[Union[arkouda.pdarrayclass.pdarray, List[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]], arkouda.pdarrayclass.pdarray]

      Bitwise AND of values in each segment.

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform a bitwise AND reduction on
      each group.

      :param values: The values to group and reduce with AND
      :type values: pdarray, int64

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **result** (*pdarray, int64*) -- Bitwise AND of values in segments corresponding to keys

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not int64
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype


   .. py:method:: XOR(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[Union[arkouda.pdarrayclass.pdarray, List[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]], arkouda.pdarrayclass.pdarray]

      Bitwise XOR of values in each segment.

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform a bitwise XOR reduction on
      each group.

      :param values: The values to group and reduce with XOR
      :type values: pdarray, int64

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **result** (*pdarray, int64*) -- Bitwise XOR of values in segments corresponding to keys

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not int64
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype


   .. py:method:: broadcast(self, values: arkouda.pdarrayclass.pdarray, permute: bool = True) -> arkouda.pdarrayclass.pdarray

      Fill each group's segment with a constant value.

      :param values: The values to put in each group's segment
      :type values: pdarray
      :param permute: If True (default), permute broadcast values back to the ordering
                      of the original array on which GroupBy was called. If False, the
                      broadcast values are grouped by value.
      :type permute: bool

      :returns: The broadcast values
      :rtype: pdarray

      :raises TypeError: Raised if value is not a pdarray object
      :raises ValueError: Raised if the values array does not have one
          value per segment

      .. rubric:: Notes

      This function is a sparse analog of ``np.broadcast``. If a
      GroupBy object represents a sparse matrix (tensor), then
      this function takes a (dense) column vector and replicates
      each value to the non-zero elements in the corresponding row.

      .. rubric:: Examples

      >>> a = ak.array([0, 1, 0, 1, 0])
      >>> values = ak.array([3, 5])
      >>> g = ak.GroupBy(a)
      # By default, result is in original order
      >>> g.broadcast(values)
      array([3, 5, 3, 5, 3])

      # With permute=False, result is in grouped order
      >>> g.broadcast(values, permute=False)
      array([3, 3, 3, 5, 5]

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 1, 4, 4, 4, 1, 3, 3, 2, 2])
      >>> g = ak.GroupBy(a)
      >>> keys,counts = g.count()
      >>> g.broadcast(counts > 2)
      array([True False True True True False True True False False])
      >>> g.broadcast(counts == 3)
      array([True False True True True False True True False False])
      >>> g.broadcast(counts < 4)
      array([True True True True True True True True True True])



.. py:function:: broadcast(segments: arkouda.pdarrayclass.pdarray, values: arkouda.pdarrayclass.pdarray, size: Union[int, numpy.int64, numpy.uint64] = -1, permutation: Union[arkouda.pdarrayclass.pdarray, None] = None)

   Broadcast a dense column vector to the rows of a sparse matrix or grouped array.

   :param segments: Offsets of the start of each row in the sparse matrix or grouped array.
                    Must be sorted in ascending order.
   :type segments: pdarray, int64
   :param values: The values to broadcast, one per row (or group)
   :type values: pdarray
   :param size: The total number of nonzeros in the matrix. If permutation is given, this
                argument is ignored and the size is inferred from the permutation array.
   :type size: int
   :param permutation: The permutation to go from the original ordering of nonzeros to the ordering
                       grouped by row. To broadcast values back to the original ordering, this
                       permutation will be inverted. If no permutation is supplied, it is assumed
                       that the original nonzeros were already grouped by row. In this case, the
                       size argument must be given.
   :type permutation: pdarray, int64

   :returns: The broadcast values, one per nonzero
   :rtype: pdarray

   :raises ValueError: - If segments and values are different sizes
       - If segments are empty
       - If number of nonzeros (either user-specified or inferred from permutation)
         is less than one

   .. rubric:: Examples

   # Define a sparse matrix with 3 rows and 7 nonzeros
   >>> row_starts = ak.array([0, 2, 5])
   >>> nnz = 7
   # Broadcast the row number to each nonzero element
   >>> row_number = ak.arange(3)
   >>> ak.broadcast(row_starts, row_number, nnz)
   array([0 0 1 1 1 2 2])

   # If the original nonzeros were in reverse order...
   >>> permutation = ak.arange(6, -1, -1)
   >>> ak.broadcast(row_starts, row_number, permutation=permutation)
   array([2 2 1 1 1 0 0])


.. py:function:: load(path_prefix: str, file_format: str = 'HDF5', dataset: str = 'array', calc_string_offsets: bool = False) -> Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, Mapping[str, Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]]

   Load a pdarray previously saved with ``pdarray.save()``.

   :param path_prefix: Filename prefix used to save the original pdarray
   :type path_prefix: str
   :param file_format: 'HDF5' or 'Parquet'. Used to indicate the file type being loaded.
   :type file_format: str
   :param dataset: Dataset name where the pdarray was saved, defaults to 'array'
   :type dataset: str
   :param calc_string_offsets: If True the server will ignore Segmented Strings 'offsets' array and derive
                               it from the null-byte terminators.  Defaults to False currently
   :type calc_string_offsets: bool

   :returns: The pdarray or Strings that was previously saved
   :rtype: Union[pdarray, Strings]

   :raises TypeError: Raised if either path_prefix or dataset is not a str
   :raises ValueError: Raised if invalid file_format or if the dataset is not present in all hdf5 files or if the
       path_prefix does not correspond to files accessible to Arkouda
   :raises RuntimeError: Raised if the hdf5 files are present but there is an error in opening
       one or more of them

   .. seealso:: :obj:`save`, :obj:`load_all`, :obj:`read`


.. py:function:: gen_ranges(starts, ends, stride=1)

   Generate a segmented array of variable-length, contiguous ranges between pairs of start- and end-points.

   :param starts:
   :type starts: pdarray, int64
   :param The start value of each range:
   :param ends:
   :type ends: pdarray, int64
   :param The end value (exclusive) of each range:
   :param stride:
   :type stride: int
   :param Difference between successive elements of each range:

   :returns: * **segments** (*pdarray, int64*)
             * *The starting index of each range in the resulting array*
             * **ranges** (*pdarray, int64*)
             * *The actual ranges, flattened into a single array*


.. py:function:: _aggregator(func)


.. py:class:: SegArray(segments, values, copy=False, lengths=None, grouping=None)

   .. py:method:: from_multi_array(cls, m)
      :classmethod:

      Construct a SegArray from a list of columns. This essentially transposes the input,
      resulting in an array of rows.

      :param m: List of columns, the rows of which will form the sub-arrays of the output
      :type m: list of pdarray

      :returns: Array of rows of input
      :rtype: SegArray


   .. py:method:: concat(cls, x, axis=0, ordered=True)
      :classmethod:

      Concatenate a sequence of SegArrays

      :param x: The SegArrays to concatenate
      :type x: sequence of SegArray
      :param axis: Select vertical (0) or horizontal (1) concatenation. If axis=1, all
                   SegArrays must have same size.
      :type axis: 0 or 1
      :param ordered: Must be True. This option is present for compatibility only, because unordered
                      concatenation is not yet supported.
      :type ordered: bool

      :returns: The input arrays joined into one SegArray
      :rtype: SegArray


   .. py:method:: copy(self)

      Return a deep copy.


   .. py:method:: _get_lengths(self)


   .. py:method:: __getitem__(self, i)


   .. py:method:: __eq__(self, other)

      Return self==value.


   .. py:method:: __str__(self)

      Return str(self).


   .. py:method:: __repr__(self)

      Return repr(self).


   .. py:method:: get_suffixes(self, n, return_origins=True, proper=True)

      Return the n-long suffix of each sub-array, where possible

      :param n: Length of suffix
      :type n: int
      :param return_origins: If True, return a logical index indicating which sub-arrays
                             were long enough to return an n-suffix
      :type return_origins: bool
      :param proper: If True, only return proper suffixes, i.e. from sub-arrays
                     that are at least n+1 long. If False, allow the entire
                     sub-array to be returned as a suffix.
      :type proper: bool

      :returns: * **suffixes** (*list of pdarray*) -- An n-long list of pdarrays, essentially a table where each row is an n-suffix.
                  The number of rows is the number of True values in the returned mask.
                * **origin_indices** (*pdarray, bool*) -- Boolean array that is True where the sub-array was long enough to return
                  an n-suffix, False otherwise.


   .. py:method:: get_prefixes(self, n, return_origins=True, proper=True)

      Return all sub-array prefixes of length n (for sub-arrays that are at least n+1 long)

      :param n: Length of suffix
      :type n: int
      :param return_origins: If True, return a logical index indicating which sub-arrays
                             were long enough to return an n-prefix
      :type return_origins: bool
      :param proper: If True, only return proper prefixes, i.e. from sub-arrays
                     that are at least n+1 long. If False, allow the entire
                     sub-array to be returned as a prefix.
      :type proper: bool

      :returns: * **prefixes** (*list of pdarray*) -- An n-long list of pdarrays, essentially a table where each row is an n-prefix.
                  The number of rows is the number of True values in the returned mask.
                * **origin_indices** (*pdarray, bool*) -- Boolean array that is True where the sub-array was long enough to return
                  an n-suffix, False otherwise.


   .. py:method:: get_ngrams(self, n, return_origins=True)

      Return all n-grams from all sub-arrays.

      :param n: Length of n-gram
      :type n: int
      :param return_origins: If True, return an int64 array indicating which sub-array
                             each returned n-gram came from.
      :type return_origins: bool

      :returns: * **ngrams** (*list of pdarray*) -- An n-long list of pdarrays, essentially a table where each row is an n-gram.
                * **origin_indices** (*pdarray, int*) -- The index of the sub-array from which the corresponding n-gram originated


   .. py:method:: _normalize_index(self, j)


   .. py:method:: get_jth(self, j, return_origins=True, compressed=False, default=0)

      Select the j-th element of each sub-array, where possible.

      :param j: The index of the value to get from each sub-array. If j is negative,
                it counts backwards from the end of each sub-array.
      :type j: int
      :param return_origins: If True, return a logical index indicating where j is in bounds
      :type return_origins: bool
      :param compressed: If False, return array is same size as self, with default value
                         where j is out of bounds. If True, the return array only contains
                         values where j is in bounds.
      :type compressed: bool
      :param default: When compressed=False, the value to return when j is out of bounds
                      for the sub-array
      :type default: scalar

      :returns: * **val** (*pdarray*) -- compressed=False: The j-th value of each sub-array where j is in
                  bounds and the default value where j is out of bounds.
                  compressed=True: The j-th values of only the sub-arrays where j is
                  in bounds
                * **origin_indices** (*pdarray, bool*) -- A Boolean array that is True where j is in bounds for the sub-array.


   .. py:method:: set_jth(self, i, j, v)

      Set the j-th element of each sub-array in a subset.

      :param i: Indices of sub-arrays to set j-th element
      :type i: pdarray, int
      :param j: Index of value to set in each sub-array. If j is negative, it counts
                backwards from the end of the sub-array.
      :type j: int
      :param v: The value(s) to set. If v is a pdarray, it must have same length as i.
      :type v: pdarray or scalar

      :raises ValueError: If j is out of bounds in any of the sub-arrays specified by i.


   .. py:method:: get_length_n(self, n, return_origins=True)

      Return all sub-arrays of length n, as a list of columns.

      :param n: Length of sub-arrays to select
      :type n: int
      :param return_origins: Return a logical index indicating which sub-arrays are length n
      :type return_origins: bool

      :returns: * **columns** (*list of pdarray*) -- An n-long list of pdarray, where each row is one of the n-long
                  sub-arrays from the SegArray. The number of rows is the number of
                  True values in the returned mask.
                * **origin_indices** (*pdarray, bool*) -- Array of bool for each element of the SegArray, True where sub-array
                  has length n.


   .. py:method:: append(self, other, axis=0)

      Append other to self, either vertically (axis=0, length of resulting SegArray
      increases), or horizontally (axis=1, each sub-array of other appends to the
      corresponding sub-array of self).

      :param other: Array of sub-arrays to append
      :type other: SegArray
      :param axis: Whether to append vertically (0) or horizontally (1). If axis=1, other
                   must be same size as self.
      :type axis: 0 or 1

      :returns: axis=0: New SegArray containing all sub-arrays
                axis=1: New SegArray of same length, with pairs of sub-arrays concatenated
      :rtype: SegArray


   .. py:method:: append_single(self, x, prepend=False)

      Append a single value to each sub-array.

      :param x: Single value to append to each sub-array
      :type x: pdarray or scalar

      :returns: Copy of original SegArray with values from x appended to each sub-array
      :rtype: SegArray


   .. py:method:: prepend_single(self, x)


   .. py:method:: remove_repeats(self, return_multiplicity=False)

      Condense sequences of repeated values within a sub-array to a single value.

      :param return_multiplicity: If True, also return the number of times each value was repeated.
      :type return_multiplicity: bool

      :returns: * **norepeats** (*SegArray*) -- Sub-arrays with runs of repeated values replaced with single value
                * **multiplicity** (*SegArray*) -- If return_multiplicity=True, this array contains the number of times
                  each value in the returned SegArray was repeated in the original SegArray.


   .. py:method:: to_ndarray(self)

      Convert the array into a numpy.ndarray containing sub-arrays

      :returns: A numpy ndarray with the same sub-arrays (also numpy.ndarray) as this array
      :rtype: np.ndarray

      .. seealso:: :obj:`array`

      .. rubric:: Examples

      >>> segarr = ak.SegArray(ak.array([0, 4, 7]), ak.arange(12))
      >>> segarr.to_ndarray()
      array([[1, 2, 3, 4], [5, 6, 7], [8, 9, 10, 11, 12]])
      >>> type(segarr.to_ndarray())
      numpy.ndarray


   .. py:method:: sum(self, x=None)


   .. py:method:: prod(self, x=None)


   .. py:method:: min(self, x=None)


   .. py:method:: max(self, x=None)


   .. py:method:: argmin(self, x=None)


   .. py:method:: argmax(self, x=None)


   .. py:method:: any(self, x=None)


   .. py:method:: all(self, x=None)


   .. py:method:: OR(self, x=None)


   .. py:method:: AND(self, x=None)


   .. py:method:: XOR(self, x=None)


   .. py:method:: nunique(self, x=None)


   .. py:method:: mean(self, x=None)


   .. py:method:: aggregate(self, op, x=None)


   .. py:method:: unique(self, x=None)

      Return sub-arrays of unique values.

      :param x: The values to unique, per group. By default, the values of this
                SegArray's sub-arrays.
      :type x: pdarray

      :returns: Same number of sub-arrays as original SegArray, but elements in sub-array
                are unique and in sorted order.
      :rtype: SegArray


   .. py:method:: save(self, prefix_path, dataset='segarray', segment_suffix='_segments', value_suffix='_values', mode='truncate')

      Save the SegArray to HDF5. The result is a collection of HDF5 files, one file
      per locale of the arkouda server, where each filename starts with prefix_path.

      :param prefix_path: Directory and filename prefix that all output files will share
      :type prefix_path: str
      :param dataset: Name prefix for saved data within the HDF5 file
      :type dataset: str
      :param segment_suffix: Suffix to append to dataset name for segments array
      :type segment_suffix: str
      :param value_suffix: Suffix to append to dataset name for values array
      :type value_suffix: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', add data as a new column to existing files.
      :type mode: str {'truncate' | 'append'}

      :rtype: None

      .. rubric:: Notes

      Unlike for ak.Strings, SegArray is saved as two datasets in the top level of
      the HDF5 file, not nested under a group.


   .. py:method:: load(cls, prefix_path, dataset='segarray', segment_suffix='_segments', value_suffix='_values', mode='truncate')
      :classmethod:

      Load a saved SegArray from HDF5. All arguments msut match what
      was supplied to SegArray.save()

      :param prefix_path: Directory and filename prefix
      :type prefix_path: str
      :param dataset: Name prefix for saved data within the HDF5 files
      :type dataset: str
      :param segment_suffix: Suffix to append to dataset name for segments array
      :type segment_suffix: str
      :param value_suffix: Suffix to append to dataset name for values array
      :type value_suffix: str

      :rtype: SegArray


   .. py:method:: intersect(self, other)

      Computes the intersection of 2 SegArrays.

      :param other: SegArray to compute against
      :type other: SegArray

      :returns: Segments are the 1d intersections of the segments of self and other
      :rtype: SegArray

      .. seealso:: :obj:`pdarraysetops.intersect1d`

      .. rubric:: Examples

      >>> a = [1, 2, 3, 1, 4]
      >>> b = [3, 1, 4, 5]
      >>> c = [1, 3, 3, 5]
      >>> d = [2, 2, 4]
      >>> seg_a = ak.SegArray(ak.array([0, len(a)]), ak.array(a+b))
      >>> seg_b = ak.SegArray(ak.array([0, len(c)]), ak.array(c+d))
      >>> seg_a.intersect(seg_b)
      SegArray([
      [1, 3],
      [4]
      ])


   .. py:method:: union(self, other)

      Computes the union of 2 SegArrays.

      :param other: SegArray to compute against
      :type other: SegArray

      :returns: Segments are the 1d union of the segments of self and other
      :rtype: SegArray

      .. seealso:: :obj:`pdarraysetops.union1d`

      .. rubric:: Examples

      >>> a = [1, 2, 3, 1, 4]
      >>> b = [3, 1, 4, 5]
      >>> c = [1, 3, 3, 5]
      >>> d = [2, 2, 4]
      >>> seg_a = ak.SegArray(ak.array([0, len(a)]), ak.array(a+b))
      >>> seg_b = ak.SegArray(ak.array([0, len(c)]), ak.array(c+d))
      >>> seg_a.union(seg_b)
      SegArray([
      [1, 2, 3, 4, 5],
      [1, 2, 3, 4, 5]
      ])


   .. py:method:: setdiff(self, other)

      Computes the set difference of 2 SegArrays.

      :param other: SegArray to compute against
      :type other: SegArray

      :returns: Segments are the 1d set difference of the segments of self and other
      :rtype: SegArray

      .. seealso:: :obj:`pdarraysetops.setdiff1d`

      .. rubric:: Examples

      >>> a = [1, 2, 3, 1, 4]
      >>> b = [3, 1, 4, 5]
      >>> c = [1, 3, 3, 5]
      >>> d = [2, 2, 4]
      >>> seg_a = ak.SegArray(ak.array([0, len(a)]), ak.array(a+b))
      >>> seg_b = ak.SegArray(ak.array([0, len(c)]), ak.array(c+d))
      >>> seg_a.setdiff(seg_b)
      SegArray([
      [2, 4],
      [1, 3, 5]
      ])


   .. py:method:: setxor(self, other)

      Computes the symmetric difference of 2 SegArrays.

      :param other: SegArray to compute against
      :type other: SegArray

      :returns: Segments are the 1d symmetric difference of the segments of self and other
      :rtype: SegArray

      .. seealso:: :obj:`pdarraysetops.setxor1d`

      .. rubric:: Examples

      >>> a = [1, 2, 3, 1, 4]
      >>> b = [3, 1, 4, 5]
      >>> c = [1, 3, 3, 5]
      >>> d = [2, 2, 4]
      >>> seg_a = ak.SegArray(ak.array([0, len(a)]), ak.array(a+b))
      >>> seg_b = ak.SegArray(ak.array([0, len(c)]), ak.array(c+d))
      >>> seg_a.setxor(seg_b)
      SegArray([
      [2, 4, 5],
      [1, 3, 5, 2]
      ])


   .. py:method:: register(self, name, segment_suffix='_segments', value_suffix='_values', length_suffix='_lengths', grouping_suffix='_grouping')


   .. py:method:: unregister(self)


   .. py:method:: attach(cls, name, segment_suffix='_segments', value_suffix='_values', length_suffix='_lengths', grouping_suffix='_grouping')
      :classmethod:



.. py:class:: DataFrame(initialdata=None, index=None)

   Bases: :py:obj:`collections.UserDict`

   A DataFrame structure based on arkouda arrays.

   .. rubric:: Examples

   Create an empty DataFrame and add a column of data:

   >>> import arkouda as ak
   >>> import numpy as np
   >>> import pandas as pd
   >>> df = ak.DataFrame()
   >>> df['a'] = ak.array([1,2,3])

   Create a new DataFrame using a dictionary of data:

   >>> userName = ak.array(['Alice', 'Bob', 'Alice', 'Carol', 'Bob', 'Alice'])
   >>> userID = ak.array([111, 222, 111, 333, 222, 111])
   >>> item = ak.array([0, 0, 1, 1, 2, 0])
   >>> day = ak.array([5, 5, 6, 5, 6, 6])
   >>> amount = ak.array([0.5, 0.6, 1.1, 1.2, 4.3, 0.6])
   >>> df = ak.DataFrame({'userName': userName, 'userID': userID,
   >>>            'item': item, 'day': day, 'amount': amount})
   >>> df
   DataFrame(['userName', 'userID', 'item', 'day', 'amount'] [6 rows : 224 B])

   Indexing works slightly differently than with pandas:
   >>> df[0]
   {'userName': 'Alice', 'userID': 111, 'item': 0, 'day': 5, 'amount': 0.5}
   >>> df['userID']
   array([111, 222, 111, 333, 222, 111])
   >>> df['userName']
   array(['Alice', 'Bob', 'Alice', 'Carol', 'Bob', 'Alice'])
   >>> df[[1,5,7]]
     userName  userID  item  day  amount
   1      Bob     222     0    5     0.6
   2    Alice     111     1    6     1.1
   3    Carol     333     1    5     1.2

   Note that strides are not implemented except for stride = 1.
   >>> df[1:5:1]
   DataFrame(['userName', 'userID', 'item', 'day', 'amount'] [4 rows : 148 B])
   >>> df[ak.array([1,2,3])]
   DataFrame(['userName', 'userID', 'item', 'day', 'amount'] [3 rows : 112 B])
   >>> df[['userID', 'day']]
   DataFrame(['userID', 'day'] [6 rows : 96 B])

   .. py:attribute:: COLUMN_CLASSES
      

      

   .. py:method:: __getattr__(self, key)


   .. py:method:: __dir__(self)

      Default dir() implementation.


   .. py:method:: __delitem__(self, key)


   .. py:method:: __getitem__(self, key)


   .. py:method:: __setitem__(self, key, value)


   .. py:method:: __len__(self)

      Return the number of rows


   .. py:method:: _ncols(self)

      Number of columns.
      If index appears, we now want to utilize this
      because the actual index has been moved to a property


   .. py:method:: __str__(self)

      Returns a summary string of this dataframe.


   .. py:method:: _get_head_tail(self)


   .. py:method:: _get_head_tail_server(self)


   .. py:method:: _shape_str(self)


   .. py:method:: __repr__(self)

      Return ascii-formatted version of the dataframe.


   .. py:method:: _repr_html_(self)

      Return html-formatted version of the dataframe.


   .. py:method:: _ipython_key_completions_(self)


   .. py:method:: from_pandas(cls, pd_df)
      :classmethod:


   .. py:method:: _drop_column(self, keys)

      Drop a column or columns from the dataframe, in-place.

      keys : list
          The labels to be dropped on the given axis


   .. py:method:: _drop_row(self, keys)

      Drop a row or rows from the dataframe, in-place.

      keys : list
          The indexes to be dropped on the given axis


   .. py:method:: drop(self, keys, axis=0)

      Drop column/s or row/s from the dataframe, in-place.

      :param keys: The labels to be dropped on the given axis
      :type keys: str, int or list
      :param axis: The axis on which to drop from. 0/'index' - drop rows, 1/'columns' - drop columns
      :type axis: int or str

      .. rubric:: Examples

      Drop column
      >>> df.drop('col_name', axis=1)

      Drop Row
      >>> df.drop(1)
      or
      >>> df.drop(1, axis=0)


   .. py:method:: drop_duplicates(self, subset=None, keep='first')

      Drops duplcated rows and returns resulting DataFrame.

      If a subset of the columns are provided then only one instance of each
      duplicated row will be returned (keep determines which row).

      :param subset:
      :type subset: Iterable of column names to use to dedupe.
      :param keep: Determines which duplicates (if any) to keep.
      :type keep: {'first', 'last'}, default 'first'

      :returns: DataFrame with duplicates removed.
      :rtype: DataFrame


   .. py:method:: size(self)
      :property:

      Returns the number of bytes on the arkouda server.


   .. py:method:: dtypes(self)
      :property:


   .. py:method:: empty(self)
      :property:


   .. py:method:: shape(self)
      :property:


   .. py:method:: columns(self)
      :property:


   .. py:method:: index(self)
      :property:


   .. py:method:: _set_index(self, value)


   .. py:method:: reset_index(self, size=False)

      Set the index to an integer range.

      Useful if this dataframe is the result of a slice operation from
      another dataframe, or if you have permuted the rows and no longer need
      to keep that ordering on the rows.

      :param size: If size is passed, do not attempt to determine size based on
                   existing column sizes. Assume caller handles consistency correctly.
      :type size: int

      .. note::

         Pandas adds a column 'index' to indicate the original index. Arkouda does not currently
         support this behavior.


   .. py:method:: info(self)
      :property:

      Returns a summary string of this dataframe.


   .. py:method:: update_size(self)

      Computes the number of bytes on the arkouda server.


   .. py:method:: rename(self, mapper)

      Rename columns in-place according to a mapping.

      :param mapper: Function or dictionary mapping existing column names to
                     new column names. Nonexistent names will not raise an
                     error.
      :type mapper: callable or dict-like

      :returns: Renaming occurs in-place, but result is also returned,
                for compatibility.
      :rtype: self


   .. py:method:: append(self, other, ordered=True)

      Concatenate data from 'other' onto the end of this DataFrame, in place.

      Explicitly, use the arkouda concatenate function to append the data
      from each column in other to the end of self. This operation is done
      in place, in the sense that the underlying pdarrays are updated from
      the result of the arkouda concatenate function, rather than returning
      a new DataFrame object containing the result.

      :param other: The DataFrame object whose data will be appended to this DataFrame.
      :type other: DataFrame
      :param ordered: If False, allow rows to be interleaved for better performance (but
                      data within a row remains together). By default, append all rows
                      to the end, in input order.
      :type ordered: bool

      :returns: Appending occurs in-place, but result is returned for compatibility.
      :rtype: self


   .. py:method:: concat(cls, items, ordered=True)
      :classmethod:

      Essentially an append, but diffenent formatting


   .. py:method:: head(self, n=5)

      Return the first `n` rows.

      This function returns the first `n` rows of the the dataframe. It is
      useful for quickly verifying data, for example, after sorting or
      appending rows.

      :param n: Number of rows to select.
      :type n: int

      :returns: The first `n` rows of the DataFrame.
      :rtype: akutil.DataFrame

      .. seealso:: :obj:`tail`


   .. py:method:: tail(self, n=5)

      Return the last `n` rows.

      This function returns the last `n` rows for the dataframe. It is
      useful for quickly testing if your object has the right type of data in
      it.

      :param n: Number of rows to select.
      :type n: int (default=5)

      :returns: The last `n` rows of the DataFrame.
      :rtype: akutil.DataFrame

      .. seealso:: :obj:`akutil.dataframe.head`


   .. py:method:: sample(self, n=5)

      Return a random sample of `n` rows.

      :param n: Number of rows to return.
      :type n: int (default=5)

      :returns: The sampled `n` rows of the DataFrame.
      :rtype: akutil.DataFrame


   .. py:method:: GroupBy(self, keys, use_series=False)

      Group the dataframe by a column or a list of columns.

      :param keys: An (ordered) list of column names or a single string to group by.
      :type keys: string or list
      :param use_series:
      :type use_series: If True, returns an akutil.GroupBy oject. Otherwise an arkouda GroupBy object

      :returns: Either an akutil GroupBy or an arkouda GroupBy object.
      :rtype: GroupBy

      .. seealso:: :obj:`arkouda.GroupBy`


   .. py:method:: memory_usage(self, unit='GB')

      Print the size of this DataFrame.

      :param unit: Unit to return. One of {'KB', 'MB', 'GB'}.
      :type unit: str

      :returns: The number of bytes used by this DataFrame in [unit]s.
      :rtype: int


   .. py:method:: to_pandas(self, datalimit=maxTransferBytes, retain_index=False)

      Send this DataFrame to a pandas DataFrame.

      :param datalimit: The maximum number size, in megabytes to transfer. The requested
                        DataFrame will be converted to a pandas DataFrame only if the
                        estimated size of the DataFrame does not exceed this value.
      :type datalimit: int (default=arkouda.client.maxTransferBytes)
      :param retain_index: Normally, to_pandas() creates a new range index object. If you want
                           to keep the index column, set this to True.
      :type retain_index: book (default=False)

      :returns: The result of converting this DataFrame to a pandas DataFrame.
      :rtype: pandas.DataFrame


   .. py:method:: save(self, path, index=False)

      Save DataFrame to disk, preserving column names.

      :param path: File path to save data
      :type path: str
      :param index: If True, save the index column. By default, do not save the index.
      :type index: bool

      .. rubric:: Notes

      This method saves one file per locale of the arkouda server. All
      files are prefixed by the path argument and suffixed by their
      locale number.


   .. py:method:: save_table(self, prefix_path, columns=None, index=False, file_format='HDF5')

      Save a dataframe as a table in Parquet

      :param prefix_path: Path and filename prefix to save to
      :type prefix_path: str
      :param columns: List of columns to include in the file. If None, writes out all columns
      :type columns: List
      :param file_format: 'HDF5' or 'Parquet'. Defaults to 'HDF5'
      :type file_format: str
      :param index: If true, include the index values in the save file.
      :type index: Bool

      .. rubric:: Notes

      This function currently uses 'truncate' mode to ensure the file exists before appending.


   .. py:method:: load_table(cls, prefix_path)
      :classmethod:


   .. py:method:: argsort(self, key, ascending=True)

      Return the permutation that sorts the dataframe by `key`.

      :param key: The key to sort on.
      :type key: str

      :returns: The permutation array that sorts the data on `key`.
      :rtype: ak.pdarray


   .. py:method:: coargsort(self, keys, ascending=True)

      Return the permutation that sorts the dataframe by `keys`.

      Sorting using Strings may not yield correct results

      :param keys: The keys to sort on.
      :type keys: list

      :returns: The permutation array that sorts the data on `keys`.
      :rtype: ak.pdarray


   .. py:method:: sort_values(self, by=None, ascending=True)

      Sort the DataFrame by one or more columns.

      If no column is specified, all columns are used.

      Note: Fails on sorting ak.Strings when multiple columns being sorted

      :param by: The name(s) of the column(s) to sort by.
      :type by: str or list/tuple of str
      :param ascending: Sort values in ascending (default) or descending order.
      :type ascending: bool

      .. seealso:: :obj:`apply_permutation`, :obj:`sorted`


   .. py:method:: apply_permutation(self, perm)

      Apply a permutation to an entire DataFrame.

      This may be useful if you want to unsort an DataFrame, or even to
      apply an arbitrary permutation such as the inverse of a sorting
      permutation.

      :param perm: A permutation array. Should be the same size as the data
                   arrays, and should consist of the integers [0,size-1] in
                   some order. Very minimal testing is done to ensure this
                   is a permutation.
      :type perm: ak.pdarray

      .. seealso:: :obj:`sort`


   .. py:method:: filter_by_range(self, keys, low=1, high=None)

      Find all rows where the value count of the items in a given set of
      columns (keys) is within the range [low, high].

      To filter by a specific value, set low == high.

      :param keys: The names of the columns to group by
      :type keys: list or str
      :param low: The lowest value count.
      :type low: int (default=1)
      :param high: The highest value count, default to unlimited.
      :type high: int (default=None)

      :returns: An array of boolean values for qualified rows in this DataFrame.
      :rtype: pdarray

      .. seealso:: :obj:`filter_by_count`


   .. py:method:: copy(self, deep=True)

      Make a copy of this object's data.

      When `deep = True` (default), a new object will be created with a copy of
      the calling object's data. Modifications to the data of the copy will not
      be reflected in the original object.


      When `deep = False` a new object will be created without copying the
      calling object's data. Any changes to the data of the original object will
      be reflected in the shallow copy, and vice versa.

      :param deep: When True, return a deep copy. Otherwise, return a shallow copy.
      :type deep: bool (default=True)

      :returns: A deep or shallow copy according to caller specification.
      :rtype: aku.DataFrame


   .. py:method:: groupby(self, keys, use_series=True)

      Group the dataframe by a column or a list of columns.  Alias for GroupBy

      :param keys:
      :type keys: a single column name or a list of column names
      :param use_series:
      :type use_series: Change return type to Arkouda Groupby object.

      :rtype: An arkouda Groupby instance



.. py:function:: sorted(df, column=False)

   Analogous to other python 'sorted(obj)' functions in that it returns
   a sorted copy of the DataFrame.

   If no sort key is specified, sort by the first key returned.

   Note: This fails on sorting ak.Strings, as does DataFrame.sort().

   :param df: The DataFrame to sort.
   :type df: akutil.dataframe.DataFrame
   :param column: The name of the column to sort by.
   :type column: str

   :returns: A sorted copy of the original DataFrame.
   :rtype: akutil.dataframe.DataFrame


.. py:function:: intersect(a, b, positions=True, unique=False)

   Find the intersection of two arkouda arrays.

   This function can be especially useful when `positions=True` so
   that the caller gets the indices of values present in both arrays.

   :param a: An array of strings
   :type a: ak.Strings or ak.pdarray
   :param b: An array of strings
   :type b: ak.Strings or ak.pdarray
   :param positions: Return tuple of boolean pdarrays that indicate positions in a and b
                     where the values are in the intersection.
   :type positions: bool (default=True)
   :param unique: If the number of distinct values in `a` (and `b`) is equal to the size of
                  `a` (and `b`), there is a more efficient method to compute the intersection.
   :type unique: bool (default=False)

   :returns: The indices of `a` and `b` where any element occurs at least once in both
             arrays.
   :rtype: (ak.pdarray, ak.pdarray)


.. py:function:: invert_permutation(perm)

   Find the inverse of a permutation array.

   :param perm: The permutation array.
   :type perm: ak.pdarray

   :returns: The inverse of the permutation array.
   :rtype: ak.pdarray


.. py:function:: intx(a, b)

   Find all the rows that are in both dataframes. Columns should be in
   identical order.

   Note: does not work for columns of floating point values, but does work for
   Strings, pdarrays of int64 type, and Categorical *should* work.


.. py:class:: Row(dict=None, /, **kwargs)

   Bases: :py:obj:`collections.UserDict`

   This class is useful for printing and working with individual rows of a
   of an aku.DataFrame.

   .. py:method:: __str__(self)

      Return ascii-formatted version of the dataframe.


   .. py:method:: __repr__(self)

      Return repr(self).


   .. py:method:: _repr_html_(self)

      Return html-formatted version of the dataframe.



.. py:class:: pdarray(name: str, mydtype: numpy.dtype, size: arkouda.dtypes.int_scalars, ndim: arkouda.dtypes.int_scalars, shape: Sequence[int], itemsize: arkouda.dtypes.int_scalars)

   The basic arkouda array class. This class contains only the
   attributies of the array; the data resides on the arkouda
   server. When a server operation results in a new array, arkouda
   will create a pdarray instance that points to the array data on
   the server. As such, the user should not initialize pdarray
   instances directly.

   .. attribute:: name

      The server-side identifier for the array

      :type: str

   .. attribute:: dtype

      The element type of the array

      :type: dtype

   .. attribute:: size

      The number of elements in the array

      :type: int_scalars

   .. attribute:: ndim

      The rank of the array (currently only rank 1 arrays supported)

      :type: int_scalars

   .. attribute:: shape

      A list or tuple containing the sizes of each dimension of the array

      :type: Sequence[int]

   .. attribute:: itemsize

      The size in bytes of each element

      :type: int_scalars

   .. py:attribute:: BinOps
      

      

   .. py:attribute:: OpEqOps
      

      

   .. py:attribute:: objtype
      :annotation: = pdarray

      

   .. py:attribute:: __array_priority__
      :annotation: = 1000

      

   .. py:method:: __del__(self)


   .. py:method:: __bool__(self) -> bool


   .. py:method:: __len__(self)


   .. py:method:: __str__(self)

      Return str(self).


   .. py:method:: __repr__(self)

      Return repr(self).


   .. py:method:: format_other(self, other: object) -> str

      Attempt to cast scalar other to the element dtype of this pdarray,
      and print the resulting value to a string (e.g. for sending to a
      server command). The user should not call this function directly.

      :param other: The scalar to be cast to the pdarray.dtype
      :type other: object

      :rtype: string representation of np.dtype corresponding to the other parameter

      :raises TypeError: Raised if the other parameter cannot be converted to
          Numpy dtype


   .. py:method:: _binop(self, other: pdarray, op: str) -> pdarray

      Executes binary operation specified by the op string

      :param other: The pdarray upon which the binop is to be executed
      :type other: pdarray
      :param op: The binop to be executed
      :type op: str

      :returns: A pdarray encapsulating the binop result
      :rtype: pdarray

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set, or if the
          pdarray sizes don't match
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype


   .. py:method:: _r_binop(self, other: pdarray, op: str) -> pdarray

      Executes reverse binary operation specified by the op string

      :param other: The pdarray upon which the reverse binop is to be executed
      :type other: pdarray
      :param op: The name of the reverse binop to be executed
      :type op: str

      :returns: A pdarray encapsulating the reverse binop result
      :rtype: pdarray

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype


   .. py:method:: __add__(self, other)


   .. py:method:: __radd__(self, other)


   .. py:method:: __sub__(self, other)


   .. py:method:: __rsub__(self, other)


   .. py:method:: __mul__(self, other)


   .. py:method:: __rmul__(self, other)


   .. py:method:: __truediv__(self, other)


   .. py:method:: __rtruediv__(self, other)


   .. py:method:: __floordiv__(self, other)


   .. py:method:: __rfloordiv__(self, other)


   .. py:method:: __mod__(self, other)


   .. py:method:: __rmod__(self, other)


   .. py:method:: __lshift__(self, other)


   .. py:method:: __rlshift__(self, other)


   .. py:method:: __rshift__(self, other)


   .. py:method:: __rrshift__(self, other)


   .. py:method:: __and__(self, other)


   .. py:method:: __rand__(self, other)


   .. py:method:: __or__(self, other)


   .. py:method:: __ror__(self, other)


   .. py:method:: __xor__(self, other)


   .. py:method:: __rxor__(self, other)


   .. py:method:: __pow__(self, other)


   .. py:method:: __rpow__(self, other)


   .. py:method:: __lt__(self, other)

      Return self<value.


   .. py:method:: __gt__(self, other)

      Return self>value.


   .. py:method:: __le__(self, other)

      Return self<=value.


   .. py:method:: __ge__(self, other)

      Return self>=value.


   .. py:method:: __eq__(self, other)

      Return self==value.


   .. py:method:: __ne__(self, other)

      Return self!=value.


   .. py:method:: __neg__(self)


   .. py:method:: __invert__(self)


   .. py:method:: opeq(self, other, op)


   .. py:method:: __iadd__(self, other)


   .. py:method:: __isub__(self, other)


   .. py:method:: __imul__(self, other)


   .. py:method:: __itruediv__(self, other)


   .. py:method:: __ifloordiv__(self, other)


   .. py:method:: __ilshift__(self, other)


   .. py:method:: __irshift__(self, other)


   .. py:method:: __iand__(self, other)


   .. py:method:: __ior__(self, other)


   .. py:method:: __ixor__(self, other)


   .. py:method:: __ipow__(self, other)


   .. py:method:: __iter__(self)
      :abstractmethod:


   .. py:method:: __getitem__(self, key)


   .. py:method:: __setitem__(self, key, value)


   .. py:method:: fill(self, value: arkouda.dtypes.numeric_scalars) -> None

      Fill the array (in place) with a constant value.

      :param value:
      :type value: numeric_scalars

      :raises TypeError: Raised if value is not an int, int64, float, or float64


   .. py:method:: any(self) -> numpy.bool_

      Return True iff any element of the array evaluates to True.


   .. py:method:: all(self) -> numpy.bool_

      Return True iff all elements of the array evaluate to True.


   .. py:method:: is_registered(self) -> numpy.bool_

      Return True iff the object is contained in the registry

      :param None:

      :returns: Indicates if the object is contained in the registry
      :rtype: bool

      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: _list_component_names(self) -> List[str]

      Internal Function that returns a list of all component names

      :param None:

      :returns: List of all component names
      :rtype: List[str]


   .. py:method:: info(self) -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str


   .. py:method:: pretty_print_info(self) -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None


   .. py:method:: is_sorted(self) -> numpy.bool_

      Return True iff the array is monotonically non-decreasing.

      :param None:

      :returns: Indicates if the array is monotonically non-decreasing
      :rtype: bool

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: sum(self) -> arkouda.dtypes.numeric_and_bool_scalars

      Return the sum of all elements in the array.


   .. py:method:: prod(self) -> numpy.float64

      Return the product of all elements in the array. Return value is
      always a np.float64 or np.int64.


   .. py:method:: min(self) -> arkouda.dtypes.numpy_scalars

      Return the minimum value of the array.


   .. py:method:: max(self) -> arkouda.dtypes.numpy_scalars

      Return the maximum value of the array.


   .. py:method:: argmin(self) -> numpy.int64

      Return the index of the first occurrence of the array min value


   .. py:method:: argmax(self) -> numpy.int64

      Return the index of the first occurrence of the array max value.


   .. py:method:: mean(self) -> numpy.float64

      Return the mean of the array.


   .. py:method:: var(self, ddof: arkouda.dtypes.int_scalars = 0) -> numpy.float64

      Compute the variance. See ``arkouda.var`` for details.

      :param ddof: "Delta Degrees of Freedom" used in calculating var
      :type ddof: int_scalars

      :returns: The scalar variance of the array
      :rtype: np.float64

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises ValueError: Raised if the ddof >= pdarray size
      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: std(self, ddof: arkouda.dtypes.int_scalars = 0) -> numpy.float64

      Compute the standard deviation. See ``arkouda.std`` for details.

      :param ddof: "Delta Degrees of Freedom" used in calculating std
      :type ddof: int_scalars

      :returns: The scalar standard deviation of the array
      :rtype: np.float64

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: mink(self, k: arkouda.dtypes.int_scalars) -> pdarray

      Compute the minimum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: The maximum `k` values from pda
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray


   .. py:method:: maxk(self, k: arkouda.dtypes.int_scalars) -> pdarray

      Compute the maximum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: The maximum `k` values from pda
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray


   .. py:method:: argmink(self, k: arkouda.dtypes.int_scalars) -> pdarray

      Compute the minimum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: Indices corresponding to the maximum `k` values from pda
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray


   .. py:method:: argmaxk(self, k: arkouda.dtypes.int_scalars) -> pdarray

      Finds the indices corresponding to the maximum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: Indices corresponding to the  maximum `k` values, sorted
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray


   .. py:method:: popcount(self) -> pdarray

      Find the population (number of bits set) in each element. See `ak.popcount`.


   .. py:method:: parity(self) -> pdarray

      Find the parity (XOR of all bits) in each element. See `ak.parity`.


   .. py:method:: clz(self) -> pdarray

      Count the number of leading zeros in each element. See `ak.clz`.


   .. py:method:: ctz(self) -> pdarray

      Count the number of trailing zeros in each element. See `ak.ctz`.


   .. py:method:: rotl(self, other) -> pdarray

      Rotate bits left by <other>.


   .. py:method:: rotr(self, other) -> pdarray

      Rotate bits right by <other>.


   .. py:method:: astype(self, dtype) -> pdarray

      Cast values of pdarray to provided dtype

      :param dtype: Dtype to cast to
      :type dtype: np.dtype or str

      :returns: An arkouda pdarray with values converted to the specified data type
      :rtype: ak.pdarray

      .. rubric:: Notes

      This is essentially shorthand for ak.cast(x, '<dtype>') where x is a pdarray.


   .. py:method:: reshape(self, *shape, order='row_major')

      Gives a new shape to an array without changing its data.

      :param shape: The new shape should be compatible with the original shape.
      :type shape: int, tuple of ints, or pdarray
      :param order: Read the elements of the pdarray in this index order
                    By default, read the elements in row_major or C-like order where the last index changes the fastest
                    If 'column_major' or 'F', read the elements in column_major or Fortran-like order where the first index changes the fastest
      :type order: str {'row_major' | 'C' | 'column_major' | 'F'}

      :returns: An arrayview object with the data from the array but with the new shape
      :rtype: ArrayView


   .. py:method:: to_ndarray(self) -> numpy.ndarray

      Convert the array to a np.ndarray, transferring array data from the
      Arkouda server to client-side Python. Note: if the pdarray size exceeds
      client.maxTransferBytes, a RuntimeError is raised.

      :returns: A numpy ndarray with the same attributes and data as the pdarray
      :rtype: np.ndarray

      :raises RuntimeError: Raised if there is a server-side error thrown, if the pdarray size
          exceeds the built-in client.maxTransferBytes size limit, or if the bytes
          received does not match expected number of bytes

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_ndarray()
      array([0, 1, 2, 3, 4])

      >>> type(a.to_ndarray())
      numpy.ndarray


   .. py:method:: to_cuda(self)

      Convert the array to a Numba DeviceND array, transferring array data from the
      arkouda server to Python via ndarray. If the array exceeds a builtin size limit,
      a RuntimeError is raised.

      :returns: A Numba ndarray with the same attributes and data as the pdarray; on GPU
      :rtype: numba.DeviceNDArray

      :raises ImportError: Raised if CUDA is not available
      :raises ModuleNotFoundError: Raised if Numba is either not installed or not enabled
      :raises RuntimeError: Raised if there is a server-side error thrown in the course of retrieving
          the pdarray.

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_cuda()
      array([0, 1, 2, 3, 4])

      >>> type(a.to_cuda())
      numpy.devicendarray


   .. py:method:: save(self, prefix_path: str, dataset: str = 'array', mode: str = 'truncate', compressed: bool = False, file_format: str = 'HDF5') -> str

      Save the pdarray to HDF5 or Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param compressed: Defaults to False. When True, files will be written with Snappy compression
                         and RLE bit packing. This is currently only supported on Parquet files and will
                         not impact the generated files when writing HDF5 files.
      :type compressed: bool
      :param file_format: By default, saved files will be written to the HDF5 file format. If
                          'Parquet', the files will be written to the Parquet file format. This
                          is case insensitive.
      :type file_format: str {'HDF5', 'Parquet'}

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray
      :raises ValueError: Raised if there is an error in parsing the prefix path pointing to
          file write location or if the mode parameter is neither truncate
          nor append
      :raises TypeError: Raised if any one of the prefix_path, dataset, or mode parameters
          is not a string

      .. seealso:: :obj:`save_all`, :obj:`load`, :obj:`read`

      .. rubric:: Notes

      The prefix_path must be visible to the arkouda server and the user must
      have write permission.

      Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales``. If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.

      .. rubric:: Examples

      >>> a = ak.arange(0, 100, 1)
      >>> a.save('arkouda_range', dataset='array')
      >>> a.save('arkouda_range_parquet', dataset='array', file_format='Parquet')

      Array is saved in numLocales files with names like ``tmp/arkouda_range_LOCALE0``

      The array can be read back in as follows

      >>> b = ak.read('arkouda_range', dataset='array')
      >>> (a == b).all()
      True

      >>> c = ak.read_parquet('arkouda_range_parquet*')
      >>> (c == b).all()
      True


   .. py:method:: save_parquet(self, prefix_path: str, dataset: str = 'array', mode: str = 'truncate', compressed: bool = False) -> str

      Save the pdarray to Parquet. The result is a collection of Parquet files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in Parquet files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
      :type mode: str {'truncate', 'append'}
      :param compressed: By default, write without Snappy compression and RLE encoding.
      :type compressed: bool

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray
      :raises ValueError: Raised if there is an error in parsing the prefix path pointing to
          file write location or if the mode parameter is neither truncate
          nor append
      :raises TypeError: Raised if any one of the prefix_path, dataset, or mode parameters
          is not a string

      .. seealso:: :obj:`save`, :obj:`save_all`, :obj:`load`, :obj:`read`

      .. rubric:: Notes

      The prefix_path must be visible to the arkouda server and the user must
      have write permission.

      Output files have names of the form ``<prefix_path>_LOCALE<i>.parquet``, where ``<i>``
      ranges from 0 to ``numLocales``. If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.

      .. rubric:: Examples

      >>> a = ak.arange(0, 100, 1)
      >>> a.save_parquet('arkouda_range')

      Array is saved in numLocales files with names like ``arkouda_range_LOCALE0000.parquet``

      The array can be read back in as follows

      >>> b = ak.read('arkouda_range')
      >>> (a == b).all()
      True


   .. py:method:: save_hdf(self, prefix_path: str, dataset: str = 'array', mode: str = 'truncate') -> str

      Save the pdarray to HDF5. The result is a collection of HDF5 files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in HDF5 files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
      :type mode: str {'truncate', 'append'}
      :param compressed: By default, write without Snappy compression and RLE encoding.
      :type compressed: bool

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray
      :raises ValueError: Raised if there is an error in parsing the prefix path pointing to
          file write location or if the mode parameter is neither truncate
          nor append
      :raises TypeError: Raised if any one of the prefix_path, dataset, or mode parameters
          is not a string

      .. seealso:: :obj:`save`, :obj:`save_all`, :obj:`load`, :obj:`read`

      .. rubric:: Notes

      The prefix_path must be visible to the arkouda server and the user must
      have write permission.

      Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales``. If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.

      .. rubric:: Examples

      >>> a = ak.arange(0, 100, 1)
      >>> a.save_hdf('arkouda_range')

      Array is saved in numLocales files with names like ``arkouda_range_LOCALE0000``

      The array can be read back in as follows

      >>> b = ak.read('arkouda_range')
      >>> (a == b).all()
      True


   .. py:method:: register(self, user_defined_name: str) -> pdarray

      Register this pdarray with a user defined name in the arkouda server
      so it can be attached to later using pdarray.attach()
      This is an in-place operation, registering a pdarray more than once will
      update the name in the registry and remove the previously registered name.
      A name can only be registered to one pdarray at a time.

      :param user_defined_name: user defined name array is to be registered under
      :type user_defined_name: str

      :returns: The same pdarray which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support a fluid programming style.
                Please note you cannot register two different pdarrays with the same name.
      :rtype: pdarray

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the pdarray with the user_defined_name
          If the user is attempting to register more than one pdarray with the same name, the former should be
          unregistered first to free up the registration name.

      .. seealso:: :obj:`attach`, :obj:`unregister`, :obj:`is_registered`, :obj:`list_registry`, :obj:`unregister_pdarray_by_name`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion
      until they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()


   .. py:method:: unregister(self) -> None

      Unregister a pdarray in the arkouda server which was previously
      registered using register() and/or attahced to using attach()


      :rtype: None

      :raises RuntimeError: Raised if the server could not find the internal name/symbol to remove

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion until
      they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()


   .. py:method:: attach(user_defined_name: str) -> pdarray
      :staticmethod:

      class method to return a pdarray attached to the registered name in the arkouda
      server which was registered using register()

      :param user_defined_name: user defined name which array was registered under
      :type user_defined_name: str

      :returns: pdarray which is bound to corresponding server side component that was registered with user_defined_name
      :rtype: pdarray

      :raises TypeError: Raised if user_defined_name is not a str

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion
      until they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()


   .. py:method:: _get_grouping_keys(self) -> List[pdarray]

      Private method for generating grouping keys used by GroupBy.

      API: this method must be defined by all groupable arrays, and it
      must return a list of arrays that can be (co)argsorted.



.. py:function:: arange(*args, **kwargs) -> arkouda.pdarrayclass.pdarray

   arange([start,] stop[, stride,] dtype=int64)

   Create a pdarray of consecutive integers within the interval [start, stop).
   If only one arg is given then arg is the stop parameter. If two args are
   given, then the first arg is start and second is stop. If three args are
   given, then the first arg is start, second is stop, third is stride.

   The return value is cast to type dtype

   :param start: Starting value (inclusive)
   :type start: int_scalars, optional
   :param stop: Stopping value (exclusive)
   :type stop: int_scalars
   :param stride: The difference between consecutive elements, the default stride is 1,
                  if stride is specified then start must also be specified.
   :type stride: int_scalars, optional
   :param dtype: The target dtype to cast values to
   :type dtype: np.dtype, type, or str

   :returns: Integers from start (inclusive) to stop (exclusive) by stride
   :rtype: pdarray, dtype

   :raises TypeError: Raised if start, stop, or stride is not an int object
   :raises ZeroDivisionError: Raised if stride == 0

   .. seealso:: :obj:`linspace`, :obj:`zeros`, :obj:`ones`, :obj:`randint`

   .. rubric:: Notes

   Negative strides result in decreasing values. Currently, only int64
   pdarrays can be created with this method. For float64 arrays, use
   the linspace method.

   .. rubric:: Examples

   >>> ak.arange(0, 5, 1)
   array([0, 1, 2, 3, 4])

   >>> ak.arange(5, 0, -1)
   array([5, 4, 3, 2, 1])

   >>> ak.arange(0, 10, 2)
   array([0, 2, 4, 6, 8])

   >>> ak.arange(-5, -10, -1)
   array([-5, -6, -7, -8, -9])


.. py:function:: ones(size: Union[arkouda.dtypes.int_scalars, str], dtype: Union[numpy.dtype, type, str] = float64) -> arkouda.pdarrayclass.pdarray

   Create a pdarray filled with ones.

   :param size: Size of the array (only rank-1 arrays supported)
   :type size: int_scalars
   :param dtype: Resulting array type, default float64
   :type dtype: Union[float64, int64, bool]

   :returns: Ones of the requested size and dtype
   :rtype: pdarray

   :raises TypeError: Raised if the supplied dtype is not supported or if the size
       parameter is neither an int nor a str that is parseable to an int.

   .. seealso:: :obj:`zeros`, :obj:`ones_like`

   .. rubric:: Examples

   >>> ak.ones(5, dtype=ak.int64)
   array([1, 1, 1, 1, 1])

   >>> ak.ones(5, dtype=ak.float64)
   array([1, 1, 1, 1, 1])

   >>> ak.ones(5, dtype=ak.bool)
   array([True, True, True, True, True])


.. py:function:: argsort(pda: Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, arkouda.categorical.Categorical], algorithm: SortingAlgorithm = SortingAlgorithm.RadixSortLSD) -> arkouda.pdarrayclass.pdarray

   Return the permutation that sorts the array.

   :param pda: The array to sort (int64, uint64, or float64)
   :type pda: pdarray or Strings or Categorical

   :returns: The indices such that ``pda[indices]`` is sorted
   :rtype: pdarray, int64

   :raises TypeError: Raised if the parameter is other than a pdarray or Strings

   .. seealso:: :obj:`coargsort`

   .. rubric:: Notes

   Uses a least-significant-digit radix sort, which is stable and
   resilient to non-uniformity in data but communication intensive.

   .. rubric:: Examples

   >>> a = ak.randint(0, 10, 10)
   >>> perm = ak.argsort(a)
   >>> a[perm]
   array([0, 1, 1, 3, 4, 5, 7, 8, 8, 9])


.. py:function:: in1d(pda1: Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, Categorical], pda2: Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, Categorical], invert: bool = False) -> arkouda.pdarrayclass.pdarray

   Test whether each element of a 1-D array is also present in a second array.

   Returns a boolean array the same length as `pda1` that is True
   where an element of `pda1` is in `pda2` and False otherwise.

   :param pda1: Input array.
   :type pda1: pdarray or Strings or Categorical
   :param pda2: The values against which to test each value of `pda1`. Must be the
                same type as `pda1`.
   :type pda2: pdarray or Strings or Categorical
   :param invert: If True, the values in the returned array are inverted (that is,
                  False where an element of `pda1` is in `pda2` and True otherwise).
                  Default is False. ``ak.in1d(a, b, invert=True)`` is equivalent
                  to (but is faster than) ``~ak.in1d(a, b)``.
   :type invert: bool, optional

   :returns: The values `pda1[in1d]` are in `pda2`.
   :rtype: pdarray, bool

   :raises TypeError: Raised if either pda1 or pda2 is not a pdarray, Strings, or
       Categorical object or if invert is not a bool
   :raises RuntimeError: Raised if the dtype of either array is not supported

   .. seealso:: :obj:`unique`, :obj:`intersect1d`, :obj:`union1d`

   .. rubric:: Notes

   `in1d` can be considered as an element-wise function version of the
   python keyword `in`, for 1-D sequences. ``in1d(a, b)`` is logically
   equivalent to ``ak.array([item in b for item in a])``, but is much
   faster and scales to arbitrarily large ``a``.

   ak.in1d is not supported for bool or float64 pdarrays

   .. rubric:: Examples

   >>> ak.in1d(ak.array([-1, 0, 1]), ak.array([-2, 0, 2]))
   array([False, True, False])

   >>> ak.in1d(ak.array(['one','two']),ak.array(['two', 'three','four','five']))
   array([False, True])


.. py:function:: coargsort(arrays: Sequence[Union[arkouda.strings.Strings, arkouda.pdarrayclass.pdarray, arkouda.categorical.Categorical]], algorithm: SortingAlgorithm = SortingAlgorithm.RadixSortLSD) -> arkouda.pdarrayclass.pdarray

   Return the permutation that groups the rows (left-to-right), if the
   input arrays are treated as columns. The permutation sorts numeric
   columns, but not strings/Categoricals -- strings/Categoricals are grouped, but not ordered.

   :param arrays: The columns (int64, uint64, float64, Strings, or Categorical) to sort by row
   :type arrays: Sequence[Union[Strings, pdarray, Categorical]]

   :returns: The indices that permute the rows to grouped order
   :rtype: pdarray, int64

   :raises ValueError: Raised if the pdarrays are not of the same size or if the parameter
       is not an Iterable containing pdarrays, Strings, or Categoricals

   .. seealso:: :obj:`argsort`

   .. rubric:: Notes

   Uses a least-significant-digit radix sort, which is stable and resilient
   to non-uniformity in data but communication intensive. Starts with the
   last array and moves forward. This sort operates directly on numeric types,
   but for Strings, it operates on a hash. Thus, while grouping of equivalent
   strings is guaranteed, lexicographic ordering of the groups is not. For Categoricals,
   coargsort sorts based on Categorical.codes which guarantees grouping of equivalent categories
   but not lexicographic ordering of those groups.

   .. rubric:: Examples

   >>> a = ak.array([0, 1, 0, 1])
   >>> b = ak.array([1, 1, 0, 0])
   >>> perm = ak.coargsort([a, b])
   >>> perm
   array([2, 0, 3, 1])
   >>> a[perm]
   array([0, 0, 1, 1])
   >>> b[perm]
   array([0, 1, 0, 1])


.. py:data:: int64
   

   

.. py:data:: float64
   

   

.. py:data:: bool
   

   

.. py:function:: register(a, name)

   Register an arkouda object with a user-specified name. Backwards compatible
   with earlier arkouda versions.


.. py:function:: convert_if_categorical(values)

   Convert a cetegorical array to strings for display


.. py:function:: concatenate(items, ordered=True)


.. py:function:: get_callback(x)


.. py:function:: unique(pda: groupable, return_groups: bool = False) -> Union[groupable, Tuple[groupable, arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray, int]]

   Find the unique elements of an array.

   Returns the unique elements of an array, sorted if the values are integers.
   There is an optional output in addition to the unique elements: the number
   of times each unique value comes up in the input array.

   :param pda: Input array.
   :type pda: (list of) pdarray, Strings, or Categorical
   :param return_groups: If True, also return grouping information for the array.
   :type return_groups: bool, optional

   :returns: * **unique** (*(list of) pdarray, Strings, or Categorical*) -- The unique values. If input dtype is int64, return values will be sorted.
             * **permutation** (*pdarray, optional*) -- Permutation that groups equivalent values together (only when return_groups=True)
             * **segments** (*pdarray, optional*) -- The offset of each group in the permuted array (only when return_groups=True)

   :raises TypeError: Raised if pda is not a pdarray or Strings object
   :raises RuntimeError: Raised if the pdarray or Strings dtype is unsupported

   .. rubric:: Notes

   For integer arrays, this function checks to see whether `pda` is sorted
   and, if so, whether it is already unique. This step can save considerable
   computation. Otherwise, this function will sort `pda`.

   .. rubric:: Examples

   >>> A = ak.array([3, 2, 1, 1, 2, 3])
   >>> ak.unique(A)
   array([1, 2, 3])


.. py:class:: GroupBy(keys: groupable, assume_sorted: bool = False, hash_strings: bool = True)

   Group an array or list of arrays by value, usually in preparation
   for aggregating the within-group values of another array.

   :param keys: The array to group by value, or if list, the column arrays to group by row
   :type keys: (list of) pdarray, Strings, or Categorical
   :param assume_sorted: If True, assume keys is already sorted (Default: False)
   :type assume_sorted: bool

   .. attribute:: nkeys

      The number of key arrays (columns)

      :type: int

   .. attribute:: size

      The length of the input array(s), i.e. number of rows

      :type: int

   .. attribute:: permutation

      The permutation that sorts the keys array(s) by value (row)

      :type: pdarray

   .. attribute:: unique_keys

      The unique values of the keys array(s), in grouped order

      :type: (list of) pdarray, Strings, or Categorical

   .. attribute:: ngroups

      The length of the unique_keys array(s), i.e. number of groups

      :type: int

   .. attribute:: segments

      The start index of each group in the grouped array(s)

      :type: pdarray

   .. attribute:: logger

      Used for all logging operations

      :type: ArkoudaLogger

   :raises TypeError: Raised if keys is a pdarray with a dtype other than int64

   .. rubric:: Notes

   Integral pdarrays, Strings, and Categoricals are natively supported, but
   float64 and bool arrays are not.

   For a user-defined class to be groupable, it must inherit from pdarray
   and define or overload the grouping API:
     1) a ._get_grouping_keys() method that returns a list of pdarrays
        that can be (co)argsorted.
     2) (Optional) a .group() method that returns the permutation that
        groups the array
   If the input is a single array with a .group() method defined, method 2
   will be used; otherwise, method 1 will be used.

   .. py:attribute:: Reductions
      

      

   .. py:method:: count(self) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Count the number of elements in each group, i.e. the number of times
      each key appears.

      :param none:

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **counts** (*pdarray, int64*) -- The number of times each unique key appears

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 2, 3, 1, 2, 4, 3, 4, 3, 4])
      >>> g = ak.GroupBy(a)
      >>> keys,counts = g.count()
      >>> keys
      array([1, 2, 3, 4])
      >>> counts
      array([1, 2, 4, 3])


   .. py:method:: aggregate(self, values: groupable, operator: str, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group another
      array of values and apply a reduction to each group's values.

      :param values: The values to group and reduce
      :type values: pdarray
      :param operator: The name of the reduction operator to use
      :type operator: str

      :returns: * **unique_keys** (*groupable*) -- The unique keys, in grouped order
                * **aggregates** (*groupable*) -- One aggregate value per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if the requested operator is not supported for the
          values dtype

      .. rubric:: Examples

      >>> keys = ak.arange(0, 10)
      >>> vals = ak.linspace(-1, 1, 10)
      >>> g = ak.GroupBy(keys)
      >>> g.aggregate(vals, 'sum')
      (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([-1, -0.77777777777777768,
      -0.55555555555555536, -0.33333333333333348, -0.11111111111111116,
      0.11111111111111116, 0.33333333333333348, 0.55555555555555536, 0.77777777777777768,
      1]))
      >>> g.aggregate(vals, 'min')
      (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([-1, -0.77777777777777779,
      -0.55555555555555558, -0.33333333333333337, -0.11111111111111116, 0.11111111111111116,
      0.33333333333333326, 0.55555555555555536, 0.77777777777777768, 1]))


   .. py:method:: sum(self, values: arkouda.pdarrayclass.pdarray, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and sum each group's values.

      :param values: The values to group and sum
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_sums** (*pdarray*) -- One sum per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array

      .. rubric:: Notes

      The grouped sum of a boolean ``pdarray`` returns integers.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.sum(b)
      (array([2, 3, 4]), array([8, 14, 6]))


   .. py:method:: prod(self, values: arkouda.pdarrayclass.pdarray, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and compute the product of each group's
      values.

      :param values: The values to group and multiply
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_products** (*pdarray, float64*) -- One product per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object
      :raises ValueError: Raised if the key array size does not match the values size
          or if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if prod is not supported for the values dtype

      .. rubric:: Notes

      The return dtype is always float64.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.prod(b)
      (array([2, 3, 4]), array([12, 108.00000000000003, 8.9999999999999982]))


   .. py:method:: mean(self, values: arkouda.pdarrayclass.pdarray, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and compute the mean of each group's
      values.

      :param values: The values to group and average
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_means** (*pdarray, float64*) -- One mean value per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object
      :raises ValueError: Raised if the key array size does not match the values size
          or if the operator is not in the GroupBy.Reductions array

      .. rubric:: Notes

      The return dtype is always float64.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.mean(b)
      (array([2, 3, 4]), array([2.6666666666666665, 2.7999999999999998, 3]))


   .. py:method:: min(self, values: arkouda.pdarrayclass.pdarray, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the minimum of each group's
      values.

      :param values: The values to group and find minima
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_minima** (*pdarray*) -- One minimum per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if min is
          not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values size
          or if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if min is not supported for the values dtype

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.min(b)
      (array([2, 3, 4]), array([1, 1, 3]))


   .. py:method:: max(self, values: arkouda.pdarrayclass.pdarray, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the maximum of each
      group's values.

      :param values: The values to group and find maxima
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_maxima** (*pdarray*) -- One maximum per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if max is
          not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if max is not supported for the values dtype

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.max(b)
      (array([2, 3, 4]), array([4, 4, 3]))


   .. py:method:: argmin(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the location of the first
      minimum of each group's values.

      :param values: The values to group and find argmin
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_argminima** (*pdarray, int64*) -- One index per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if argmax
          is not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values
          size or if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if argmin is not supported for the values dtype

      .. rubric:: Notes

      The returned indices refer to the original values array as
      passed in, not the permutation applied by the GroupBy instance.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.argmin(b)
      (array([2, 3, 4]), array([5, 4, 2]))


   .. py:method:: argmax(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the location of the first
      maximum of each group's values.

      :param values: The values to group and find argmax
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_argmaxima** (*pdarray, int64*) -- One index per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if argmax
          is not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array

      .. rubric:: Notes

      The returned indices refer to the original values array as passed in,
      not the permutation applied by the GroupBy instance.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.argmax(b)
      (array([2, 3, 4]), array([9, 3, 2]))


   .. py:method:: nunique(self, values: groupable) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group another
      array of values and return the number of unique values in each group.

      :param values: The values to group and find unique values
      :type values: pdarray, int64

      :returns: * **unique_keys** (*groupable*) -- The unique keys, in grouped order
                * **group_nunique** (*groupable*) -- Number of unique values per unique key in the GroupBy instance

      :raises TypeError: Raised if the dtype(s) of values array(s) does/do not support
          the nunique method
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if nunique is not supported for the values dtype

      .. rubric:: Examples

      >>> data = ak.array([3, 4, 3, 1, 1, 4, 3, 4, 1, 4])
      >>> data
      array([3, 4, 3, 1, 1, 4, 3, 4, 1, 4])
      >>> labels = ak.array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4])
      >>> labels
      ak.array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4])
      >>> g = ak.GroupBy(labels)
      >>> g.keys
      ak.array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4])
      >>> g.nunique(data)
      array([1,2,3,4]), array([2, 2, 3, 1])
      #    Group (1,1,1) has values [3,4,3] -> there are 2 unique values 3&4
      #    Group (2,2,2) has values [1,1,4] -> 2 unique values 1&4
      #    Group (3,3,3) has values [3,4,1] -> 3 unique values
      #    Group (4) has values [4] -> 1 unique value


   .. py:method:: any(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[Union[arkouda.pdarrayclass.pdarray, List[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]], arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group another
      array of values and perform an "or" reduction on each group.

      :param values: The values to group and reduce with "or"
      :type values: pdarray, bool

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_any** (*pdarray, bool*) -- One bool per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not bool
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array


   .. py:method:: all(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[Union[arkouda.pdarrayclass.pdarray, List[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]], arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform an "and" reduction on
      each group.

      :param values: The values to group and reduce with "and"
      :type values: pdarray, bool

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_any** (*pdarray, bool*) -- One bool per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not bool
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype


   .. py:method:: OR(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[Union[arkouda.pdarrayclass.pdarray, List[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]], arkouda.pdarrayclass.pdarray]

      Bitwise OR of values in each segment.

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform a bitwise OR reduction on
      each group.

      :param values: The values to group and reduce with OR
      :type values: pdarray, int64

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **result** (*pdarray, int64*) -- Bitwise OR of values in segments corresponding to keys

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not int64
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype


   .. py:method:: AND(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[Union[arkouda.pdarrayclass.pdarray, List[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]], arkouda.pdarrayclass.pdarray]

      Bitwise AND of values in each segment.

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform a bitwise AND reduction on
      each group.

      :param values: The values to group and reduce with AND
      :type values: pdarray, int64

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **result** (*pdarray, int64*) -- Bitwise AND of values in segments corresponding to keys

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not int64
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype


   .. py:method:: XOR(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[Union[arkouda.pdarrayclass.pdarray, List[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]], arkouda.pdarrayclass.pdarray]

      Bitwise XOR of values in each segment.

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform a bitwise XOR reduction on
      each group.

      :param values: The values to group and reduce with XOR
      :type values: pdarray, int64

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **result** (*pdarray, int64*) -- Bitwise XOR of values in segments corresponding to keys

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not int64
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype


   .. py:method:: broadcast(self, values: arkouda.pdarrayclass.pdarray, permute: bool = True) -> arkouda.pdarrayclass.pdarray

      Fill each group's segment with a constant value.

      :param values: The values to put in each group's segment
      :type values: pdarray
      :param permute: If True (default), permute broadcast values back to the ordering
                      of the original array on which GroupBy was called. If False, the
                      broadcast values are grouped by value.
      :type permute: bool

      :returns: The broadcast values
      :rtype: pdarray

      :raises TypeError: Raised if value is not a pdarray object
      :raises ValueError: Raised if the values array does not have one
          value per segment

      .. rubric:: Notes

      This function is a sparse analog of ``np.broadcast``. If a
      GroupBy object represents a sparse matrix (tensor), then
      this function takes a (dense) column vector and replicates
      each value to the non-zero elements in the corresponding row.

      .. rubric:: Examples

      >>> a = ak.array([0, 1, 0, 1, 0])
      >>> values = ak.array([3, 5])
      >>> g = ak.GroupBy(a)
      # By default, result is in original order
      >>> g.broadcast(values)
      array([3, 5, 3, 5, 3])

      # With permute=False, result is in grouped order
      >>> g.broadcast(values, permute=False)
      array([3, 3, 3, 5, 5]

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 1, 4, 4, 4, 1, 3, 3, 2, 2])
      >>> g = ak.GroupBy(a)
      >>> keys,counts = g.count()
      >>> g.broadcast(counts > 2)
      array([True False True True True False True True False False])
      >>> g.broadcast(counts == 3)
      array([True False True True True False True True False False])
      >>> g.broadcast(counts < 4)
      array([True True True True True True True True True True])



.. py:function:: in1dmulti(a, b, assume_unique=False, symmetric=False)

   The multi-level analog of ak.in1d -- test membership of rows of a in the set of rows of b.

   :param a: Rows are elements for which to test membership in b
   :type a: list of pdarrays
   :param b: Rows are elements of the set in which to test membership
   :type b: list of pdarrays
   :param assume_unique: If true, assume rows of a and b are each unique and sorted. By default, sort and unique them explicitly.
   :type assume_unique: bool

   :returns: * *pdarray, bool* -- True for each row in a that is contained in b
             * *Notes* -- Only works for pdarrays of int64 dtype, Strings, or Categorical


.. py:class:: Index(index)

   .. py:method:: __getitem__(self, key)


   .. py:method:: __repr__(self)

      Return repr(self).


   .. py:method:: __len__(self)


   .. py:method:: __eq__(self, v)

      Return self==value.


   .. py:method:: factory(index)
      :staticmethod:


   .. py:method:: to_pandas(self)


   .. py:method:: set_dtype(self, dtype)

      Change the data type of the index

      Currently only aku.ip_address and ak.array are supported.


   .. py:method:: register(self, label)


   .. py:method:: to_dict(self, label)


   .. py:method:: _check_types(self, other)


   .. py:method:: _merge(self, other)


   .. py:method:: _merge_all(self, array)


   .. py:method:: _check_aligned(self, other)


   .. py:method:: argsort(self, ascending=True)


   .. py:method:: concat(self, other)


   .. py:method:: lookup(self, key)



.. py:class:: MultiIndex(index)

   Bases: :py:obj:`Index`

   .. py:method:: __getitem__(self, key)


   .. py:method:: __len__(self)


   .. py:method:: __eq__(self, v)

      Return self==value.


   .. py:method:: to_pandas(self)


   .. py:method:: set_dtype(self, dtype)

      Change the data type of the index

      Currently only aku.ip_address and ak.array are supported.


   .. py:method:: register(self, label)


   .. py:method:: to_dict(self, labels)


   .. py:method:: _merge(self, other)


   .. py:method:: _merge_all(self, array)


   .. py:method:: argsort(self, ascending=True)


   .. py:method:: concat(self, other)


   .. py:method:: lookup(self, key)



.. py:class:: Series(ar_tuple=None, data=None, index=None)

   One-dimensional arkouda array with axis labels.

   :param ar_tuple: second being the value. The grouping key(s) will be the index of the series.
   :type ar_tuple: 2-tuple of arkouda arrays with the first being the grouping key(s) and the

   .. py:attribute:: dt
      

      

   .. py:attribute:: str
      

      

   .. py:method:: __len__(self)


   .. py:method:: __repr__(self)

      Return ascii-formatted version of the series.


   .. py:method:: __getitem__(self, key)


   .. py:method:: shape(self)
      :property:


   .. py:method:: isin(self, lst)

      Find series elements whose values are in the specified list

      Input
      -----
      Either a python list or an arkouda array.

      :rtype: Arkouda boolean which is true for elements that are in the list and false otherwise.


   .. py:method:: locate(self, key)

      Lookup values by index label

      The input can be a scalar, a list of scalers, or a list of lists (if the series has a MultiIndex).
      As a special case, if a Series is used as the key, the series labels are preserved with its values
      use as the key.

      Keys will be turned into arkouda arrays as needed.

      :rtype: A Series containing the values corresponding to the key.


   .. py:method:: _make_binop(cls, operator)
      :classmethod:


   .. py:method:: _make_unaryop(cls, operator)
      :classmethod:


   .. py:method:: _make_aggop(cls, name)
      :classmethod:


   .. py:method:: add(self, b)


   .. py:method:: topn(self, n=10)

      Return the top values of the series

      :param n:
      :type n: Number of values to return

      :rtype: A new Series with the top values


   .. py:method:: sort_index(self, ascending=True)

      Sort the series by its index

      :rtype: A new Series sorted.


   .. py:method:: sort_values(self, ascending=True)

      Sort the series numerically

      :rtype: A new Series sorted smallest to largest


   .. py:method:: tail(self, n=10)

      Return the last n values of the series


   .. py:method:: head(self, n=10)

      Return the first n values of the series


   .. py:method:: to_pandas(self)

      Convert the series to a local PANDAS series


   .. py:method:: value_counts(self, sort=True)

      Return a Series containing counts of unique values.

      The resulting object will be in descending order so that the
      first element is the most frequently-occurring element.

      :param sort:
      :type sort: Boolean. Whether or not to sort the results.  Default is true.


   .. py:method:: diff(self)

      Diffs consecutive values of the series.

      Returns a new series with the same index and length.  First value is set to NaN.


   .. py:method:: to_dataframe(self, index_labels=None, value_label=None)

      Converts series to an arkouda data frame

             Parameters
      ----------
      index_labels:  column names(s) to label the index.
      value_label:  column name to label values.
      :rtype: An arkouda dataframe.


   .. py:method:: register(self, label)

      Register the series with arkouda

      :param label:
      :type label: Arkouda name used for the series

      :rtype: Numer of keys


   .. py:method:: attach(label, nkeys=1)
      :staticmethod:

      Retrieve a series registered with arkouda

      :param label:
      :type label: name used to register the series
      :param nkeys:
      :type nkeys: number of keys, if a multi-index was registerd


   .. py:method:: _all_aligned(array)
      :staticmethod:

      Is an array of Series indexed aligned?


   .. py:method:: concat(arrays, axis=0, index_labels=None, value_labels=None)
      :staticmethod:

      Concatenate in arkouda a list of arkouda Series or grouped arkouda arrays horizontally or vertically.

      If a list of grouped arkouda arrays is passed they are converted to a series. Each grouping is a 2-tuple
      with the first item being the key(s) and the second being the value.

      If horizontal, each series or grouping must have the same length and the same index. The index of the series is
      converted to a column in the dataframe.  If it is a multi-index,each level is converted to a column.

      :param arrays:
      :type arrays: The list of series/groupings to concat.
      :param axis:
      :type axis: Whether or not to do a verticle (axis=0) or horizontal (axis=1) concatenation
      :param index_labels:
      :type index_labels: column names(s) to label the index.
      :param value_labels:
      :type value_labels: column names to label values of each series.

      :returns: * **axis=0** (*an arkouda series.*)
                * **axis=1** (*an arkouda dataframe.*)


   .. py:method:: pdconcat(arrays, axis=0, labels=None)
      :staticmethod:

      Concatenate a list of arkouda Series or grouped arkouda arrays, returning a PANDAS object.

      If a list of grouped arkouda arrays is passed they are converted to a series. Each grouping is a 2-tuple
      with the first item being the key(s) and the second being the value.

      If horizontal, each series or grouping must have the same length and the same index. The index of the series is
      converted to a column in the dataframe.  If it is a multi-index,each level is converted to a column.

      :param arrays:
      :type arrays: The list of series/groupings to concat.
      :param axis:
      :type axis: Whether or not to do a verticle (axis=0) or horizontal (axis=1) concatenation
      :param labels:
      :type labels: names to give the columns of the data frame.

      :returns: * **axis=0** (*a local PANDAS series*)
                * **axis=1** (*a local PANDAS dataframe*)



.. py:class:: Strings(strings_pdarray: arkouda.pdarrayclass.pdarray, bytes_size: arkouda.dtypes.int_scalars)

   Represents an array of strings whose data resides on the
   arkouda server. The user should not call this class directly;
   rather its instances are created by other arkouda functions.

   .. attribute:: entry

      Encapsulation of a Segmented Strings array contained on
      the arkouda server.  This is a composite of
       - offsets array: starting indices for each string
       - bytes array: raw bytes of all strings joined by nulls

      :type: pdarray

   .. attribute:: size

      The number of strings in the array

      :type: int_scalars

   .. attribute:: nbytes

      The total number of bytes in all strings

      :type: int_scalars

   .. attribute:: ndim

      The rank of the array (currently only rank 1 arrays supported)

      :type: int_scalars

   .. attribute:: shape

      The sizes of each dimension of the array

      :type: tuple

   .. attribute:: dtype

      The dtype is ak.str

      :type: dtype

   .. attribute:: logger

      Used for all logging operations

      :type: ArkoudaLogger

   .. rubric:: Notes

   Strings is composed of two pdarrays: (1) offsets, which contains the
   starting indices for each string and (2) bytes, which contains the
   raw bytes of all strings, delimited by nulls.

   .. py:attribute:: BinOps
      

      

   .. py:attribute:: objtype
      :annotation: = str

      

   .. py:method:: from_return_msg(rep_msg: str) -> Strings
      :staticmethod:

      Factory method for creating a Strings object from an Arkouda server
      response message

      :param rep_msg: Server response message currently of form
                      `created name type size ndim shape itemsize+created bytes.size 1234`
      :type rep_msg: str

      :returns: object representing a segmented strings array on the server
      :rtype: Strings

      :raises RuntimeError: Raised if there's an error converting a server-returned str-descriptor

      .. rubric:: Notes

      We really don't have an itemsize because these are variable length strings.
      In the future we could probably use this position to store the total bytes.


   .. py:method:: from_parts(offset_attrib: Union[arkouda.pdarrayclass.pdarray, str], bytes_attrib: Union[arkouda.pdarrayclass.pdarray, str]) -> Strings
      :staticmethod:

      Factory method for creating a Strings object from an Arkouda server
      response where the arrays are separate components.

      :param offset_attrib: the array containing the offsets
      :type offset_attrib: Union[pdarray, str]
      :param bytes_attrib: the array containing the string values
      :type bytes_attrib: Union[pdarray, str]

      :returns: object representing a segmented strings array on the server
      :rtype: Strings

      :raises RuntimeError: Raised if there's an error converting a server-returned str-descriptor

      .. rubric:: Notes

      This factory method is used when we construct the parts of a Strings
      object on the client side and transfer the offsets & bytes separately
      to the server.  This results in two entries in the symbol table and we
      need to instruct the server to assemble the into a composite entity.


   .. py:method:: __iter__(self)
      :abstractmethod:


   .. py:method:: __len__(self) -> int


   .. py:method:: __str__(self) -> str

      Return str(self).


   .. py:method:: __repr__(self) -> str

      Return repr(self).


   .. py:method:: _binop(self, other: Union[Strings, arkouda.dtypes.str_scalars], op: str) -> arkouda.pdarrayclass.pdarray

      Executes the requested binop on this Strings instance and the
      parameter Strings object and returns the results within
      a pdarray object.

      :param other: the other object is a Strings object
      :type other: Strings, str_scalars
      :param op: name of the binary operation to be performed
      :type op: str

      :returns: encapsulating the results of the requested binop
      :rtype: pdarray

      :raises ValueError: Raised if (1) the op is not in the self.BinOps set, or (2) if the
          sizes of this and the other instance don't match, or (3) the other
          object is not a Strings object
      :raises RuntimeError: Raised if a server-side error is thrown while executing the
          binary operation


   .. py:method:: __eq__(self, other) -> bool

      Return self==value.


   .. py:method:: __ne__(self, other) -> bool

      Return self!=value.


   .. py:method:: __getitem__(self, key)


   .. py:method:: get_lengths(self) -> arkouda.pdarrayclass.pdarray

      Return the length of each string in the array.

      :returns: The length of each string
      :rtype: pdarray, int

      :raises RuntimeError: Raised if there is a server-side error thrown


   .. py:method:: to_lower(self) -> Strings

      Returns a new Strings with all uppercase characters from the original replaced with their lowercase equivalent

      :returns: Strings with all uppercase characters from the original replaced with their lowercase equivalent
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.to_upper`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS {i}' for i in range(5)])
      >>> strings
      array(['StrINgS 0', 'StrINgS 1', 'StrINgS 2', 'StrINgS 3', 'StrINgS 4'])
      >>> strings.to_lower()
      array(['strings 0', 'strings 1', 'strings 2', 'strings 3', 'strings 4'])


   .. py:method:: to_upper(self) -> Strings

      Returns a new Strings with all lowercase characters from the original replaced with their uppercase equivalent

      :returns: Strings with all lowercase characters from the original replaced with their uppercase equivalent
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.to_lower`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS {i}' for i in range(5)])
      >>> strings
      array(['StrINgS 0', 'StrINgS 1', 'StrINgS 2', 'StrINgS 3', 'StrINgS 4'])
      >>> strings.to_upper()
      array(['STRINGS 0', 'STRINGS 1', 'STRINGS 2', 'STRINGS 3', 'STRINGS 4'])


   .. py:method:: is_lower(self) -> arkouda.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the Strings is entirely lowercase

      :returns: True for elements that are entirely lowercase, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.is_upper`

      .. rubric:: Examples

      >>> lower = ak.array([f'strings {i}' for i in range(3)])
      >>> upper = ak.array([f'STRINGS {i}' for i in range(3)])
      >>> strings = ak.concatenate([lower, upper])
      >>> strings
      array(['strings 0', 'strings 1', 'strings 2', 'STRINGS 0', 'STRINGS 1', 'STRINGS 2'])
      >>> strings.is_lower()
      array([True True True False False False])


   .. py:method:: is_upper(self) -> arkouda.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the Strings is entirely uppercase

      :returns: True for elements that are entirely uppercase, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.is_lower`

      .. rubric:: Examples

      >>> lower = ak.array([f'strings {i}' for i in range(3)])
      >>> upper = ak.array([f'STRINGS {i}' for i in range(3)])
      >>> strings = ak.concatenate([lower, upper])
      >>> strings
      array(['strings 0', 'strings 1', 'strings 2', 'STRINGS 0', 'STRINGS 1', 'STRINGS 2'])
      >>> strings.is_upper()
      array([False False False True True True])


   .. py:method:: cached_regex_patterns(self) -> List

      Returns the regex patterns for which Match objects have been cached


   .. py:method:: purge_cached_regex_patterns(self) -> None

      purges cached regex patterns


   .. py:method:: _get_matcher(self, pattern: Union[bytes, arkouda.dtypes.str_scalars], create: bool = True)

      internal function to fetch cached Matcher objects


   .. py:method:: find_locations(self, pattern: Union[bytes, arkouda.dtypes.str_scalars]) -> Tuple[arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray]

      Finds pattern matches and returns pdarrays containing the number, start postitions, and lengths of matches

      :param pattern: The regex pattern used to find matches
      :type pattern: str_scalars

      :returns: * *pdarray, int64* -- For each original string, the number of pattern matches
                * *pdarray, int64* -- The start positons of pattern matches
                * *pdarray, int64* -- The lengths of pattern matches

      :raises TypeError: Raised if the pattern parameter is not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.findall`, :obj:`Strings.match`

      .. rubric:: Examples

      >>> strings = ak.array(['{} string {}'.format(i, i) for i in range(1, 6)])
      >>> num_matches, starts, lens = strings.find_locations('\d')
      >>> num_matches
      array([2, 2, 2, 2, 2])
      >>> starts
      array([0, 9, 0, 9, 0, 9, 0, 9, 0, 9])
      >>> lens
      array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))


   .. py:method:: search(self, pattern: Union[bytes, arkouda.dtypes.str_scalars]) -> arkouda.match.Match

      Returns a match object with the first location in each element where pattern produces a match.
      Elements match if any part of the string matches the regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: str

      :returns: Match object where elements match if any part of the string matches the regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.search('_+')
      <ak.Match object: matched=True, span=(1, 2); matched=True, span=(0, 4); matched=False; matched=True, span=(0, 2); matched=False>


   .. py:method:: match(self, pattern: Union[bytes, arkouda.dtypes.str_scalars]) -> arkouda.match.Match

      Returns a match object where elements match only if the beginning of the string matches the regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: str

      :returns: Match object where elements match only if the beginning of the string matches the regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.match('_+')
      <ak.Match object: matched=False; matched=True, span=(0, 4); matched=False; matched=True, span=(0, 2); matched=False>


   .. py:method:: fullmatch(self, pattern: Union[bytes, arkouda.dtypes.str_scalars]) -> arkouda.match.Match

      Returns a match object where elements match only if the whole string matches the regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: str

      :returns: Match object where elements match only if the whole string matches the regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.fullmatch('_+')
      <ak.Match object: matched=False; matched=True, span=(0, 4); matched=False; matched=False; matched=False>


   .. py:method:: split(self, pattern: Union[bytes, arkouda.dtypes.str_scalars], maxsplit: int = 0, return_segments: bool = False) -> Union[Strings, Tuple]

      Returns a new Strings split by the occurrences of pattern. If maxsplit is nonzero, at most maxsplit splits occur

      :param pattern: Regex used to split strings into substrings
      :type pattern: str
      :param maxsplit: The max number of pattern match occurences in each element to split.
                       The default maxsplit=0 splits on all occurences
      :type maxsplit: int
      :param return_segments: If True, return mapping of original strings to first substring
                              in return array.
      :type return_segments: bool

      :returns: * *Strings* -- Substrings with pattern matches removed
                * *pdarray, int64 (optional)* -- For each original string, the index of first corresponding substring
                  in the return array

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.split('_+', maxsplit=2, return_segments=True)
      (array(['1', '2', '', '', '', '3', '', '4', '5____6___7', '']), array([0 3 5 6 9]))


   .. py:method:: findall(self, pattern: Union[bytes, arkouda.dtypes.str_scalars], return_match_origins: bool = False) -> Union[Strings, Tuple]

      Return a new Strings containg all non-overlapping matches of pattern

      :param pattern: Regex used to find matches
      :type pattern: str_scalars
      :param return_match_origins: If True, return a pdarray containing the index of the original string each pattern match is from
      :type return_match_origins: bool

      :returns: * *Strings* -- Strings object containing only pattern matches
                * *pdarray, int64 (optional)* -- The index of the original string each pattern match is from

      :raises TypeError: Raised if the pattern parameter is not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.find_locations`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.findall('_+', return_match_origins=True)
      (array(['_', '___', '____', '__', '___', '____', '___']), array([0 0 1 3 3 3 3]))


   .. py:method:: sub(self, pattern: Union[bytes, arkouda.dtypes.str_scalars], repl: Union[bytes, arkouda.dtypes.str_scalars], count: int = 0) -> Strings

      Return new Strings obtained by replacing non-overlapping occurrences of pattern with the replacement repl.
      If count is nonzero, at most count substitutions occur

      :param pattern: The regex to substitue
      :type pattern: str_scalars
      :param repl: The substring to replace pattern matches with
      :type repl: str_scalars
      :param count: The max number of pattern match occurences in each element to replace.
                    The default count=0 replaces all occurences of pattern with repl
      :type count: int

      :returns: Strings with pattern matches replaced
      :rtype: Strings

      :raises TypeError: Raised if pattern or repl are not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.subn`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.sub(pattern='_+', repl='-', count=2)
      array(['1-2-', '-', '3', '-4-5____6___7', ''])


   .. py:method:: subn(self, pattern: Union[bytes, arkouda.dtypes.str_scalars], repl: Union[bytes, arkouda.dtypes.str_scalars], count: int = 0) -> Tuple

      Perform the same operation as sub(), but return a tuple (new_Strings, number_of_substitions)

      :param pattern: The regex to substitue
      :type pattern: str_scalars
      :param repl: The substring to replace pattern matches with
      :type repl: str_scalars
      :param count: The max number of pattern match occurences in each element to replace.
                    The default count=0 replaces all occurences of pattern with repl
      :type count: int

      :returns: * *Strings* -- Strings with pattern matches replaced
                * *pdarray, int64* -- The number of substitutions made for each element of Strings

      :raises TypeError: Raised if pattern or repl are not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.sub`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.subn(pattern='_+', repl='-', count=2)
      (array(['1-2-', '-', '3', '-4-5____6___7', '']), array([2 1 0 2 0]))


   .. py:method:: contains(self, substr: Union[bytes, arkouda.dtypes.str_scalars], regex: bool = False) -> arkouda.pdarrayclass.pdarray

      Check whether each element contains the given substring.

      :param substr: The substring in the form of string or byte array to search for
      :type substr: str_scalars
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2 (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: True for elements that contain substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not bytes or str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.startswith`, :obj:`Strings.endswith`

      .. rubric:: Examples

      >>> strings = ak.array(['{} string {}'.format(i, i) for i in range(1, 6)])
      >>> strings
      array(['1 string 1', '2 string 2', '3 string 3', '4 string 4', '5 string 5'])
      >>> strings.contains('string')
      array([True, True, True, True, True])
      >>> strings.contains('string \d', regex=True)
      array([True, True, True, True, True])


   .. py:method:: startswith(self, substr: Union[bytes, arkouda.dtypes.str_scalars], regex: bool = False) -> arkouda.pdarrayclass.pdarray

      Check whether each element starts with the given substring.

      :param substr: The prefix to search for
      :type substr: Union[bytes, str_scalars]
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2 (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: True for elements that start with substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not a bytes ior str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.contains`, :obj:`Strings.endswith`

      .. rubric:: Examples

      >>> strings_end = ak.array(['string {}'.format(i) for i in range(1, 6)])
      >>> strings_end
      array(['string 1', 'string 2', 'string 3', 'string 4', 'string 5'])
      >>> strings_end.startswith('string')
      array([True, True, True, True, True])
      >>> strings_start = ak.array(['{} string'.format(i) for i in range(1,6)])
      >>> strings_start
      array(['1 string', '2 string', '3 string', '4 string', '5 string'])
      >>> strings_start.startswith('\d str', regex = True)
      array([True, True, True, True, True])


   .. py:method:: endswith(self, substr: Union[bytes, arkouda.dtypes.str_scalars], regex: bool = False) -> arkouda.pdarrayclass.pdarray

      Check whether each element ends with the given substring.

      :param substr: The suffix to search for
      :type substr: Union[bytes, str_scalars]
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2 (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: True for elements that end with substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not bytes or str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.contains`, :obj:`Strings.startswith`

      .. rubric:: Examples

      >>> strings_start = ak.array(['{} string'.format(i) for i in range(1,6)])
      >>> strings_start
      array(['1 string', '2 string', '3 string', '4 string', '5 string'])
      >>> strings_start.endswith('ing')
      array([True, True, True, True, True])
      >>> strings_end = ak.array(['string {}'.format(i) for i in range(1, 6)])
      >>> strings_end
      array(['string 1', 'string 2', 'string 3', 'string 4', 'string 5'])
      >>> strings_end.endswith('ing \d', regex = True)
      array([True, True, True, True, True])


   .. py:method:: flatten(self, delimiter: str, return_segments: bool = False, regex: bool = False) -> Union[Strings, Tuple]

      Unpack delimiter-joined substrings into a flat array.

      :param delimiter: Characters used to split strings into substrings
      :type delimiter: str
      :param return_segments: If True, also return mapping of original strings to first substring
                              in return array.
      :type return_segments: bool
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2 (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: * *Strings* -- Flattened substrings with delimiters removed
                * *pdarray, int64 (optional)* -- For each original string, the index of first corresponding substring
                  in the return array

      .. seealso:: :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> orig = ak.array(['one|two', 'three|four|five', 'six'])
      >>> orig.flatten('|')
      array(['one', 'two', 'three', 'four', 'five', 'six'])
      >>> flat, map = orig.flatten('|', return_segments=True)
      >>> map
      array([0, 2, 5])
      >>> under = ak.array(['one_two', 'three_____four____five', 'six'])
      >>> under_flat, under_map = under.flatten('_+', return_segments=True, regex=True)
      >>> under_flat
      array(['one', 'two', 'three', 'four', 'five', 'six'])
      >>> under_map
      array([0, 2, 5])


   .. py:method:: peel(self, delimiter: Union[bytes, arkouda.dtypes.str_scalars], times: arkouda.dtypes.int_scalars = 1, includeDelimiter: bool = False, keepPartial: bool = False, fromRight: bool = False, regex: bool = False) -> Tuple

      Peel off one or more delimited fields from each string (similar
      to string.partition), returning two new arrays of strings.
      *Warning*: This function is experimental and not guaranteed to work.

      :param delimiter: The separator where the split will occur
      :type delimiter: Union[bytes, str_scalars]
      :param times: The number of times the delimiter is sought, i.e. skip over
                    the first (times-1) delimiters
      :type times: Union[int, np.int64]
      :param includeDelimiter: If true, append the delimiter to the end of the first return
                               array. By default, it is prepended to the beginning of the
                               second return array.
      :type includeDelimiter: bool
      :param keepPartial: If true, a string that does not contain <times> instances of
                          the delimiter will be returned in the first array. By default,
                          such strings are returned in the second array.
      :type keepPartial: bool
      :param fromRight: If true, peel from the right instead of the left (see also rpeel)
      :type fromRight: bool
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2 (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns:

                left: Strings
                    The field(s) peeled from the end of each string (unless
                    fromRight is true)
                right: Strings
                    The remainder of each string after peeling (unless fromRight
                    is true)
      :rtype: Tuple[Strings, Strings]

      :raises TypeError: Raised if the delimiter parameter is not byte or str_scalars, if
          times is not int64, or if includeDelimiter, keepPartial, or
          fromRight is not bool
      :raises ValueError: Raised if times is < 1 or if delimiter is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`rpeel`, :obj:`stick`, :obj:`lstick`

      .. rubric:: Examples

      >>> s = ak.array(['a.b', 'c.d', 'e.f.g'])
      >>> s.peel('.')
      (array(['a', 'c', 'e']), array(['b', 'd', 'f.g']))
      >>> s.peel('.', includeDelimiter=True)
      (array(['a.', 'c.', 'e.']), array(['b', 'd', 'f.g']))
      >>> s.peel('.', times=2)
      (array(['', '', 'e.f']), array(['a.b', 'c.d', 'g']))
      >>> s.peel('.', times=2, keepPartial=True)
      (array(['a.b', 'c.d', 'e.f']), array(['', '', 'g']))


   .. py:method:: rpeel(self, delimiter: Union[bytes, arkouda.dtypes.str_scalars], times: arkouda.dtypes.int_scalars = 1, includeDelimiter: bool = False, keepPartial: bool = False, regex: bool = False)

      Peel off one or more delimited fields from the end of each string
      (similar to string.rpartition), returning two new arrays of strings.
      *Warning*: This function is experimental and not guaranteed to work.

      :param delimiter: The separator where the split will occur
      :type delimiter: Union[bytes, str_scalars]
      :param times: The number of times the delimiter is sought, i.e. skip over
                    the last (times-1) delimiters
      :type times: Union[int, np.int64]
      :param includeDelimiter: If true, prepend the delimiter to the start of the first return
                               array. By default, it is appended to the end of the
                               second return array.
      :type includeDelimiter: bool
      :param keepPartial: If true, a string that does not contain <times> instances of
                          the delimiter will be returned in the second array. By default,
                          such strings are returned in the first array.
      :type keepPartial: bool
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2 (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns:

                left: Strings
                    The remainder of the string after peeling
                right: Strings
                    The field(s) that were peeled from the right of each string
      :rtype: Tuple[Strings, Strings]

      :raises TypeError: Raised if the delimiter parameter is not bytes or str_scalars or
          if times is not int64
      :raises ValueError: Raised if times is < 1 or if delimiter is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`peel`, :obj:`stick`, :obj:`lstick`

      .. rubric:: Examples

      >>> s = ak.array(['a.b', 'c.d', 'e.f.g'])
      >>> s.rpeel('.')
      (array(['a', 'c', 'e.f']), array(['b', 'd', 'g']))
      # Compared against peel
      >>> s.peel('.')
      (array(['a', 'c', 'e']), array(['b', 'd', 'f.g']))


   .. py:method:: stick(self, other: Strings, delimiter: Union[bytes, arkouda.dtypes.str_scalars] = '', toLeft: bool = False) -> Strings

      Join the strings from another array onto one end of the strings
      of this array, optionally inserting a delimiter.
      *Warning*: This function is experimental and not guaranteed to work.

      :param other: The strings to join onto self's strings
      :type other: Strings
      :param delimiter: String inserted between self and other
      :type delimiter: str
      :param toLeft: If true, join other strings to the left of self. By default,
                     other is joined to the right of self.
      :type toLeft: bool

      :returns: The array of joined strings
      :rtype: Strings

      :raises TypeError: Raised if the delimiter parameter is not bytes or str_scalars
          or if the other parameter is not a Strings instance
      :raises ValueError: Raised if times is < 1
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`lstick`, :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> s = ak.array(['a', 'c', 'e'])
      >>> t = ak.array(['b', 'd', 'f'])
      >>> s.stick(t, delimiter='.')
      array(['a.b', 'c.d', 'e.f'])


   .. py:method:: __add__(self, other: Strings) -> Strings


   .. py:method:: lstick(self, other: Strings, delimiter: Union[bytes, arkouda.dtypes.str_scalars] = '') -> Strings

      Join the strings from another array onto the left of the strings
      of this array, optionally inserting a delimiter.
      *Warning*: This function is experimental and not guaranteed to work.

      :param other: The strings to join onto self's strings
      :type other: Strings
      :param delimiter: String inserted between self and other
      :type delimiter: Union[bytes,str_scalars]

      :returns: The array of joined strings, as other + self
      :rtype: Strings

      :raises TypeError: Raised if the delimiter parameter is neither bytes nor a str
          or if the other parameter is not a Strings instance
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`stick`, :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> s = ak.array(['a', 'c', 'e'])
      >>> t = ak.array(['b', 'd', 'f'])
      >>> s.lstick(t, delimiter='.')
      array(['b.a', 'd.c', 'f.e'])


   .. py:method:: __radd__(self, other: Strings) -> Strings


   .. py:method:: hash(self) -> Tuple[arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray]

      Compute a 128-bit hash of each string.

      :returns: A tuple of two int64 pdarrays. The ith hash value is the concatenation
                of the ith values from each array.
      :rtype: Tuple[pdarray,pdarray]

      .. rubric:: Notes

      The implementation uses SipHash128, a fast and balanced hash function (used
      by Python for dictionaries and sets). For realistic numbers of strings (up
      to about 10**15), the probability of a collision between two 128-bit hash
      values is negligible.


   .. py:method:: group(self) -> arkouda.pdarrayclass.pdarray

      Return the permutation that groups the array, placing equivalent
      strings together. All instances of the same string are guaranteed to lie
      in one contiguous block of the permuted array, but the blocks are not
      necessarily ordered.

      :returns: The permutation that groups the array by value
      :rtype: pdarray

      .. seealso:: :obj:`GroupBy`, :obj:`unique`

      .. rubric:: Notes

      If the arkouda server is compiled with "-sSegmentedArray.useHash=true",
      then arkouda uses 128-bit hash values to group strings, rather than sorting
      the strings directly. This method is fast, but the resulting permutation
      merely groups equivalent strings and does not sort them. If the "useHash"
      parameter is false, then a full sort is performed.

      :raises RuntimeError: Raised if there is a server-side error in executing group request or
          creating the pdarray encapsulating the return message


   .. py:method:: _get_grouping_keys(self) -> List[arkouda.pdarrayclass.pdarray]

      Private method for generating grouping keys used by GroupBy.

      API: this method must be defined by all groupable arrays, and it
      must return a list of arrays that can be (co)argsorted.


   .. py:method:: to_ndarray(self) -> numpy.ndarray

      Convert the array to a np.ndarray, transferring array data from the
      arkouda server to Python. If the array exceeds a built-in size limit,
      a RuntimeError is raised.

      :returns: A numpy ndarray with the same strings as this array
      :rtype: np.ndarray

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``arkouda.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting ak.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`

      .. rubric:: Examples

      >>> a = ak.array(["hello", "my", "world"])
      >>> a.to_ndarray()
      array(['hello', 'my', 'world'], dtype='<U5')
      >>> type(a.to_ndarray())
      numpy.ndarray


   .. py:method:: _comp_to_ndarray(self, comp: str) -> numpy.ndarray

      This is an internal helper function to perform the to_ndarray for one
      of the string components.

      :param comp: The strings component to request
      :type comp: str

      :returns: A numpy ndarray with the same attributes and data as the pdarray
      :rtype: np.ndarray

      :raises RuntimeError: Raised if there is a server-side error thrown, if the pdarray size
          exceeds the built-in client.maxTransferBytes size limit, or if the bytes
          received does not match expected number of bytes

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.


   .. py:method:: astype(self, dtype) -> arkouda.pdarrayclass.pdarray

      Cast values of Strings object to provided dtype

      :param dtype: Dtype to cast to
      :type dtype: np.dtype or str

      :returns: An arkouda pdarray with values converted to the specified data type
      :rtype: ak.pdarray

      .. rubric:: Notes

      This is essentially shorthand for ak.cast(x, '<dtype>') where x is a pdarray.


   .. py:method:: save(self, prefix_path: str, dataset: str = 'strings_array', mode: str = 'truncate', save_offsets: bool = True, compressed: bool = False, file_format: str = 'HDF5') -> str

      Save the Strings object to HDF5 or Parquet. The result is a collection of
      files, one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the Strings array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: The name of the Strings dataset to be written, defaults to strings_array
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Strings dataset within existing files.
      :type mode: str {'truncate' | 'append'}
      :param save_offsets: Defaults to True which will instruct the server to save the offsets array to HDF5
                           If False the offsets array will not be save and will be derived from the string values
                           upon load/read. This is not supported for Parquet files.
      :type save_offsets: bool
      :param compressed: Defaults to False. When True, files will be written with Snappy compression
                         and RLE bit packing. This is currently only supported on Parquet files and will
                         not impact the generated files when writing HDF5 files.
      :type compressed: bool
      :param file_format: By default, saved files will be written to the HDF5 file format. If
                          'Parquet', the files will be written to the Parquet file format. This
                          is case insensitive.
      :type file_format: str

      :rtype: String message indicating result of save operation

      :raises ValueError: Raised if the lengths of columns and values differ, or the mode is
          neither 'truncate' nor 'append'
      :raises TypeError: Raised if prefix_path, dataset, or mode is not a str

      .. seealso:: :obj:`pdarrayIO.save`

      .. rubric:: Notes

      Important implementation notes: (1) Strings state is saved as two datasets
      within an hdf5 group: one for the string characters and one for the
      segments corresponding to the start of each string, (2) the hdf5 group is named
      via the dataset parameter.


   .. py:method:: save_parquet(self, prefix_path: str, dataset: str = 'strings_array', mode: str = 'truncate', compressed: bool = False) -> str

      Save the Strings object to Parquet. The result is a collection of Parquet files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the Strings array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: The name of the Strings dataset to be written, defaults to strings_array
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Strings dataset within existing files.
      :type mode: str {'truncate' | 'append'}
      :param compressed: Defaults to False. When True, files will be written with Snappy compression
                         and RLE bit packing.
      :type compressed: bool

      :rtype: String message indicating result of save operation

      :raises ValueError: Raised if the lengths of columns and values differ, or the mode is
          neither 'truncate' nor 'append'
      :raises TypeError: Raised if prefix_path, dataset, or mode is not a str

      .. seealso:: :obj:`strings.save`, :obj:`pdarray.save_parquet`


   .. py:method:: save_hdf(self, prefix_path: str, dataset: str = 'strings_array', mode: str = 'truncate', save_offsets: bool = True) -> str

      Save the Strings object to HDF5. The result is a collection of HDF5 files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the Strings array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: The name of the Strings dataset to be written, defaults to strings_array
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Strings dataset within existing files.
      :type mode: str {'truncate' | 'append'}
      :param save_offsets: Defaults to True which will instruct the server to save the offsets array to HDF5
                           If False the offsets array will not be save and will be derived from the string values
                           upon load/read.
      :type save_offsets: bool

      :rtype: String message indicating result of save operation

      :raises ValueError: Raised if the lengths of columns and values differ, or the mode is
          neither 'truncate' nor 'append'
      :raises TypeError: Raised if prefix_path, dataset, or mode is not a str

      .. seealso:: :obj:`strings.save`, :obj:`pdarray.save`


   .. py:method:: is_registered(self) -> numpy.bool_

      Return True iff the object is contained in the registry

      :param None:

      :returns: Indicates if the object is contained in the registry
      :rtype: bool

      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: _list_component_names(self) -> List[str]

      Internal Function that returns a list of all component names

      :param None:

      :returns: List of all component names
      :rtype: List[str]


   .. py:method:: info(self) -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str


   .. py:method:: pretty_print_info(self) -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None


   .. py:method:: register(self, user_defined_name: str) -> Strings

      Register this Strings object with a user defined name in the arkouda server
      so it can be attached to later using Strings.attach()
      This is an in-place operation, registering a Strings object more than once will
      update the name in the registry and remove the previously registered name.
      A name can only be registered to one object at a time.

      :param user_defined_name: user defined name which the Strings object is to be registered under
      :type user_defined_name: str

      :returns: The same Strings object which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support a fluid programming style.
                Please note you cannot register two different objects with the same name.
      :rtype: Strings

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the Strings object with the user_defined_name
          If the user is attempting to register more than one object with the same name, the former should be
          unregistered first to free up the registration name.

      .. seealso:: :obj:`attach`, :obj:`unregister`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion
      until they are unregistered.


   .. py:method:: unregister(self) -> None

      Unregister a Strings object in the arkouda server which was previously
      registered using register() and/or attached to using attach()


      :rtype: None

      :raises RuntimeError: Raised if the server could not find the internal name/symbol to remove

      .. seealso:: :obj:`register`, :obj:`attach`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion until
      they are unregistered.


   .. py:method:: attach(user_defined_name: str) -> Strings
      :staticmethod:

      class method to return a Strings object attached to the registered name in the arkouda
      server which was registered using register()

      :param user_defined_name: user defined name which the Strings object was registered under
      :type user_defined_name: str

      :returns: the Strings object registered with user_defined_name in the arkouda server
      :rtype: Strings object

      :raises TypeError: Raised if user_defined_name is not a str

      .. seealso:: :obj:`register`, :obj:`unregister`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion
      until they are unregistered.


   .. py:method:: unregister_strings_by_name(user_defined_name: str) -> None
      :staticmethod:

      Unregister a Strings object in the arkouda server previously registered via register()

      :param user_defined_name: The registered name of the Strings object
      :type user_defined_name: str

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`attach`, :obj:`is_registered`



.. py:class:: pdarray(name: str, mydtype: numpy.dtype, size: arkouda.dtypes.int_scalars, ndim: arkouda.dtypes.int_scalars, shape: Sequence[int], itemsize: arkouda.dtypes.int_scalars)

   The basic arkouda array class. This class contains only the
   attributies of the array; the data resides on the arkouda
   server. When a server operation results in a new array, arkouda
   will create a pdarray instance that points to the array data on
   the server. As such, the user should not initialize pdarray
   instances directly.

   .. attribute:: name

      The server-side identifier for the array

      :type: str

   .. attribute:: dtype

      The element type of the array

      :type: dtype

   .. attribute:: size

      The number of elements in the array

      :type: int_scalars

   .. attribute:: ndim

      The rank of the array (currently only rank 1 arrays supported)

      :type: int_scalars

   .. attribute:: shape

      A list or tuple containing the sizes of each dimension of the array

      :type: Sequence[int]

   .. attribute:: itemsize

      The size in bytes of each element

      :type: int_scalars

   .. py:attribute:: BinOps
      

      

   .. py:attribute:: OpEqOps
      

      

   .. py:attribute:: objtype
      :annotation: = pdarray

      

   .. py:attribute:: __array_priority__
      :annotation: = 1000

      

   .. py:method:: __del__(self)


   .. py:method:: __bool__(self) -> bool


   .. py:method:: __len__(self)


   .. py:method:: __str__(self)

      Return str(self).


   .. py:method:: __repr__(self)

      Return repr(self).


   .. py:method:: format_other(self, other: object) -> str

      Attempt to cast scalar other to the element dtype of this pdarray,
      and print the resulting value to a string (e.g. for sending to a
      server command). The user should not call this function directly.

      :param other: The scalar to be cast to the pdarray.dtype
      :type other: object

      :rtype: string representation of np.dtype corresponding to the other parameter

      :raises TypeError: Raised if the other parameter cannot be converted to
          Numpy dtype


   .. py:method:: _binop(self, other: pdarray, op: str) -> pdarray

      Executes binary operation specified by the op string

      :param other: The pdarray upon which the binop is to be executed
      :type other: pdarray
      :param op: The binop to be executed
      :type op: str

      :returns: A pdarray encapsulating the binop result
      :rtype: pdarray

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set, or if the
          pdarray sizes don't match
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype


   .. py:method:: _r_binop(self, other: pdarray, op: str) -> pdarray

      Executes reverse binary operation specified by the op string

      :param other: The pdarray upon which the reverse binop is to be executed
      :type other: pdarray
      :param op: The name of the reverse binop to be executed
      :type op: str

      :returns: A pdarray encapsulating the reverse binop result
      :rtype: pdarray

      :raises ValueError: Raised if the op is not within the pdarray.BinOps set
      :raises TypeError: Raised if other is not a pdarray or the pdarray.dtype is not
          a supported dtype


   .. py:method:: __add__(self, other)


   .. py:method:: __radd__(self, other)


   .. py:method:: __sub__(self, other)


   .. py:method:: __rsub__(self, other)


   .. py:method:: __mul__(self, other)


   .. py:method:: __rmul__(self, other)


   .. py:method:: __truediv__(self, other)


   .. py:method:: __rtruediv__(self, other)


   .. py:method:: __floordiv__(self, other)


   .. py:method:: __rfloordiv__(self, other)


   .. py:method:: __mod__(self, other)


   .. py:method:: __rmod__(self, other)


   .. py:method:: __lshift__(self, other)


   .. py:method:: __rlshift__(self, other)


   .. py:method:: __rshift__(self, other)


   .. py:method:: __rrshift__(self, other)


   .. py:method:: __and__(self, other)


   .. py:method:: __rand__(self, other)


   .. py:method:: __or__(self, other)


   .. py:method:: __ror__(self, other)


   .. py:method:: __xor__(self, other)


   .. py:method:: __rxor__(self, other)


   .. py:method:: __pow__(self, other)


   .. py:method:: __rpow__(self, other)


   .. py:method:: __lt__(self, other)

      Return self<value.


   .. py:method:: __gt__(self, other)

      Return self>value.


   .. py:method:: __le__(self, other)

      Return self<=value.


   .. py:method:: __ge__(self, other)

      Return self>=value.


   .. py:method:: __eq__(self, other)

      Return self==value.


   .. py:method:: __ne__(self, other)

      Return self!=value.


   .. py:method:: __neg__(self)


   .. py:method:: __invert__(self)


   .. py:method:: opeq(self, other, op)


   .. py:method:: __iadd__(self, other)


   .. py:method:: __isub__(self, other)


   .. py:method:: __imul__(self, other)


   .. py:method:: __itruediv__(self, other)


   .. py:method:: __ifloordiv__(self, other)


   .. py:method:: __ilshift__(self, other)


   .. py:method:: __irshift__(self, other)


   .. py:method:: __iand__(self, other)


   .. py:method:: __ior__(self, other)


   .. py:method:: __ixor__(self, other)


   .. py:method:: __ipow__(self, other)


   .. py:method:: __iter__(self)
      :abstractmethod:


   .. py:method:: __getitem__(self, key)


   .. py:method:: __setitem__(self, key, value)


   .. py:method:: fill(self, value: arkouda.dtypes.numeric_scalars) -> None

      Fill the array (in place) with a constant value.

      :param value:
      :type value: numeric_scalars

      :raises TypeError: Raised if value is not an int, int64, float, or float64


   .. py:method:: any(self) -> numpy.bool_

      Return True iff any element of the array evaluates to True.


   .. py:method:: all(self) -> numpy.bool_

      Return True iff all elements of the array evaluate to True.


   .. py:method:: is_registered(self) -> numpy.bool_

      Return True iff the object is contained in the registry

      :param None:

      :returns: Indicates if the object is contained in the registry
      :rtype: bool

      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: _list_component_names(self) -> List[str]

      Internal Function that returns a list of all component names

      :param None:

      :returns: List of all component names
      :rtype: List[str]


   .. py:method:: info(self) -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str


   .. py:method:: pretty_print_info(self) -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None


   .. py:method:: is_sorted(self) -> numpy.bool_

      Return True iff the array is monotonically non-decreasing.

      :param None:

      :returns: Indicates if the array is monotonically non-decreasing
      :rtype: bool

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: sum(self) -> arkouda.dtypes.numeric_and_bool_scalars

      Return the sum of all elements in the array.


   .. py:method:: prod(self) -> numpy.float64

      Return the product of all elements in the array. Return value is
      always a np.float64 or np.int64.


   .. py:method:: min(self) -> arkouda.dtypes.numpy_scalars

      Return the minimum value of the array.


   .. py:method:: max(self) -> arkouda.dtypes.numpy_scalars

      Return the maximum value of the array.


   .. py:method:: argmin(self) -> numpy.int64

      Return the index of the first occurrence of the array min value


   .. py:method:: argmax(self) -> numpy.int64

      Return the index of the first occurrence of the array max value.


   .. py:method:: mean(self) -> numpy.float64

      Return the mean of the array.


   .. py:method:: var(self, ddof: arkouda.dtypes.int_scalars = 0) -> numpy.float64

      Compute the variance. See ``arkouda.var`` for details.

      :param ddof: "Delta Degrees of Freedom" used in calculating var
      :type ddof: int_scalars

      :returns: The scalar variance of the array
      :rtype: np.float64

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises ValueError: Raised if the ddof >= pdarray size
      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: std(self, ddof: arkouda.dtypes.int_scalars = 0) -> numpy.float64

      Compute the standard deviation. See ``arkouda.std`` for details.

      :param ddof: "Delta Degrees of Freedom" used in calculating std
      :type ddof: int_scalars

      :returns: The scalar standard deviation of the array
      :rtype: np.float64

      :raises TypeError: Raised if pda is not a pdarray instance
      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: mink(self, k: arkouda.dtypes.int_scalars) -> pdarray

      Compute the minimum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: The maximum `k` values from pda
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray


   .. py:method:: maxk(self, k: arkouda.dtypes.int_scalars) -> pdarray

      Compute the maximum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: The maximum `k` values from pda
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray


   .. py:method:: argmink(self, k: arkouda.dtypes.int_scalars) -> pdarray

      Compute the minimum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: Indices corresponding to the maximum `k` values from pda
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray


   .. py:method:: argmaxk(self, k: arkouda.dtypes.int_scalars) -> pdarray

      Finds the indices corresponding to the maximum "k" values.

      :param k: The desired count of maximum values to be returned by the output.
      :type k: int_scalars

      :returns: Indices corresponding to the  maximum `k` values, sorted
      :rtype: pdarray, int

      :raises TypeError: Raised if pda is not a pdarray


   .. py:method:: popcount(self) -> pdarray

      Find the population (number of bits set) in each element. See `ak.popcount`.


   .. py:method:: parity(self) -> pdarray

      Find the parity (XOR of all bits) in each element. See `ak.parity`.


   .. py:method:: clz(self) -> pdarray

      Count the number of leading zeros in each element. See `ak.clz`.


   .. py:method:: ctz(self) -> pdarray

      Count the number of trailing zeros in each element. See `ak.ctz`.


   .. py:method:: rotl(self, other) -> pdarray

      Rotate bits left by <other>.


   .. py:method:: rotr(self, other) -> pdarray

      Rotate bits right by <other>.


   .. py:method:: astype(self, dtype) -> pdarray

      Cast values of pdarray to provided dtype

      :param dtype: Dtype to cast to
      :type dtype: np.dtype or str

      :returns: An arkouda pdarray with values converted to the specified data type
      :rtype: ak.pdarray

      .. rubric:: Notes

      This is essentially shorthand for ak.cast(x, '<dtype>') where x is a pdarray.


   .. py:method:: reshape(self, *shape, order='row_major')

      Gives a new shape to an array without changing its data.

      :param shape: The new shape should be compatible with the original shape.
      :type shape: int, tuple of ints, or pdarray
      :param order: Read the elements of the pdarray in this index order
                    By default, read the elements in row_major or C-like order where the last index changes the fastest
                    If 'column_major' or 'F', read the elements in column_major or Fortran-like order where the first index changes the fastest
      :type order: str {'row_major' | 'C' | 'column_major' | 'F'}

      :returns: An arrayview object with the data from the array but with the new shape
      :rtype: ArrayView


   .. py:method:: to_ndarray(self) -> numpy.ndarray

      Convert the array to a np.ndarray, transferring array data from the
      Arkouda server to client-side Python. Note: if the pdarray size exceeds
      client.maxTransferBytes, a RuntimeError is raised.

      :returns: A numpy ndarray with the same attributes and data as the pdarray
      :rtype: np.ndarray

      :raises RuntimeError: Raised if there is a server-side error thrown, if the pdarray size
          exceeds the built-in client.maxTransferBytes size limit, or if the bytes
          received does not match expected number of bytes

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_ndarray()
      array([0, 1, 2, 3, 4])

      >>> type(a.to_ndarray())
      numpy.ndarray


   .. py:method:: to_cuda(self)

      Convert the array to a Numba DeviceND array, transferring array data from the
      arkouda server to Python via ndarray. If the array exceeds a builtin size limit,
      a RuntimeError is raised.

      :returns: A Numba ndarray with the same attributes and data as the pdarray; on GPU
      :rtype: numba.DeviceNDArray

      :raises ImportError: Raised if CUDA is not available
      :raises ModuleNotFoundError: Raised if Numba is either not installed or not enabled
      :raises RuntimeError: Raised if there is a server-side error thrown in the course of retrieving
          the pdarray.

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`

      .. rubric:: Examples

      >>> a = ak.arange(0, 5, 1)
      >>> a.to_cuda()
      array([0, 1, 2, 3, 4])

      >>> type(a.to_cuda())
      numpy.devicendarray


   .. py:method:: save(self, prefix_path: str, dataset: str = 'array', mode: str = 'truncate', compressed: bool = False, file_format: str = 'HDF5') -> str

      Save the pdarray to HDF5 or Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param compressed: Defaults to False. When True, files will be written with Snappy compression
                         and RLE bit packing. This is currently only supported on Parquet files and will
                         not impact the generated files when writing HDF5 files.
      :type compressed: bool
      :param file_format: By default, saved files will be written to the HDF5 file format. If
                          'Parquet', the files will be written to the Parquet file format. This
                          is case insensitive.
      :type file_format: str {'HDF5', 'Parquet'}

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray
      :raises ValueError: Raised if there is an error in parsing the prefix path pointing to
          file write location or if the mode parameter is neither truncate
          nor append
      :raises TypeError: Raised if any one of the prefix_path, dataset, or mode parameters
          is not a string

      .. seealso:: :obj:`save_all`, :obj:`load`, :obj:`read`

      .. rubric:: Notes

      The prefix_path must be visible to the arkouda server and the user must
      have write permission.

      Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales``. If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.

      .. rubric:: Examples

      >>> a = ak.arange(0, 100, 1)
      >>> a.save('arkouda_range', dataset='array')
      >>> a.save('arkouda_range_parquet', dataset='array', file_format='Parquet')

      Array is saved in numLocales files with names like ``tmp/arkouda_range_LOCALE0``

      The array can be read back in as follows

      >>> b = ak.read('arkouda_range', dataset='array')
      >>> (a == b).all()
      True

      >>> c = ak.read_parquet('arkouda_range_parquet*')
      >>> (c == b).all()
      True


   .. py:method:: save_parquet(self, prefix_path: str, dataset: str = 'array', mode: str = 'truncate', compressed: bool = False) -> str

      Save the pdarray to Parquet. The result is a collection of Parquet files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in Parquet files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
      :type mode: str {'truncate', 'append'}
      :param compressed: By default, write without Snappy compression and RLE encoding.
      :type compressed: bool

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray
      :raises ValueError: Raised if there is an error in parsing the prefix path pointing to
          file write location or if the mode parameter is neither truncate
          nor append
      :raises TypeError: Raised if any one of the prefix_path, dataset, or mode parameters
          is not a string

      .. seealso:: :obj:`save`, :obj:`save_all`, :obj:`load`, :obj:`read`

      .. rubric:: Notes

      The prefix_path must be visible to the arkouda server and the user must
      have write permission.

      Output files have names of the form ``<prefix_path>_LOCALE<i>.parquet``, where ``<i>``
      ranges from 0 to ``numLocales``. If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.

      .. rubric:: Examples

      >>> a = ak.arange(0, 100, 1)
      >>> a.save_parquet('arkouda_range')

      Array is saved in numLocales files with names like ``arkouda_range_LOCALE0000.parquet``

      The array can be read back in as follows

      >>> b = ak.read('arkouda_range')
      >>> (a == b).all()
      True


   .. py:method:: save_hdf(self, prefix_path: str, dataset: str = 'array', mode: str = 'truncate') -> str

      Save the pdarray to HDF5. The result is a collection of HDF5 files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in HDF5 files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
      :type mode: str {'truncate', 'append'}
      :param compressed: By default, write without Snappy compression and RLE encoding.
      :type compressed: bool

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray
      :raises ValueError: Raised if there is an error in parsing the prefix path pointing to
          file write location or if the mode parameter is neither truncate
          nor append
      :raises TypeError: Raised if any one of the prefix_path, dataset, or mode parameters
          is not a string

      .. seealso:: :obj:`save`, :obj:`save_all`, :obj:`load`, :obj:`read`

      .. rubric:: Notes

      The prefix_path must be visible to the arkouda server and the user must
      have write permission.

      Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales``. If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.

      .. rubric:: Examples

      >>> a = ak.arange(0, 100, 1)
      >>> a.save_hdf('arkouda_range')

      Array is saved in numLocales files with names like ``arkouda_range_LOCALE0000``

      The array can be read back in as follows

      >>> b = ak.read('arkouda_range')
      >>> (a == b).all()
      True


   .. py:method:: register(self, user_defined_name: str) -> pdarray

      Register this pdarray with a user defined name in the arkouda server
      so it can be attached to later using pdarray.attach()
      This is an in-place operation, registering a pdarray more than once will
      update the name in the registry and remove the previously registered name.
      A name can only be registered to one pdarray at a time.

      :param user_defined_name: user defined name array is to be registered under
      :type user_defined_name: str

      :returns: The same pdarray which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support a fluid programming style.
                Please note you cannot register two different pdarrays with the same name.
      :rtype: pdarray

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the pdarray with the user_defined_name
          If the user is attempting to register more than one pdarray with the same name, the former should be
          unregistered first to free up the registration name.

      .. seealso:: :obj:`attach`, :obj:`unregister`, :obj:`is_registered`, :obj:`list_registry`, :obj:`unregister_pdarray_by_name`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion
      until they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()


   .. py:method:: unregister(self) -> None

      Unregister a pdarray in the arkouda server which was previously
      registered using register() and/or attahced to using attach()


      :rtype: None

      :raises RuntimeError: Raised if the server could not find the internal name/symbol to remove

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion until
      they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()


   .. py:method:: attach(user_defined_name: str) -> pdarray
      :staticmethod:

      class method to return a pdarray attached to the registered name in the arkouda
      server which was registered using register()

      :param user_defined_name: user defined name which array was registered under
      :type user_defined_name: str

      :returns: pdarray which is bound to corresponding server side component that was registered with user_defined_name
      :rtype: pdarray

      :raises TypeError: Raised if user_defined_name is not a str

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`is_registered`, :obj:`unregister_pdarray_by_name`, :obj:`list_registry`

      .. rubric:: Notes

      Registered names/pdarrays in the server are immune to deletion
      until they are unregistered.

      .. rubric:: Examples

      >>> a = zeros(100)
      >>> a.register("my_zeros")
      >>> # potentially disconnect from server and reconnect to server
      >>> b = ak.pdarray.attach("my_zeros")
      >>> # ...other work...
      >>> b.unregister()


   .. py:method:: _get_grouping_keys(self) -> List[pdarray]

      Private method for generating grouping keys used by GroupBy.

      API: this method must be defined by all groupable arrays, and it
      must return a list of arrays that can be (co)argsorted.



.. py:function:: is_sorted(pda: pdarray) -> numpy.bool_

   Return True iff the array is monotonically non-decreasing.

   :param pda: The pdarray instance to be evaluated
   :type pda: pdarray

   :returns: Indicates if the array is monotonically non-decreasing
   :rtype: bool

   :raises TypeError: Raised if pda is not a pdarray instance
   :raises RuntimeError: Raised if there's a server-side error thrown


.. py:function:: array(a: Union[arkouda.pdarrayclass.pdarray, numpy.ndarray, Iterable], dtype: Union[numpy.dtype, type, str] = None) -> Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]

   Convert a Python or Numpy Iterable to a pdarray or Strings object, sending
   the corresponding data to the arkouda server.

   :param a: Rank-1 array of a supported dtype
   :type a: Union[pdarray, np.ndarray]
   :param dtype: The target dtype to cast values to
   :type dtype: np.dtype, type, or str

   :returns: A pdarray instance stored on arkouda server or Strings instance, which
             is composed of two pdarrays stored on arkouda server
   :rtype: pdarray or Strings

   :raises TypeError: Raised if a is not a pdarray, np.ndarray, or Python Iterable such as a
       list, array, tuple, or deque
   :raises RuntimeError: Raised if a is not one-dimensional, nbytes > maxTransferBytes, a.dtype is
       not supported (not in DTypes), or if the product of a size and
       a.itemsize > maxTransferBytes
   :raises ValueError: Raised if the returned message is malformed or does not contain the fields
       required to generate the array.

   .. seealso:: :obj:`pdarray.to_ndarray`

   .. rubric:: Notes

   The number of bytes in the input array cannot exceed `arkouda.maxTransferBytes`,
   otherwise a RuntimeError will be raised. This is to protect the user
   from overwhelming the connection between the Python client and the arkouda
   server, under the assumption that it is a low-bandwidth connection. The user
   may override this limit by setting ak.maxTransferBytes to a larger value,
   but should proceed with caution.

   If the pdrray or ndarray is of type U, this method is called twice recursively
   to create the Strings object and the two corresponding pdarrays for string
   bytes and offsets, respectively.

   .. rubric:: Examples

   >>> ak.array(np.arange(1,10))
   array([1, 2, 3, 4, 5, 6, 7, 8, 9])

   >>> ak.array(range(1,10))
   array([1, 2, 3, 4, 5, 6, 7, 8, 9])

   >>> strings = ak.array(['string {}'.format(i) for i in range(0,5)])
   >>> type(strings)
   <class 'arkouda.strings.Strings'>


.. py:function:: arange(*args, **kwargs) -> arkouda.pdarrayclass.pdarray

   arange([start,] stop[, stride,] dtype=int64)

   Create a pdarray of consecutive integers within the interval [start, stop).
   If only one arg is given then arg is the stop parameter. If two args are
   given, then the first arg is start and second is stop. If three args are
   given, then the first arg is start, second is stop, third is stride.

   The return value is cast to type dtype

   :param start: Starting value (inclusive)
   :type start: int_scalars, optional
   :param stop: Stopping value (exclusive)
   :type stop: int_scalars
   :param stride: The difference between consecutive elements, the default stride is 1,
                  if stride is specified then start must also be specified.
   :type stride: int_scalars, optional
   :param dtype: The target dtype to cast values to
   :type dtype: np.dtype, type, or str

   :returns: Integers from start (inclusive) to stop (exclusive) by stride
   :rtype: pdarray, dtype

   :raises TypeError: Raised if start, stop, or stride is not an int object
   :raises ZeroDivisionError: Raised if stride == 0

   .. seealso:: :obj:`linspace`, :obj:`zeros`, :obj:`ones`, :obj:`randint`

   .. rubric:: Notes

   Negative strides result in decreasing values. Currently, only int64
   pdarrays can be created with this method. For float64 arrays, use
   the linspace method.

   .. rubric:: Examples

   >>> ak.arange(0, 5, 1)
   array([0, 1, 2, 3, 4])

   >>> ak.arange(5, 0, -1)
   array([5, 4, 3, 2, 1])

   >>> ak.arange(0, 10, 2)
   array([0, 2, 4, 6, 8])

   >>> ak.arange(-5, -10, -1)
   array([-5, -6, -7, -8, -9])


.. py:function:: ones(size: Union[arkouda.dtypes.int_scalars, str], dtype: Union[numpy.dtype, type, str] = float64) -> arkouda.pdarrayclass.pdarray

   Create a pdarray filled with ones.

   :param size: Size of the array (only rank-1 arrays supported)
   :type size: int_scalars
   :param dtype: Resulting array type, default float64
   :type dtype: Union[float64, int64, bool]

   :returns: Ones of the requested size and dtype
   :rtype: pdarray

   :raises TypeError: Raised if the supplied dtype is not supported or if the size
       parameter is neither an int nor a str that is parseable to an int.

   .. seealso:: :obj:`zeros`, :obj:`ones_like`

   .. rubric:: Examples

   >>> ak.ones(5, dtype=ak.int64)
   array([1, 1, 1, 1, 1])

   >>> ak.ones(5, dtype=ak.float64)
   array([1, 1, 1, 1, 1])

   >>> ak.ones(5, dtype=ak.bool)
   array([True, True, True, True, True])


.. py:function:: zeros(size: Union[arkouda.dtypes.int_scalars, str], dtype: Union[numpy.dtype, type, str] = float64) -> arkouda.pdarrayclass.pdarray

   Create a pdarray filled with zeros.

   :param size: Size of the array (only rank-1 arrays supported)
   :type size: int_scalars
   :param dtype: Type of resulting array, default float64
   :type dtype: all_scalars

   :returns: Zeros of the requested size and dtype
   :rtype: pdarray

   :raises TypeError: Raised if the supplied dtype is not supported or if the size
       parameter is neither an int nor a str that is parseable to an int.

   .. seealso:: :obj:`ones`, :obj:`zeros_like`

   .. rubric:: Examples

   >>> ak.zeros(5, dtype=ak.int64)
   array([0, 0, 0, 0, 0])

   >>> ak.zeros(5, dtype=ak.float64)
   array([0, 0, 0, 0, 0])

   >>> ak.zeros(5, dtype=ak.bool)
   array([False, False, False, False, False])


.. py:function:: concatenate(arrays: Sequence[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, Categorical]], ordered: bool = True) -> Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, Categorical]

   Concatenate a list or tuple of ``pdarray`` or ``Strings`` objects into
   one ``pdarray`` or ``Strings`` object, respectively.

   :param arrays: The arrays to concatenate. Must all have same dtype.
   :type arrays: Sequence[Union[pdarray,Strings,Categorical]]
   :param ordered: If True (default), the arrays will be appended in the
                   order given. If False, array data may be interleaved
                   in blocks, which can greatly improve performance but
                   results in non-deterministic ordering of elements.
   :type ordered: bool

   :returns: Single pdarray or Strings object containing all values, returned in
             the original order
   :rtype: Union[pdarray,Strings,Categorical]

   :raises ValueError: Raised if arrays is empty or if 1..n pdarrays have
       differing dtypes
   :raises TypeError: Raised if arrays is not a pdarrays or Strings python Sequence such as a
       list or tuple
   :raises RuntimeError: Raised if 1..n array elements are dtypes for which
       concatenate has not been implemented.

   .. rubric:: Examples

   >>> ak.concatenate([ak.array([1, 2, 3]), ak.array([4, 5, 6])])
   array([1, 2, 3, 4, 5, 6])

   >>> ak.concatenate([ak.array([True,False,True]),ak.array([False,True,True])])
   array([True, False, True, False, True, True])

   >>> ak.concatenate([ak.array(['one','two']),ak.array(['three','four','five'])])
   array(['one', 'two', 'three', 'four', 'five'])


.. py:function:: in1d(pda1: Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, Categorical], pda2: Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, Categorical], invert: bool = False) -> arkouda.pdarrayclass.pdarray

   Test whether each element of a 1-D array is also present in a second array.

   Returns a boolean array the same length as `pda1` that is True
   where an element of `pda1` is in `pda2` and False otherwise.

   :param pda1: Input array.
   :type pda1: pdarray or Strings or Categorical
   :param pda2: The values against which to test each value of `pda1`. Must be the
                same type as `pda1`.
   :type pda2: pdarray or Strings or Categorical
   :param invert: If True, the values in the returned array are inverted (that is,
                  False where an element of `pda1` is in `pda2` and True otherwise).
                  Default is False. ``ak.in1d(a, b, invert=True)`` is equivalent
                  to (but is faster than) ``~ak.in1d(a, b)``.
   :type invert: bool, optional

   :returns: The values `pda1[in1d]` are in `pda2`.
   :rtype: pdarray, bool

   :raises TypeError: Raised if either pda1 or pda2 is not a pdarray, Strings, or
       Categorical object or if invert is not a bool
   :raises RuntimeError: Raised if the dtype of either array is not supported

   .. seealso:: :obj:`unique`, :obj:`intersect1d`, :obj:`union1d`

   .. rubric:: Notes

   `in1d` can be considered as an element-wise function version of the
   python keyword `in`, for 1-D sequences. ``in1d(a, b)`` is logically
   equivalent to ``ak.array([item in b for item in a])``, but is much
   faster and scales to arbitrarily large ``a``.

   ak.in1d is not supported for bool or float64 pdarrays

   .. rubric:: Examples

   >>> ak.in1d(ak.array([-1, 0, 1]), ak.array([-2, 0, 2]))
   array([False, True, False])

   >>> ak.in1d(ak.array(['one','two']),ak.array(['two', 'three','four','five']))
   array([False, True])


.. py:function:: argsort(pda: Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, arkouda.categorical.Categorical], algorithm: SortingAlgorithm = SortingAlgorithm.RadixSortLSD) -> arkouda.pdarrayclass.pdarray

   Return the permutation that sorts the array.

   :param pda: The array to sort (int64, uint64, or float64)
   :type pda: pdarray or Strings or Categorical

   :returns: The indices such that ``pda[indices]`` is sorted
   :rtype: pdarray, int64

   :raises TypeError: Raised if the parameter is other than a pdarray or Strings

   .. seealso:: :obj:`coargsort`

   .. rubric:: Notes

   Uses a least-significant-digit radix sort, which is stable and
   resilient to non-uniformity in data but communication intensive.

   .. rubric:: Examples

   >>> a = ak.randint(0, 10, 10)
   >>> perm = ak.argsort(a)
   >>> a[perm]
   array([0, 1, 1, 3, 4, 5, 7, 8, 8, 9])


.. py:class:: Categorical(values, **kwargs)

   Represents an array of values belonging to named categories. Converting a
   Strings object to Categorical often saves memory and speeds up operations,
   especially if there are many repeated values, at the cost of some one-time
   work in initialization.

   :param values: String values to convert to categories
   :type values: Strings
   :param NAvalue: The value to use to represent missing/null data
   :type NAvalue: str scalar

   .. attribute:: categories

      The set of category labels (determined automatically)

      :type: Strings

   .. attribute:: codes

      The category indices of the values or -1 for N/A

      :type: pdarray, int64

   .. attribute:: permutation

      The permutation that groups the values in the same order as categories

      :type: pdarray, int64

   .. attribute:: segments

      When values are grouped, the starting offset of each group

      :type: pdarray, int64

   .. attribute:: size

      The number of items in the array

      :type: Union[int,np.int64]

   .. attribute:: nlevels

      The number of distinct categories

      :type: Union[int,np.int64]

   .. attribute:: ndim

      The rank of the array (currently only rank 1 arrays supported)

      :type: Union[int,np.int64]

   .. attribute:: shape

      The sizes of each dimension of the array

      :type: tuple

   .. py:attribute:: BinOps
      

      

   .. py:attribute:: RegisterablePieces
      

      

   .. py:attribute:: RequiredPieces
      

      

   .. py:attribute:: objtype
      :annotation: = category

      

   .. py:attribute:: permutation
      

      

   .. py:attribute:: segments
      

      

   .. py:method:: from_codes(cls, codes: arkouda.pdarrayclass.pdarray, categories: arkouda.strings.Strings, permutation=None, segments=None, **kwargs) -> Categorical
      :classmethod:

      Make a Categorical from codes and categories arrays. If codes and
      categories have already been pre-computed, this constructor saves
      time. If not, please use the normal constructor.

      :param codes: Category indices of each value
      :type codes: pdarray, int64
      :param categories: Unique category labels
      :type categories: Strings
      :param permutation: The permutation that groups the values in the same order
                          as categories
      :type permutation: pdarray, int64
      :param segments: When values are grouped, the starting offset of each group
      :type segments: pdarray, int64

      :returns: The Categorical object created from the input parameters
      :rtype: Categorical

      :raises TypeError: Raised if codes is not a pdarray of int64 objects or if
          categories is not a Strings object


   .. py:method:: standardize_categories(cls, arrays, NAvalue='N/A')
      :classmethod:

      Standardize an array of Categoricals so that they share the same categories.

      :param arrays: The Categoricals to standardize
      :type arrays: sequence of Categoricals
      :param NAvalue: The value to use to represent missing/null data
      :type NAvalue: str scalar

      :returns: A list of the original Categoricals remapped to the shared categories.
      :rtype: List of Categoricals


   .. py:method:: set_categories(self, new_categories, NAvalue=None)

      Set categories to user-defined values.

      :param new_categories: The array of new categories to use. Must be unique.
      :type new_categories: Strings
      :param NAvalue: The value to use to represent missing/null data
      :type NAvalue: str scalar

      :returns: A new Categorical with the user-defined categories. Old values present
                in new categories will appear unchanged. Old values not present will
                be assigned the NA value.
      :rtype: Categorical


   .. py:method:: to_ndarray(self) -> numpy.ndarray

      Convert the array to a np.ndarray, transferring array data from
      the arkouda server to Python. This conversion discards category
      information and produces an ndarray of strings. If the arrays
      exceeds a built-in size limit, a RuntimeError is raised.

      :returns: A numpy ndarray of strings corresponding to the values in
                this array
      :rtype: np.ndarray

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``arkouda.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting ak.maxTransferBytes to a larger
      value, but proceed with caution.


   .. py:method:: __iter__(self)
      :abstractmethod:


   .. py:method:: __len__(self)


   .. py:method:: __str__(self)

      Return str(self).


   .. py:method:: __repr__(self)

      Return repr(self).


   .. py:method:: _binop(self, other: Union[Categorical, arkouda.dtypes.str_scalars], op: arkouda.dtypes.str_scalars) -> arkouda.pdarrayclass.pdarray

      Executes the requested binop on this Categorical instance and returns
      the results within a pdarray object.

      :param other: the other object is a Categorical object or string scalar
      :type other: Union[Categorical,str_scalars]
      :param op: name of the binary operation to be performed
      :type op: str_scalars

      :returns: encapsulating the results of the requested binop
      :rtype: pdarray

      :raises ValueError: Raised if (1) the op is not in the self.BinOps set, or (2) if the
          sizes of this and the other instance don't match
      :raises RuntimeError: Raised if a server-side error is thrown while executing the
          binary operation


   .. py:method:: _r_binop(self, other: Union[Categorical, arkouda.dtypes.str_scalars], op: arkouda.dtypes.str_scalars) -> arkouda.pdarrayclass.pdarray

          Executes the requested reverse binop on this Categorical instance and
          returns the results within a pdarray object.

          Parameters
          ----------
          other : Union[Categorical,str_scalars]
              the other object is a Categorical object or string scalar
          op : str_scalars
              name of the binary operation to be performed

          Returns
          -------
          pdarray
              encapsulating the results of the requested binop

          Raises
      -   -----
          ValueError
              Raised if (1) the op is not in the self.BinOps set, or (2) if the
              sizes of this and the other instance don't match
          RuntimeError
              Raised if a server-side error is thrown while executing the
              binary operation



   .. py:method:: __eq__(self, other)

      Return self==value.


   .. py:method:: __ne__(self, other)

      Return self!=value.


   .. py:method:: __getitem__(self, key) -> Categorical


   .. py:method:: isna(self)

      Find where values are missing or null (as defined by self.NAvalue)


   .. py:method:: reset_categories(self) -> Categorical

      Recompute the category labels, discarding any unused labels. This
      method is often useful after slicing or indexing a Categorical array,
      when the resulting array only contains a subset of the original
      categories. In this case, eliminating unused categories can speed up
      other operations.

      :returns: A Categorical object generated from the current instance
      :rtype: Categorical


   .. py:method:: contains(self, substr: str) -> arkouda.pdarrayclass.pdarray

      Check whether each element contains the given substring.

      :param substr: The substring to search for
      :type substr: str

      :returns: True for elements that contain substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if substr is not a str

      .. rubric:: Notes

      This method can be significantly faster than the corresponding method
      on Strings objects, because it searches the unique category labels
      instead of the full array.

      .. seealso:: :obj:`Categorical.startswith`, :obj:`Categorical.endswith`


   .. py:method:: startswith(self, substr: str) -> arkouda.pdarrayclass.pdarray

      Check whether each element starts with the given substring.

      :param substr: The substring to search for
      :type substr: str

      :raises TypeError: Raised if substr is not a str

      :returns: True for elements that contain substr, False otherwise
      :rtype: pdarray, bool

      .. rubric:: Notes

      This method can be significantly faster than the corresponding
      method on Strings objects, because it searches the unique category
      labels instead of the full array.

      .. seealso:: :obj:`Categorical.contains`, :obj:`Categorical.endswith`


   .. py:method:: endswith(self, substr: str) -> arkouda.pdarrayclass.pdarray

      Check whether each element ends with the given substring.

      :param substr: The substring to search for
      :type substr: str

      :raises TypeError: Raised if substr is not a str

      :returns: True for elements that contain substr, False otherwise
      :rtype: pdarray, bool

      .. rubric:: Notes

      This method can be significantly faster than the corresponding method
      on Strings objects, because it searches the unique category labels
      instead of the full array.

      .. seealso:: :obj:`Categorical.startswith`, :obj:`Categorical.contains`


   .. py:method:: in1d(self, test: Union[arkouda.strings.Strings, Categorical]) -> arkouda.pdarrayclass.pdarray

      Test whether each element of the Categorical object is
      also present in the test Strings or Categorical object.

      Returns a boolean array the same length as `self` that is True
      where an element of `self` is in `test` and False otherwise.

      :param test: The values against which to test each value of 'self`.
      :type test: Union[Strings,Categorical]

      :returns: The values `self[in1d]` are in the `test` Strings or Categorical object.
      :rtype: pdarray, bool

      :raises TypeError: Raised if test is not a Strings or Categorical object

      .. seealso:: :obj:`unique`, :obj:`intersect1d`, :obj:`union1d`

      .. rubric:: Notes

      `in1d` can be considered as an element-wise function version of the
      python keyword `in`, for 1-D sequences. ``in1d(a, b)`` is logically
      equivalent to ``ak.array([item in b for item in a])``, but is much
      faster and scales to arbitrarily large ``a``.

      .. rubric:: Examples

      >>> strings = ak.array(['String {}'.format(i) for i in range(0,5)])
      >>> cat = ak.Categorical(strings)
      >>> ak.in1d(cat,strings)
      array([True, True, True, True, True])
      >>> strings = ak.array(['String {}'.format(i) for i in range(5,9)])
      >>> catTwo = ak.Categorical(strings)
      >>> ak.in1d(cat,catTwo)
      array([False, False, False, False, False])


   .. py:method:: unique(self) -> Categorical


   .. py:method:: group(self) -> arkouda.pdarrayclass.pdarray

      Return the permutation that groups the array, placing equivalent
      categories together. All instances of the same category are guaranteed
      to lie in one contiguous block of the permuted array, but the blocks
      are not necessarily ordered.

      :returns: The permutation that groups the array by value
      :rtype: pdarray

      .. seealso:: :obj:`GroupBy`, :obj:`unique`

      .. rubric:: Notes

      This method is faster than the corresponding Strings method. If the
      Categorical was created from a Strings object, then this function
      simply returns the cached permutation. Even if the Categorical was
      created using from_codes(), this function will be faster than
      Strings.group() because it sorts dense integer values, rather than
      128-bit hash values.


   .. py:method:: _get_grouping_keys(self)

      Private method for generating grouping keys used by GroupBy.

      API: this method must be defined by all groupable arrays, and it
      must return a list of arrays that can be (co)argsorted.


   .. py:method:: argsort(self)


   .. py:method:: sort(self)


   .. py:method:: concatenate(self, others: Sequence[Categorical], ordered: bool = True) -> Categorical

      Merge this Categorical with other Categorical objects in the array,
      concatenating the arrays and synchronizing the categories.

      :param others: The Categorical arrays to concatenate and merge with this one
      :type others: Sequence[Categorical]
      :param ordered: If True (default), the arrays will be appended in the
                      order given. If False, array data may be interleaved
                      in blocks, which can greatly improve performance but
                      results in non-deterministic ordering of elements.
      :type ordered: bool

      :returns: The merged Categorical object
      :rtype: Categorical

      :raises TypeError: Raised if any others array objects are not Categorical objects

      .. rubric:: Notes

      This operation can be expensive -- slower than concatenating Strings.


   .. py:method:: save(self, prefix_path: str, dataset: str = 'categorical_array', file_format: str = 'HDF5', mode: str = 'truncate') -> str

      Save the Categorical object to HDF5. The result is a collection of HDF5 files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path and dataset. Each locale saves its chunk of the Strings array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in HDF5 files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Categorical dataset within existing files.
      :type mode: str {'truncate' | 'append'}

      :rtype: String message indicating result of save operation

      :raises ValueError: Raised if the lengths of columns and values differ, or the mode is
          neither 'truncate' nor 'append'
      :raises TypeError: Raised if prefix_path, dataset, or mode is not a str

      .. seealso:: :obj:`pdarrayIO.save`, :obj:`pdarrayIO.load_all`

      .. rubric:: Notes

      Important implementation notes: (1) Strings state is saved as two datasets
      within an hdf5 group: one for the string characters and one for the
      segments corresponding to the start of each string, (2) the hdf5 group is named
      via the dataset parameter.


   .. py:method:: register(self, user_defined_name: str) -> Categorical

      Register this Categorical object and underlying components with the Arkouda server

      :param user_defined_name: user defined name the Categorical is to be registered under,
                                this will be the root name for underlying components
      :type user_defined_name: str

      :returns: The same Categorical which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support a fluid programming style.
                Please note you cannot register two different Categoricals with the same name.
      :rtype: Categorical

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the Categorical with the user_defined_name

      .. seealso:: :obj:`unregister`, :obj:`attach`, :obj:`unregister_categorical_by_name`, :obj:`is_registered`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.


   .. py:method:: unregister(self) -> None

      Unregister this Categorical object in the arkouda server which was previously
      registered using register() and/or attached to using attach()

      :raises RegistrationError: If the object is already unregistered or if there is a server error
          when attempting to unregister

      .. seealso:: :obj:`register`, :obj:`attach`, :obj:`unregister_categorical_by_name`, :obj:`is_registered`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.


   .. py:method:: is_registered(self) -> numpy.bool_

       Return True iff the object is contained in the registry

      :returns: Indicates if the object is contained in the registry
      :rtype: numpy.bool

      :raises RegistrationError: Raised if there's a server-side error or a mis-match of registered components

      .. seealso:: :obj:`register`, :obj:`attach`, :obj:`unregister`, :obj:`unregister_categorical_by_name`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.


   .. py:method:: _get_components_dict(self) -> Dict

      Internal function that returns a dictionary with all required or non-None components of self

      Required Categorical components (Codes and Categories) are always included in returned components_dict
      Optional Categorical components (Permutation and Segments) are only included if they've been set (are not None)

      :returns:

                Dictionary of all required or non-None components of self
                    Keys: component names (Codes, Categories, Permutation, Segments)
                    Values: components of self
      :rtype: Dict


   .. py:method:: _list_component_names(self) -> List[str]

      Internal function that returns a list of all component names

      :param None:

      :returns: List of all component names
      :rtype: List[str]


   .. py:method:: info(self) -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str


   .. py:method:: pretty_print_info(self) -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None


   .. py:method:: attach(user_defined_name: str) -> Categorical
      :staticmethod:

       Function to return a Categorical object attached to the registered name in the
       arkouda server which was registered using register()

       Parameters
       ----------
       user_defined_name : str
           user defined name which Categorical object was registered under

       Returns
       -------
       Categorical
              The Categorical object created by re-attaching to the corresponding server components

      :raises TypeError:     if user_defined_name is not a string
          
          .. seealso:: :obj:`register`, :obj:`is_registered`, :obj:`unregister`, :obj:`unregister_categorical_by_name`


   .. py:method:: unregister_categorical_by_name(user_defined_name: str) -> None
      :staticmethod:

      Function to unregister Categorical object by name which was registered
      with the arkouda server via register()

      :param user_defined_name: Name under which the Categorical object was registered
      :type user_defined_name: str

      :raises TypeError: if user_defined_name is not a string
      :raises RegistrationError: if there is an issue attempting to unregister any underlying components

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`attach`, :obj:`is_registered`


   .. py:method:: parse_hdf_categoricals(d: Mapping[str, Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]) -> Tuple[List[str], Dict[str, Categorical]]
      :staticmethod:

      This function should be used in conjunction with the load_all function which reads hdf5 files and reconstitutes
      Categorical objects.  Categorical objects use a naming convention and HDF5 structure so they can be identified
      and constructed for the user.

      In general you should not call this method directly

      :param d:
      :type d: Dictionary of String to either Pdarray or Strings object

      :returns: * *2-Tuple of List of strings containing key names which should be removed and Dictionary of base name to*
                * *Categorical object*

      .. seealso:: :obj:`Categorical.save`, :obj:`load_all`



.. py:function:: unique(pda: groupable, return_groups: bool = False) -> Union[groupable, Tuple[groupable, arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray, int]]

   Find the unique elements of an array.

   Returns the unique elements of an array, sorted if the values are integers.
   There is an optional output in addition to the unique elements: the number
   of times each unique value comes up in the input array.

   :param pda: Input array.
   :type pda: (list of) pdarray, Strings, or Categorical
   :param return_groups: If True, also return grouping information for the array.
   :type return_groups: bool, optional

   :returns: * **unique** (*(list of) pdarray, Strings, or Categorical*) -- The unique values. If input dtype is int64, return values will be sorted.
             * **permutation** (*pdarray, optional*) -- Permutation that groups equivalent values together (only when return_groups=True)
             * **segments** (*pdarray, optional*) -- The offset of each group in the permuted array (only when return_groups=True)

   :raises TypeError: Raised if pda is not a pdarray or Strings object
   :raises RuntimeError: Raised if the pdarray or Strings dtype is unsupported

   .. rubric:: Notes

   For integer arrays, this function checks to see whether `pda` is sorted
   and, if so, whether it is already unique. This step can save considerable
   computation. Otherwise, this function will sort `pda`.

   .. rubric:: Examples

   >>> A = ak.array([3, 2, 1, 1, 2, 3])
   >>> ak.unique(A)
   array([1, 2, 3])


.. py:class:: GroupBy(keys: groupable, assume_sorted: bool = False, hash_strings: bool = True)

   Group an array or list of arrays by value, usually in preparation
   for aggregating the within-group values of another array.

   :param keys: The array to group by value, or if list, the column arrays to group by row
   :type keys: (list of) pdarray, Strings, or Categorical
   :param assume_sorted: If True, assume keys is already sorted (Default: False)
   :type assume_sorted: bool

   .. attribute:: nkeys

      The number of key arrays (columns)

      :type: int

   .. attribute:: size

      The length of the input array(s), i.e. number of rows

      :type: int

   .. attribute:: permutation

      The permutation that sorts the keys array(s) by value (row)

      :type: pdarray

   .. attribute:: unique_keys

      The unique values of the keys array(s), in grouped order

      :type: (list of) pdarray, Strings, or Categorical

   .. attribute:: ngroups

      The length of the unique_keys array(s), i.e. number of groups

      :type: int

   .. attribute:: segments

      The start index of each group in the grouped array(s)

      :type: pdarray

   .. attribute:: logger

      Used for all logging operations

      :type: ArkoudaLogger

   :raises TypeError: Raised if keys is a pdarray with a dtype other than int64

   .. rubric:: Notes

   Integral pdarrays, Strings, and Categoricals are natively supported, but
   float64 and bool arrays are not.

   For a user-defined class to be groupable, it must inherit from pdarray
   and define or overload the grouping API:
     1) a ._get_grouping_keys() method that returns a list of pdarrays
        that can be (co)argsorted.
     2) (Optional) a .group() method that returns the permutation that
        groups the array
   If the input is a single array with a .group() method defined, method 2
   will be used; otherwise, method 1 will be used.

   .. py:attribute:: Reductions
      

      

   .. py:method:: count(self) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Count the number of elements in each group, i.e. the number of times
      each key appears.

      :param none:

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **counts** (*pdarray, int64*) -- The number of times each unique key appears

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 2, 3, 1, 2, 4, 3, 4, 3, 4])
      >>> g = ak.GroupBy(a)
      >>> keys,counts = g.count()
      >>> keys
      array([1, 2, 3, 4])
      >>> counts
      array([1, 2, 4, 3])


   .. py:method:: aggregate(self, values: groupable, operator: str, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group another
      array of values and apply a reduction to each group's values.

      :param values: The values to group and reduce
      :type values: pdarray
      :param operator: The name of the reduction operator to use
      :type operator: str

      :returns: * **unique_keys** (*groupable*) -- The unique keys, in grouped order
                * **aggregates** (*groupable*) -- One aggregate value per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if the requested operator is not supported for the
          values dtype

      .. rubric:: Examples

      >>> keys = ak.arange(0, 10)
      >>> vals = ak.linspace(-1, 1, 10)
      >>> g = ak.GroupBy(keys)
      >>> g.aggregate(vals, 'sum')
      (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([-1, -0.77777777777777768,
      -0.55555555555555536, -0.33333333333333348, -0.11111111111111116,
      0.11111111111111116, 0.33333333333333348, 0.55555555555555536, 0.77777777777777768,
      1]))
      >>> g.aggregate(vals, 'min')
      (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([-1, -0.77777777777777779,
      -0.55555555555555558, -0.33333333333333337, -0.11111111111111116, 0.11111111111111116,
      0.33333333333333326, 0.55555555555555536, 0.77777777777777768, 1]))


   .. py:method:: sum(self, values: arkouda.pdarrayclass.pdarray, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and sum each group's values.

      :param values: The values to group and sum
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_sums** (*pdarray*) -- One sum per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array

      .. rubric:: Notes

      The grouped sum of a boolean ``pdarray`` returns integers.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.sum(b)
      (array([2, 3, 4]), array([8, 14, 6]))


   .. py:method:: prod(self, values: arkouda.pdarrayclass.pdarray, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and compute the product of each group's
      values.

      :param values: The values to group and multiply
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_products** (*pdarray, float64*) -- One product per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object
      :raises ValueError: Raised if the key array size does not match the values size
          or if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if prod is not supported for the values dtype

      .. rubric:: Notes

      The return dtype is always float64.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.prod(b)
      (array([2, 3, 4]), array([12, 108.00000000000003, 8.9999999999999982]))


   .. py:method:: mean(self, values: arkouda.pdarrayclass.pdarray, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and compute the mean of each group's
      values.

      :param values: The values to group and average
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_means** (*pdarray, float64*) -- One mean value per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object
      :raises ValueError: Raised if the key array size does not match the values size
          or if the operator is not in the GroupBy.Reductions array

      .. rubric:: Notes

      The return dtype is always float64.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.mean(b)
      (array([2, 3, 4]), array([2.6666666666666665, 2.7999999999999998, 3]))


   .. py:method:: min(self, values: arkouda.pdarrayclass.pdarray, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the minimum of each group's
      values.

      :param values: The values to group and find minima
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_minima** (*pdarray*) -- One minimum per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if min is
          not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values size
          or if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if min is not supported for the values dtype

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.min(b)
      (array([2, 3, 4]), array([1, 1, 3]))


   .. py:method:: max(self, values: arkouda.pdarrayclass.pdarray, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the maximum of each
      group's values.

      :param values: The values to group and find maxima
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_maxima** (*pdarray*) -- One maximum per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if max is
          not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if max is not supported for the values dtype

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.max(b)
      (array([2, 3, 4]), array([4, 4, 3]))


   .. py:method:: argmin(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the location of the first
      minimum of each group's values.

      :param values: The values to group and find argmin
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_argminima** (*pdarray, int64*) -- One index per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if argmax
          is not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values
          size or if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if argmin is not supported for the values dtype

      .. rubric:: Notes

      The returned indices refer to the original values array as
      passed in, not the permutation applied by the GroupBy instance.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.argmin(b)
      (array([2, 3, 4]), array([5, 4, 2]))


   .. py:method:: argmax(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the location of the first
      maximum of each group's values.

      :param values: The values to group and find argmax
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_argmaxima** (*pdarray, int64*) -- One index per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if argmax
          is not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array

      .. rubric:: Notes

      The returned indices refer to the original values array as passed in,
      not the permutation applied by the GroupBy instance.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.argmax(b)
      (array([2, 3, 4]), array([9, 3, 2]))


   .. py:method:: nunique(self, values: groupable) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group another
      array of values and return the number of unique values in each group.

      :param values: The values to group and find unique values
      :type values: pdarray, int64

      :returns: * **unique_keys** (*groupable*) -- The unique keys, in grouped order
                * **group_nunique** (*groupable*) -- Number of unique values per unique key in the GroupBy instance

      :raises TypeError: Raised if the dtype(s) of values array(s) does/do not support
          the nunique method
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if nunique is not supported for the values dtype

      .. rubric:: Examples

      >>> data = ak.array([3, 4, 3, 1, 1, 4, 3, 4, 1, 4])
      >>> data
      array([3, 4, 3, 1, 1, 4, 3, 4, 1, 4])
      >>> labels = ak.array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4])
      >>> labels
      ak.array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4])
      >>> g = ak.GroupBy(labels)
      >>> g.keys
      ak.array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4])
      >>> g.nunique(data)
      array([1,2,3,4]), array([2, 2, 3, 1])
      #    Group (1,1,1) has values [3,4,3] -> there are 2 unique values 3&4
      #    Group (2,2,2) has values [1,1,4] -> 2 unique values 1&4
      #    Group (3,3,3) has values [3,4,1] -> 3 unique values
      #    Group (4) has values [4] -> 1 unique value


   .. py:method:: any(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[Union[arkouda.pdarrayclass.pdarray, List[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]], arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group another
      array of values and perform an "or" reduction on each group.

      :param values: The values to group and reduce with "or"
      :type values: pdarray, bool

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_any** (*pdarray, bool*) -- One bool per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not bool
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array


   .. py:method:: all(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[Union[arkouda.pdarrayclass.pdarray, List[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]], arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform an "and" reduction on
      each group.

      :param values: The values to group and reduce with "and"
      :type values: pdarray, bool

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_any** (*pdarray, bool*) -- One bool per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not bool
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype


   .. py:method:: OR(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[Union[arkouda.pdarrayclass.pdarray, List[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]], arkouda.pdarrayclass.pdarray]

      Bitwise OR of values in each segment.

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform a bitwise OR reduction on
      each group.

      :param values: The values to group and reduce with OR
      :type values: pdarray, int64

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **result** (*pdarray, int64*) -- Bitwise OR of values in segments corresponding to keys

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not int64
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype


   .. py:method:: AND(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[Union[arkouda.pdarrayclass.pdarray, List[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]], arkouda.pdarrayclass.pdarray]

      Bitwise AND of values in each segment.

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform a bitwise AND reduction on
      each group.

      :param values: The values to group and reduce with AND
      :type values: pdarray, int64

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **result** (*pdarray, int64*) -- Bitwise AND of values in segments corresponding to keys

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not int64
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype


   .. py:method:: XOR(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[Union[arkouda.pdarrayclass.pdarray, List[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]], arkouda.pdarrayclass.pdarray]

      Bitwise XOR of values in each segment.

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform a bitwise XOR reduction on
      each group.

      :param values: The values to group and reduce with XOR
      :type values: pdarray, int64

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **result** (*pdarray, int64*) -- Bitwise XOR of values in segments corresponding to keys

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not int64
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype


   .. py:method:: broadcast(self, values: arkouda.pdarrayclass.pdarray, permute: bool = True) -> arkouda.pdarrayclass.pdarray

      Fill each group's segment with a constant value.

      :param values: The values to put in each group's segment
      :type values: pdarray
      :param permute: If True (default), permute broadcast values back to the ordering
                      of the original array on which GroupBy was called. If False, the
                      broadcast values are grouped by value.
      :type permute: bool

      :returns: The broadcast values
      :rtype: pdarray

      :raises TypeError: Raised if value is not a pdarray object
      :raises ValueError: Raised if the values array does not have one
          value per segment

      .. rubric:: Notes

      This function is a sparse analog of ``np.broadcast``. If a
      GroupBy object represents a sparse matrix (tensor), then
      this function takes a (dense) column vector and replicates
      each value to the non-zero elements in the corresponding row.

      .. rubric:: Examples

      >>> a = ak.array([0, 1, 0, 1, 0])
      >>> values = ak.array([3, 5])
      >>> g = ak.GroupBy(a)
      # By default, result is in original order
      >>> g.broadcast(values)
      array([3, 5, 3, 5, 3])

      # With permute=False, result is in grouped order
      >>> g.broadcast(values, permute=False)
      array([3, 3, 3, 5, 5]

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 1, 4, 4, 4, 1, 3, 3, 2, 2])
      >>> g = ak.GroupBy(a)
      >>> keys,counts = g.count()
      >>> g.broadcast(counts > 2)
      array([True False True True True False True True False False])
      >>> g.broadcast(counts == 3)
      array([True False True True True False True True False False])
      >>> g.broadcast(counts < 4)
      array([True True True True True True True True True True])



.. py:function:: broadcast(segments: arkouda.pdarrayclass.pdarray, values: arkouda.pdarrayclass.pdarray, size: Union[int, numpy.int64, numpy.uint64] = -1, permutation: Union[arkouda.pdarrayclass.pdarray, None] = None)

   Broadcast a dense column vector to the rows of a sparse matrix or grouped array.

   :param segments: Offsets of the start of each row in the sparse matrix or grouped array.
                    Must be sorted in ascending order.
   :type segments: pdarray, int64
   :param values: The values to broadcast, one per row (or group)
   :type values: pdarray
   :param size: The total number of nonzeros in the matrix. If permutation is given, this
                argument is ignored and the size is inferred from the permutation array.
   :type size: int
   :param permutation: The permutation to go from the original ordering of nonzeros to the ordering
                       grouped by row. To broadcast values back to the original ordering, this
                       permutation will be inverted. If no permutation is supplied, it is assumed
                       that the original nonzeros were already grouped by row. In this case, the
                       size argument must be given.
   :type permutation: pdarray, int64

   :returns: The broadcast values, one per nonzero
   :rtype: pdarray

   :raises ValueError: - If segments and values are different sizes
       - If segments are empty
       - If number of nonzeros (either user-specified or inferred from permutation)
         is less than one

   .. rubric:: Examples

   # Define a sparse matrix with 3 rows and 7 nonzeros
   >>> row_starts = ak.array([0, 2, 5])
   >>> nnz = 7
   # Broadcast the row number to each nonzero element
   >>> row_number = ak.arange(3)
   >>> ak.broadcast(row_starts, row_number, nnz)
   array([0 0 1 1 1 2 2])

   # If the original nonzeros were in reverse order...
   >>> permutation = ak.arange(6, -1, -1)
   >>> ak.broadcast(row_starts, row_number, permutation=permutation)
   array([2 2 1 1 1 0 0])


.. py:data:: akbool
   

   

.. py:data:: akint64
   

   

.. py:data:: akfloat64
   

   

.. py:function:: unsqueeze(p)


.. py:function:: zero_up(vals)

   Map an array of sparse values to 0-up indices.

   :param vals: Array to map to dense index
   :type vals: pdarray

   :returns: **aligned** -- Array with values replaced by 0-up indices
   :rtype: pdarray


.. py:function:: align(*args)

   Map multiple arrays of sparse identifiers to a common 0-up index.

   :param \*args: Arrays to map to dense index
   :type \*args: pdarrays

   :returns: **aligned** -- Arrays with values replaced by 0-up indices
   :rtype: list of pdarrays


.. py:function:: right_align(left, right)

   Map two arrays of sparse values to the 0-up index set implied by the right array,
   discarding values from left that do not appear in right.

   :param left: Left-hand identifiers
   :type left: pdarray
   :param right: Right-hand identifiers that define the index
   :type right: pdarray

   :returns: * **keep** (*pdarray, bool*) -- Logical index of left-hand values that survived
             * **aligned** (*(pdarray, pdarray)*) -- Left and right arrays with values replaced by 0-up indices


.. py:function:: left_align(left, right)

   Map two arrays of sparse identifiers to the 0-up index set implied by the left array,
   discarding values from right that do not appear in left.


.. py:exception:: NonUniqueError

   Bases: :py:obj:`ValueError`

   Inappropriate argument value (of correct type).


.. py:function:: in1dmulti(a, b, assume_unique=False, symmetric=False)

   The multi-level analog of ak.in1d -- test membership of rows of a in the set of rows of b.

   :param a: Rows are elements for which to test membership in b
   :type a: list of pdarrays
   :param b: Rows are elements of the set in which to test membership
   :type b: list of pdarrays
   :param assume_unique: If true, assume rows of a and b are each unique and sorted. By default, sort and unique them explicitly.
   :type assume_unique: bool

   :returns: * *pdarray, bool* -- True for each row in a that is contained in b
             * *Notes* -- Only works for pdarrays of int64 dtype, Strings, or Categorical


.. py:function:: lookup(keys, values, arguments, fillvalue=-1)

   Apply the function defined by the mapping keys --> values to arguments.

   :param keys: The domain of the function. Entries must be unique (if a sequence of
                arrays is given, each row is treated as a tuple-valued entry).
   :type keys: (sequence of) array-like
   :param values: The range of the function. Must be same length as keys.
   :type values: pdarray
   :param arguments: The arguments on which to evaluate the function. Must have same dtype
                     (or tuple of dtypes, for a sequence) as keys.
   :type arguments: (sequence of) array-like
   :param fillvalue: The default value to return for arguments not in keys.
   :type fillvalue: scalar

   :returns: **evaluated** -- The result of evaluating the function over arguments.
   :rtype: pdarray

   .. rubric:: Notes

   While the values cannot be Strings (or other complex objects), the same
   result can be achieved by passing an arange as the values, then using
   the return as indices into the desired object.

   .. rubric:: Examples

   # Lookup numbers by two-word name
   >>> keys1 = ak.array(['twenty' for _ in range(5)])
   >>> keys2 = ak.array(['one', 'two', 'three', 'four', 'five'])
   >>> values = ak.array([21, 22, 23, 24, 25])
   >>> args1 = ak.array(['twenty', 'thirty', 'twenty'])
   >>> args2 = ak.array(['four', 'two', 'two'])
   >>> aku.lookup([keys1, keys2], values, [args1, args2])
   array([24, -1, 22])

   # Other direction requires an intermediate index
   >>> revkeys = values
   >>> revindices = ak.arange(values.size)
   >>> revargs = ak.array([24, 21, 22])
   >>> idx = aku.lookup(revkeys, revindices, revargs)
   >>> keys1[idx], keys2[idx]
   (array(['twenty', 'twenty', 'twenty']),
   array(['four', 'one', 'two']))


.. py:function:: in1d_intervals(vals, intervals, symmetric=False, assume_unique=False)

   Test each value for membership in *any* of a set of half-open (pythonic)
   intervals.

   :param vals: Values to test for membership in intervals
   :type vals: pdarray(int, float)
   :param intervals: Non-overlapping, half-open intervals, as a tuple of
                     (lower_bounds_inclusive, upper_bounds_exclusive)
   :type intervals: 2-tuple of pdarrays
   :param symmetric: If True, also return boolean pdarray indicating which intervals
                     contained one or more query values.
   :type symmetric: bool

   :returns: * *pdarray(bool)* -- Array of same length as <vals>, True if corresponding value is
               included in any of the ranges defined by (low[i], high[i]) inclusive.
             * *pdarray(bool) (if symmetric=True)* -- Array of same length as number of intervals, True if corresponding
               interval contains any of the values in <vals>.

   .. rubric:: Notes

   First return array is equivalent to the following:
       ((vals >= intervals[0][0]) & (vals < intervals[1][0])) |
       ((vals >= intervals[0][1]) & (vals < intervals[1][1])) |
       ...
       ((vals >= intervals[0][-1]) & (vals < intervals[1][-1]))
   But much faster when testing many ranges.

   Second (optional) return array is equivalent to:
       ((intervals[0] <= vals[0]) & (intervals[1] > vals[0])) |
       ((intervals[0] <= vals[1]) & (intervals[1] > vals[1])) |
       ...
       ((intervals[0] <= vals[-1]) & (intervals[1] > vals[-1]))
   But much faster when vals is non-trivial size.


.. py:function:: search_intervals(vals, intervals, assume_unique=False)

   Given an array of query vals and non-overlapping, half-open (pythonic)
   intervals, return the index of the interval containing each query value,
   or -1 if not present in any interval.

   :param vals: Values to search for in intervals
   :type vals: pdarray(int, float)
   :param intervals: Non-overlapping, half-open intervals, as a tuple of
                     (lower_bounds_inclusive, upper_bounds_exclusive)
   :type intervals: 2-tuple of pdarrays
   :param assume_unique: If True, assume query vals are unique. Default: False.
   :type assume_unique: bool

   :returns: **idx** -- Index of interval containing each query value, or -1 if not found
   :rtype: pdarray(int64)

   .. rubric:: Notes

   The return idx satisfies the following condition:
       present = idx > -1
       ((intervals[0][idx[present]] <= vals[present]) & (intervals[1][idx[present]] > vals[present])).all()


.. py:function:: interval_lookup(keys, values, arguments, fillvalue=-1)

   Apply a function defined over non-overlapping intervals to
   an array of arguments.

   :param keys: Tuple of non-overlapping, half-open intervals expressed
                as (lower_bounds_inclusive, upper_bounds_exclusive)
   :type keys: 2-tuple of pdarray
   :param values: Function value to return for each entry in keys.
   :type values: pdarray
   :param arguments: Arguments to the function
   :type arguments: pdarray
   :param fillvalue: Default value to return when argument is not in any interval.
   :type fillvalue: scalar

   :returns: Value of function corresponding to the keys interval
             containing each argument, or fillvalue if argument not
             in any interval.
   :rtype: pdarray


.. py:function:: plot_dist(b, h, log=True, xlabel=None, newfig=True)

   Plot the distribution and cumulative distribution of histogram Data

   :param b: Bin edges
   :type b: np.ndarray
   :param h: Histogram data
   :type h: np.ndarray
   :param log: use log to scale y
   :type log: bool
   :param xlabel: Label for the x axis of the graph
   :type xlabel: str
   :param newfig: Generate a new figure or not
   :type newfig: bool

   .. rubric:: Notes

   This function does not return or display the plot. A user must have matplotlib imported in addition to arkouda to
   display plots. This could be updated to return the object or have a flag to show the resulting plots.
   See Examples Below.

   .. rubric:: Examples

   >>> import arkouda as ak
   >>> from matplotlib import pyplot as plt
   >>> b, h = ak.histogram(ak.arange(10), 3)
   >>> ak.plot_dist(b, h.to_ndarray())
   >>> # to show the plot
   >>> plt.show()


.. py:class:: Datetime(array, unit: str = _BASE_UNIT)

   Bases: :py:obj:`_AbstractBaseTime`

   Represents a date and/or time.

   Datetime is the Arkouda analog to pandas DatetimeIndex and
   other timeseries data types.

   :param array:
   :type array: int64 pdarray, pd.DatetimeIndex, pd.Series, or np.datetime64 array
   :param uint: For int64 pdarray, denotes the unit of the input. Ignored for pandas
                and numpy arrays, which carry their own unit. Not case-sensitive;
                prefixes of full names (like 'sec') are accepted.

                Possible values:

                * 'weeks' or 'w'
                * 'days' or 'd'
                * 'hours' or 'h'
                * 'minutes', 'm', or 't'
                * 'seconds' or 's'
                * 'milliseconds', 'ms', or 'l'
                * 'microseconds', 'us', or 'u'
                * 'nanoseconds', 'ns', or 'n'

                Unlike in pandas, units cannot be combined or mixed with integers
   :type uint: str, default 'ns'

   .. rubric:: Notes

   The ``.values`` attribute is always in nanoseconds with int64 dtype.

   .. py:attribute:: supported_with_datetime
      

      

   .. py:attribute:: supported_with_r_datetime
      

      

   .. py:attribute:: supported_with_timedelta
      

      

   .. py:attribute:: supported_with_r_timedelta
      

      

   .. py:attribute:: supported_opeq
      

      

   .. py:attribute:: supported_with_pdarray
      

      

   .. py:attribute:: supported_with_r_pdarray
      

      

   .. py:method:: _get_callback(cls, otherclass, op)
      :classmethod:


   .. py:method:: _scalar_callback(self, scalar)


   .. py:method:: _is_supported_scalar(scalar)
      :staticmethod:


   .. py:method:: to_pandas(self)

      Convert array to a pandas DatetimeIndex. Note: if the array size
      exceeds client.maxTransferBytes, a RuntimeError is raised.

      .. seealso:: :obj:`to_ndarray`


   .. py:method:: sum(self)

      Return the sum of all elements in the array.



.. py:class:: Categorical(values, **kwargs)

   Represents an array of values belonging to named categories. Converting a
   Strings object to Categorical often saves memory and speeds up operations,
   especially if there are many repeated values, at the cost of some one-time
   work in initialization.

   :param values: String values to convert to categories
   :type values: Strings
   :param NAvalue: The value to use to represent missing/null data
   :type NAvalue: str scalar

   .. attribute:: categories

      The set of category labels (determined automatically)

      :type: Strings

   .. attribute:: codes

      The category indices of the values or -1 for N/A

      :type: pdarray, int64

   .. attribute:: permutation

      The permutation that groups the values in the same order as categories

      :type: pdarray, int64

   .. attribute:: segments

      When values are grouped, the starting offset of each group

      :type: pdarray, int64

   .. attribute:: size

      The number of items in the array

      :type: Union[int,np.int64]

   .. attribute:: nlevels

      The number of distinct categories

      :type: Union[int,np.int64]

   .. attribute:: ndim

      The rank of the array (currently only rank 1 arrays supported)

      :type: Union[int,np.int64]

   .. attribute:: shape

      The sizes of each dimension of the array

      :type: tuple

   .. py:attribute:: BinOps
      

      

   .. py:attribute:: RegisterablePieces
      

      

   .. py:attribute:: RequiredPieces
      

      

   .. py:attribute:: objtype
      :annotation: = category

      

   .. py:attribute:: permutation
      

      

   .. py:attribute:: segments
      

      

   .. py:method:: from_codes(cls, codes: arkouda.pdarrayclass.pdarray, categories: arkouda.strings.Strings, permutation=None, segments=None, **kwargs) -> Categorical
      :classmethod:

      Make a Categorical from codes and categories arrays. If codes and
      categories have already been pre-computed, this constructor saves
      time. If not, please use the normal constructor.

      :param codes: Category indices of each value
      :type codes: pdarray, int64
      :param categories: Unique category labels
      :type categories: Strings
      :param permutation: The permutation that groups the values in the same order
                          as categories
      :type permutation: pdarray, int64
      :param segments: When values are grouped, the starting offset of each group
      :type segments: pdarray, int64

      :returns: The Categorical object created from the input parameters
      :rtype: Categorical

      :raises TypeError: Raised if codes is not a pdarray of int64 objects or if
          categories is not a Strings object


   .. py:method:: standardize_categories(cls, arrays, NAvalue='N/A')
      :classmethod:

      Standardize an array of Categoricals so that they share the same categories.

      :param arrays: The Categoricals to standardize
      :type arrays: sequence of Categoricals
      :param NAvalue: The value to use to represent missing/null data
      :type NAvalue: str scalar

      :returns: A list of the original Categoricals remapped to the shared categories.
      :rtype: List of Categoricals


   .. py:method:: set_categories(self, new_categories, NAvalue=None)

      Set categories to user-defined values.

      :param new_categories: The array of new categories to use. Must be unique.
      :type new_categories: Strings
      :param NAvalue: The value to use to represent missing/null data
      :type NAvalue: str scalar

      :returns: A new Categorical with the user-defined categories. Old values present
                in new categories will appear unchanged. Old values not present will
                be assigned the NA value.
      :rtype: Categorical


   .. py:method:: to_ndarray(self) -> numpy.ndarray

      Convert the array to a np.ndarray, transferring array data from
      the arkouda server to Python. This conversion discards category
      information and produces an ndarray of strings. If the arrays
      exceeds a built-in size limit, a RuntimeError is raised.

      :returns: A numpy ndarray of strings corresponding to the values in
                this array
      :rtype: np.ndarray

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``arkouda.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting ak.maxTransferBytes to a larger
      value, but proceed with caution.


   .. py:method:: __iter__(self)
      :abstractmethod:


   .. py:method:: __len__(self)


   .. py:method:: __str__(self)

      Return str(self).


   .. py:method:: __repr__(self)

      Return repr(self).


   .. py:method:: _binop(self, other: Union[Categorical, arkouda.dtypes.str_scalars], op: arkouda.dtypes.str_scalars) -> arkouda.pdarrayclass.pdarray

      Executes the requested binop on this Categorical instance and returns
      the results within a pdarray object.

      :param other: the other object is a Categorical object or string scalar
      :type other: Union[Categorical,str_scalars]
      :param op: name of the binary operation to be performed
      :type op: str_scalars

      :returns: encapsulating the results of the requested binop
      :rtype: pdarray

      :raises ValueError: Raised if (1) the op is not in the self.BinOps set, or (2) if the
          sizes of this and the other instance don't match
      :raises RuntimeError: Raised if a server-side error is thrown while executing the
          binary operation


   .. py:method:: _r_binop(self, other: Union[Categorical, arkouda.dtypes.str_scalars], op: arkouda.dtypes.str_scalars) -> arkouda.pdarrayclass.pdarray

          Executes the requested reverse binop on this Categorical instance and
          returns the results within a pdarray object.

          Parameters
          ----------
          other : Union[Categorical,str_scalars]
              the other object is a Categorical object or string scalar
          op : str_scalars
              name of the binary operation to be performed

          Returns
          -------
          pdarray
              encapsulating the results of the requested binop

          Raises
      -   -----
          ValueError
              Raised if (1) the op is not in the self.BinOps set, or (2) if the
              sizes of this and the other instance don't match
          RuntimeError
              Raised if a server-side error is thrown while executing the
              binary operation



   .. py:method:: __eq__(self, other)

      Return self==value.


   .. py:method:: __ne__(self, other)

      Return self!=value.


   .. py:method:: __getitem__(self, key) -> Categorical


   .. py:method:: isna(self)

      Find where values are missing or null (as defined by self.NAvalue)


   .. py:method:: reset_categories(self) -> Categorical

      Recompute the category labels, discarding any unused labels. This
      method is often useful after slicing or indexing a Categorical array,
      when the resulting array only contains a subset of the original
      categories. In this case, eliminating unused categories can speed up
      other operations.

      :returns: A Categorical object generated from the current instance
      :rtype: Categorical


   .. py:method:: contains(self, substr: str) -> arkouda.pdarrayclass.pdarray

      Check whether each element contains the given substring.

      :param substr: The substring to search for
      :type substr: str

      :returns: True for elements that contain substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if substr is not a str

      .. rubric:: Notes

      This method can be significantly faster than the corresponding method
      on Strings objects, because it searches the unique category labels
      instead of the full array.

      .. seealso:: :obj:`Categorical.startswith`, :obj:`Categorical.endswith`


   .. py:method:: startswith(self, substr: str) -> arkouda.pdarrayclass.pdarray

      Check whether each element starts with the given substring.

      :param substr: The substring to search for
      :type substr: str

      :raises TypeError: Raised if substr is not a str

      :returns: True for elements that contain substr, False otherwise
      :rtype: pdarray, bool

      .. rubric:: Notes

      This method can be significantly faster than the corresponding
      method on Strings objects, because it searches the unique category
      labels instead of the full array.

      .. seealso:: :obj:`Categorical.contains`, :obj:`Categorical.endswith`


   .. py:method:: endswith(self, substr: str) -> arkouda.pdarrayclass.pdarray

      Check whether each element ends with the given substring.

      :param substr: The substring to search for
      :type substr: str

      :raises TypeError: Raised if substr is not a str

      :returns: True for elements that contain substr, False otherwise
      :rtype: pdarray, bool

      .. rubric:: Notes

      This method can be significantly faster than the corresponding method
      on Strings objects, because it searches the unique category labels
      instead of the full array.

      .. seealso:: :obj:`Categorical.startswith`, :obj:`Categorical.contains`


   .. py:method:: in1d(self, test: Union[arkouda.strings.Strings, Categorical]) -> arkouda.pdarrayclass.pdarray

      Test whether each element of the Categorical object is
      also present in the test Strings or Categorical object.

      Returns a boolean array the same length as `self` that is True
      where an element of `self` is in `test` and False otherwise.

      :param test: The values against which to test each value of 'self`.
      :type test: Union[Strings,Categorical]

      :returns: The values `self[in1d]` are in the `test` Strings or Categorical object.
      :rtype: pdarray, bool

      :raises TypeError: Raised if test is not a Strings or Categorical object

      .. seealso:: :obj:`unique`, :obj:`intersect1d`, :obj:`union1d`

      .. rubric:: Notes

      `in1d` can be considered as an element-wise function version of the
      python keyword `in`, for 1-D sequences. ``in1d(a, b)`` is logically
      equivalent to ``ak.array([item in b for item in a])``, but is much
      faster and scales to arbitrarily large ``a``.

      .. rubric:: Examples

      >>> strings = ak.array(['String {}'.format(i) for i in range(0,5)])
      >>> cat = ak.Categorical(strings)
      >>> ak.in1d(cat,strings)
      array([True, True, True, True, True])
      >>> strings = ak.array(['String {}'.format(i) for i in range(5,9)])
      >>> catTwo = ak.Categorical(strings)
      >>> ak.in1d(cat,catTwo)
      array([False, False, False, False, False])


   .. py:method:: unique(self) -> Categorical


   .. py:method:: group(self) -> arkouda.pdarrayclass.pdarray

      Return the permutation that groups the array, placing equivalent
      categories together. All instances of the same category are guaranteed
      to lie in one contiguous block of the permuted array, but the blocks
      are not necessarily ordered.

      :returns: The permutation that groups the array by value
      :rtype: pdarray

      .. seealso:: :obj:`GroupBy`, :obj:`unique`

      .. rubric:: Notes

      This method is faster than the corresponding Strings method. If the
      Categorical was created from a Strings object, then this function
      simply returns the cached permutation. Even if the Categorical was
      created using from_codes(), this function will be faster than
      Strings.group() because it sorts dense integer values, rather than
      128-bit hash values.


   .. py:method:: _get_grouping_keys(self)

      Private method for generating grouping keys used by GroupBy.

      API: this method must be defined by all groupable arrays, and it
      must return a list of arrays that can be (co)argsorted.


   .. py:method:: argsort(self)


   .. py:method:: sort(self)


   .. py:method:: concatenate(self, others: Sequence[Categorical], ordered: bool = True) -> Categorical

      Merge this Categorical with other Categorical objects in the array,
      concatenating the arrays and synchronizing the categories.

      :param others: The Categorical arrays to concatenate and merge with this one
      :type others: Sequence[Categorical]
      :param ordered: If True (default), the arrays will be appended in the
                      order given. If False, array data may be interleaved
                      in blocks, which can greatly improve performance but
                      results in non-deterministic ordering of elements.
      :type ordered: bool

      :returns: The merged Categorical object
      :rtype: Categorical

      :raises TypeError: Raised if any others array objects are not Categorical objects

      .. rubric:: Notes

      This operation can be expensive -- slower than concatenating Strings.


   .. py:method:: save(self, prefix_path: str, dataset: str = 'categorical_array', file_format: str = 'HDF5', mode: str = 'truncate') -> str

      Save the Categorical object to HDF5. The result is a collection of HDF5 files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path and dataset. Each locale saves its chunk of the Strings array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in HDF5 files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Categorical dataset within existing files.
      :type mode: str {'truncate' | 'append'}

      :rtype: String message indicating result of save operation

      :raises ValueError: Raised if the lengths of columns and values differ, or the mode is
          neither 'truncate' nor 'append'
      :raises TypeError: Raised if prefix_path, dataset, or mode is not a str

      .. seealso:: :obj:`pdarrayIO.save`, :obj:`pdarrayIO.load_all`

      .. rubric:: Notes

      Important implementation notes: (1) Strings state is saved as two datasets
      within an hdf5 group: one for the string characters and one for the
      segments corresponding to the start of each string, (2) the hdf5 group is named
      via the dataset parameter.


   .. py:method:: register(self, user_defined_name: str) -> Categorical

      Register this Categorical object and underlying components with the Arkouda server

      :param user_defined_name: user defined name the Categorical is to be registered under,
                                this will be the root name for underlying components
      :type user_defined_name: str

      :returns: The same Categorical which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support a fluid programming style.
                Please note you cannot register two different Categoricals with the same name.
      :rtype: Categorical

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the Categorical with the user_defined_name

      .. seealso:: :obj:`unregister`, :obj:`attach`, :obj:`unregister_categorical_by_name`, :obj:`is_registered`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.


   .. py:method:: unregister(self) -> None

      Unregister this Categorical object in the arkouda server which was previously
      registered using register() and/or attached to using attach()

      :raises RegistrationError: If the object is already unregistered or if there is a server error
          when attempting to unregister

      .. seealso:: :obj:`register`, :obj:`attach`, :obj:`unregister_categorical_by_name`, :obj:`is_registered`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.


   .. py:method:: is_registered(self) -> numpy.bool_

       Return True iff the object is contained in the registry

      :returns: Indicates if the object is contained in the registry
      :rtype: numpy.bool

      :raises RegistrationError: Raised if there's a server-side error or a mis-match of registered components

      .. seealso:: :obj:`register`, :obj:`attach`, :obj:`unregister`, :obj:`unregister_categorical_by_name`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.


   .. py:method:: _get_components_dict(self) -> Dict

      Internal function that returns a dictionary with all required or non-None components of self

      Required Categorical components (Codes and Categories) are always included in returned components_dict
      Optional Categorical components (Permutation and Segments) are only included if they've been set (are not None)

      :returns:

                Dictionary of all required or non-None components of self
                    Keys: component names (Codes, Categories, Permutation, Segments)
                    Values: components of self
      :rtype: Dict


   .. py:method:: _list_component_names(self) -> List[str]

      Internal function that returns a list of all component names

      :param None:

      :returns: List of all component names
      :rtype: List[str]


   .. py:method:: info(self) -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str


   .. py:method:: pretty_print_info(self) -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None


   .. py:method:: attach(user_defined_name: str) -> Categorical
      :staticmethod:

       Function to return a Categorical object attached to the registered name in the
       arkouda server which was registered using register()

       Parameters
       ----------
       user_defined_name : str
           user defined name which Categorical object was registered under

       Returns
       -------
       Categorical
              The Categorical object created by re-attaching to the corresponding server components

      :raises TypeError:     if user_defined_name is not a string
          
          .. seealso:: :obj:`register`, :obj:`is_registered`, :obj:`unregister`, :obj:`unregister_categorical_by_name`


   .. py:method:: unregister_categorical_by_name(user_defined_name: str) -> None
      :staticmethod:

      Function to unregister Categorical object by name which was registered
      with the arkouda server via register()

      :param user_defined_name: Name under which the Categorical object was registered
      :type user_defined_name: str

      :raises TypeError: if user_defined_name is not a string
      :raises RegistrationError: if there is an issue attempting to unregister any underlying components

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`attach`, :obj:`is_registered`


   .. py:method:: parse_hdf_categoricals(d: Mapping[str, Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]) -> Tuple[List[str], Dict[str, Categorical]]
      :staticmethod:

      This function should be used in conjunction with the load_all function which reads hdf5 files and reconstitutes
      Categorical objects.  Categorical objects use a naming convention and HDF5 structure so they can be identified
      and constructed for the user.

      In general you should not call this method directly

      :param d:
      :type d: Dictionary of String to either Pdarray or Strings object

      :returns: * *2-Tuple of List of strings containing key names which should be removed and Dictionary of base name to*
                * *Categorical object*

      .. seealso:: :obj:`Categorical.save`, :obj:`load_all`



.. py:class:: Strings(strings_pdarray: arkouda.pdarrayclass.pdarray, bytes_size: arkouda.dtypes.int_scalars)

   Represents an array of strings whose data resides on the
   arkouda server. The user should not call this class directly;
   rather its instances are created by other arkouda functions.

   .. attribute:: entry

      Encapsulation of a Segmented Strings array contained on
      the arkouda server.  This is a composite of
       - offsets array: starting indices for each string
       - bytes array: raw bytes of all strings joined by nulls

      :type: pdarray

   .. attribute:: size

      The number of strings in the array

      :type: int_scalars

   .. attribute:: nbytes

      The total number of bytes in all strings

      :type: int_scalars

   .. attribute:: ndim

      The rank of the array (currently only rank 1 arrays supported)

      :type: int_scalars

   .. attribute:: shape

      The sizes of each dimension of the array

      :type: tuple

   .. attribute:: dtype

      The dtype is ak.str

      :type: dtype

   .. attribute:: logger

      Used for all logging operations

      :type: ArkoudaLogger

   .. rubric:: Notes

   Strings is composed of two pdarrays: (1) offsets, which contains the
   starting indices for each string and (2) bytes, which contains the
   raw bytes of all strings, delimited by nulls.

   .. py:attribute:: BinOps
      

      

   .. py:attribute:: objtype
      :annotation: = str

      

   .. py:method:: from_return_msg(rep_msg: str) -> Strings
      :staticmethod:

      Factory method for creating a Strings object from an Arkouda server
      response message

      :param rep_msg: Server response message currently of form
                      `created name type size ndim shape itemsize+created bytes.size 1234`
      :type rep_msg: str

      :returns: object representing a segmented strings array on the server
      :rtype: Strings

      :raises RuntimeError: Raised if there's an error converting a server-returned str-descriptor

      .. rubric:: Notes

      We really don't have an itemsize because these are variable length strings.
      In the future we could probably use this position to store the total bytes.


   .. py:method:: from_parts(offset_attrib: Union[arkouda.pdarrayclass.pdarray, str], bytes_attrib: Union[arkouda.pdarrayclass.pdarray, str]) -> Strings
      :staticmethod:

      Factory method for creating a Strings object from an Arkouda server
      response where the arrays are separate components.

      :param offset_attrib: the array containing the offsets
      :type offset_attrib: Union[pdarray, str]
      :param bytes_attrib: the array containing the string values
      :type bytes_attrib: Union[pdarray, str]

      :returns: object representing a segmented strings array on the server
      :rtype: Strings

      :raises RuntimeError: Raised if there's an error converting a server-returned str-descriptor

      .. rubric:: Notes

      This factory method is used when we construct the parts of a Strings
      object on the client side and transfer the offsets & bytes separately
      to the server.  This results in two entries in the symbol table and we
      need to instruct the server to assemble the into a composite entity.


   .. py:method:: __iter__(self)
      :abstractmethod:


   .. py:method:: __len__(self) -> int


   .. py:method:: __str__(self) -> str

      Return str(self).


   .. py:method:: __repr__(self) -> str

      Return repr(self).


   .. py:method:: _binop(self, other: Union[Strings, arkouda.dtypes.str_scalars], op: str) -> arkouda.pdarrayclass.pdarray

      Executes the requested binop on this Strings instance and the
      parameter Strings object and returns the results within
      a pdarray object.

      :param other: the other object is a Strings object
      :type other: Strings, str_scalars
      :param op: name of the binary operation to be performed
      :type op: str

      :returns: encapsulating the results of the requested binop
      :rtype: pdarray

      :raises ValueError: Raised if (1) the op is not in the self.BinOps set, or (2) if the
          sizes of this and the other instance don't match, or (3) the other
          object is not a Strings object
      :raises RuntimeError: Raised if a server-side error is thrown while executing the
          binary operation


   .. py:method:: __eq__(self, other) -> bool

      Return self==value.


   .. py:method:: __ne__(self, other) -> bool

      Return self!=value.


   .. py:method:: __getitem__(self, key)


   .. py:method:: get_lengths(self) -> arkouda.pdarrayclass.pdarray

      Return the length of each string in the array.

      :returns: The length of each string
      :rtype: pdarray, int

      :raises RuntimeError: Raised if there is a server-side error thrown


   .. py:method:: to_lower(self) -> Strings

      Returns a new Strings with all uppercase characters from the original replaced with their lowercase equivalent

      :returns: Strings with all uppercase characters from the original replaced with their lowercase equivalent
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.to_upper`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS {i}' for i in range(5)])
      >>> strings
      array(['StrINgS 0', 'StrINgS 1', 'StrINgS 2', 'StrINgS 3', 'StrINgS 4'])
      >>> strings.to_lower()
      array(['strings 0', 'strings 1', 'strings 2', 'strings 3', 'strings 4'])


   .. py:method:: to_upper(self) -> Strings

      Returns a new Strings with all lowercase characters from the original replaced with their uppercase equivalent

      :returns: Strings with all lowercase characters from the original replaced with their uppercase equivalent
      :rtype: Strings

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.to_lower`

      .. rubric:: Examples

      >>> strings = ak.array([f'StrINgS {i}' for i in range(5)])
      >>> strings
      array(['StrINgS 0', 'StrINgS 1', 'StrINgS 2', 'StrINgS 3', 'StrINgS 4'])
      >>> strings.to_upper()
      array(['STRINGS 0', 'STRINGS 1', 'STRINGS 2', 'STRINGS 3', 'STRINGS 4'])


   .. py:method:: is_lower(self) -> arkouda.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the Strings is entirely lowercase

      :returns: True for elements that are entirely lowercase, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.is_upper`

      .. rubric:: Examples

      >>> lower = ak.array([f'strings {i}' for i in range(3)])
      >>> upper = ak.array([f'STRINGS {i}' for i in range(3)])
      >>> strings = ak.concatenate([lower, upper])
      >>> strings
      array(['strings 0', 'strings 1', 'strings 2', 'STRINGS 0', 'STRINGS 1', 'STRINGS 2'])
      >>> strings.is_lower()
      array([True True True False False False])


   .. py:method:: is_upper(self) -> arkouda.pdarrayclass.pdarray

      Returns a boolean pdarray where index i indicates whether string i of the Strings is entirely uppercase

      :returns: True for elements that are entirely uppercase, False otherwise
      :rtype: pdarray, bool

      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.is_lower`

      .. rubric:: Examples

      >>> lower = ak.array([f'strings {i}' for i in range(3)])
      >>> upper = ak.array([f'STRINGS {i}' for i in range(3)])
      >>> strings = ak.concatenate([lower, upper])
      >>> strings
      array(['strings 0', 'strings 1', 'strings 2', 'STRINGS 0', 'STRINGS 1', 'STRINGS 2'])
      >>> strings.is_upper()
      array([False False False True True True])


   .. py:method:: cached_regex_patterns(self) -> List

      Returns the regex patterns for which Match objects have been cached


   .. py:method:: purge_cached_regex_patterns(self) -> None

      purges cached regex patterns


   .. py:method:: _get_matcher(self, pattern: Union[bytes, arkouda.dtypes.str_scalars], create: bool = True)

      internal function to fetch cached Matcher objects


   .. py:method:: find_locations(self, pattern: Union[bytes, arkouda.dtypes.str_scalars]) -> Tuple[arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray]

      Finds pattern matches and returns pdarrays containing the number, start postitions, and lengths of matches

      :param pattern: The regex pattern used to find matches
      :type pattern: str_scalars

      :returns: * *pdarray, int64* -- For each original string, the number of pattern matches
                * *pdarray, int64* -- The start positons of pattern matches
                * *pdarray, int64* -- The lengths of pattern matches

      :raises TypeError: Raised if the pattern parameter is not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.findall`, :obj:`Strings.match`

      .. rubric:: Examples

      >>> strings = ak.array(['{} string {}'.format(i, i) for i in range(1, 6)])
      >>> num_matches, starts, lens = strings.find_locations('\d')
      >>> num_matches
      array([2, 2, 2, 2, 2])
      >>> starts
      array([0, 9, 0, 9, 0, 9, 0, 9, 0, 9])
      >>> lens
      array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))


   .. py:method:: search(self, pattern: Union[bytes, arkouda.dtypes.str_scalars]) -> arkouda.match.Match

      Returns a match object with the first location in each element where pattern produces a match.
      Elements match if any part of the string matches the regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: str

      :returns: Match object where elements match if any part of the string matches the regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.search('_+')
      <ak.Match object: matched=True, span=(1, 2); matched=True, span=(0, 4); matched=False; matched=True, span=(0, 2); matched=False>


   .. py:method:: match(self, pattern: Union[bytes, arkouda.dtypes.str_scalars]) -> arkouda.match.Match

      Returns a match object where elements match only if the beginning of the string matches the regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: str

      :returns: Match object where elements match only if the beginning of the string matches the regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.match('_+')
      <ak.Match object: matched=False; matched=True, span=(0, 4); matched=False; matched=True, span=(0, 2); matched=False>


   .. py:method:: fullmatch(self, pattern: Union[bytes, arkouda.dtypes.str_scalars]) -> arkouda.match.Match

      Returns a match object where elements match only if the whole string matches the regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: str

      :returns: Match object where elements match only if the whole string matches the regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.fullmatch('_+')
      <ak.Match object: matched=False; matched=True, span=(0, 4); matched=False; matched=False; matched=False>


   .. py:method:: split(self, pattern: Union[bytes, arkouda.dtypes.str_scalars], maxsplit: int = 0, return_segments: bool = False) -> Union[Strings, Tuple]

      Returns a new Strings split by the occurrences of pattern. If maxsplit is nonzero, at most maxsplit splits occur

      :param pattern: Regex used to split strings into substrings
      :type pattern: str
      :param maxsplit: The max number of pattern match occurences in each element to split.
                       The default maxsplit=0 splits on all occurences
      :type maxsplit: int
      :param return_segments: If True, return mapping of original strings to first substring
                              in return array.
      :type return_segments: bool

      :returns: * *Strings* -- Substrings with pattern matches removed
                * *pdarray, int64 (optional)* -- For each original string, the index of first corresponding substring
                  in the return array

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.split('_+', maxsplit=2, return_segments=True)
      (array(['1', '2', '', '', '', '3', '', '4', '5____6___7', '']), array([0 3 5 6 9]))


   .. py:method:: findall(self, pattern: Union[bytes, arkouda.dtypes.str_scalars], return_match_origins: bool = False) -> Union[Strings, Tuple]

      Return a new Strings containg all non-overlapping matches of pattern

      :param pattern: Regex used to find matches
      :type pattern: str_scalars
      :param return_match_origins: If True, return a pdarray containing the index of the original string each pattern match is from
      :type return_match_origins: bool

      :returns: * *Strings* -- Strings object containing only pattern matches
                * *pdarray, int64 (optional)* -- The index of the original string each pattern match is from

      :raises TypeError: Raised if the pattern parameter is not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.find_locations`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.findall('_+', return_match_origins=True)
      (array(['_', '___', '____', '__', '___', '____', '___']), array([0 0 1 3 3 3 3]))


   .. py:method:: sub(self, pattern: Union[bytes, arkouda.dtypes.str_scalars], repl: Union[bytes, arkouda.dtypes.str_scalars], count: int = 0) -> Strings

      Return new Strings obtained by replacing non-overlapping occurrences of pattern with the replacement repl.
      If count is nonzero, at most count substitutions occur

      :param pattern: The regex to substitue
      :type pattern: str_scalars
      :param repl: The substring to replace pattern matches with
      :type repl: str_scalars
      :param count: The max number of pattern match occurences in each element to replace.
                    The default count=0 replaces all occurences of pattern with repl
      :type count: int

      :returns: Strings with pattern matches replaced
      :rtype: Strings

      :raises TypeError: Raised if pattern or repl are not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.subn`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.sub(pattern='_+', repl='-', count=2)
      array(['1-2-', '-', '3', '-4-5____6___7', ''])


   .. py:method:: subn(self, pattern: Union[bytes, arkouda.dtypes.str_scalars], repl: Union[bytes, arkouda.dtypes.str_scalars], count: int = 0) -> Tuple

      Perform the same operation as sub(), but return a tuple (new_Strings, number_of_substitions)

      :param pattern: The regex to substitue
      :type pattern: str_scalars
      :param repl: The substring to replace pattern matches with
      :type repl: str_scalars
      :param count: The max number of pattern match occurences in each element to replace.
                    The default count=0 replaces all occurences of pattern with repl
      :type count: int

      :returns: * *Strings* -- Strings with pattern matches replaced
                * *pdarray, int64* -- The number of substitutions made for each element of Strings

      :raises TypeError: Raised if pattern or repl are not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.sub`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.subn(pattern='_+', repl='-', count=2)
      (array(['1-2-', '-', '3', '-4-5____6___7', '']), array([2 1 0 2 0]))


   .. py:method:: contains(self, substr: Union[bytes, arkouda.dtypes.str_scalars], regex: bool = False) -> arkouda.pdarrayclass.pdarray

      Check whether each element contains the given substring.

      :param substr: The substring in the form of string or byte array to search for
      :type substr: str_scalars
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2 (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: True for elements that contain substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not bytes or str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.startswith`, :obj:`Strings.endswith`

      .. rubric:: Examples

      >>> strings = ak.array(['{} string {}'.format(i, i) for i in range(1, 6)])
      >>> strings
      array(['1 string 1', '2 string 2', '3 string 3', '4 string 4', '5 string 5'])
      >>> strings.contains('string')
      array([True, True, True, True, True])
      >>> strings.contains('string \d', regex=True)
      array([True, True, True, True, True])


   .. py:method:: startswith(self, substr: Union[bytes, arkouda.dtypes.str_scalars], regex: bool = False) -> arkouda.pdarrayclass.pdarray

      Check whether each element starts with the given substring.

      :param substr: The prefix to search for
      :type substr: Union[bytes, str_scalars]
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2 (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: True for elements that start with substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not a bytes ior str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.contains`, :obj:`Strings.endswith`

      .. rubric:: Examples

      >>> strings_end = ak.array(['string {}'.format(i) for i in range(1, 6)])
      >>> strings_end
      array(['string 1', 'string 2', 'string 3', 'string 4', 'string 5'])
      >>> strings_end.startswith('string')
      array([True, True, True, True, True])
      >>> strings_start = ak.array(['{} string'.format(i) for i in range(1,6)])
      >>> strings_start
      array(['1 string', '2 string', '3 string', '4 string', '5 string'])
      >>> strings_start.startswith('\d str', regex = True)
      array([True, True, True, True, True])


   .. py:method:: endswith(self, substr: Union[bytes, arkouda.dtypes.str_scalars], regex: bool = False) -> arkouda.pdarrayclass.pdarray

      Check whether each element ends with the given substring.

      :param substr: The suffix to search for
      :type substr: Union[bytes, str_scalars]
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2 (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: True for elements that end with substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not bytes or str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.contains`, :obj:`Strings.startswith`

      .. rubric:: Examples

      >>> strings_start = ak.array(['{} string'.format(i) for i in range(1,6)])
      >>> strings_start
      array(['1 string', '2 string', '3 string', '4 string', '5 string'])
      >>> strings_start.endswith('ing')
      array([True, True, True, True, True])
      >>> strings_end = ak.array(['string {}'.format(i) for i in range(1, 6)])
      >>> strings_end
      array(['string 1', 'string 2', 'string 3', 'string 4', 'string 5'])
      >>> strings_end.endswith('ing \d', regex = True)
      array([True, True, True, True, True])


   .. py:method:: flatten(self, delimiter: str, return_segments: bool = False, regex: bool = False) -> Union[Strings, Tuple]

      Unpack delimiter-joined substrings into a flat array.

      :param delimiter: Characters used to split strings into substrings
      :type delimiter: str
      :param return_segments: If True, also return mapping of original strings to first substring
                              in return array.
      :type return_segments: bool
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2 (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: * *Strings* -- Flattened substrings with delimiters removed
                * *pdarray, int64 (optional)* -- For each original string, the index of first corresponding substring
                  in the return array

      .. seealso:: :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> orig = ak.array(['one|two', 'three|four|five', 'six'])
      >>> orig.flatten('|')
      array(['one', 'two', 'three', 'four', 'five', 'six'])
      >>> flat, map = orig.flatten('|', return_segments=True)
      >>> map
      array([0, 2, 5])
      >>> under = ak.array(['one_two', 'three_____four____five', 'six'])
      >>> under_flat, under_map = under.flatten('_+', return_segments=True, regex=True)
      >>> under_flat
      array(['one', 'two', 'three', 'four', 'five', 'six'])
      >>> under_map
      array([0, 2, 5])


   .. py:method:: peel(self, delimiter: Union[bytes, arkouda.dtypes.str_scalars], times: arkouda.dtypes.int_scalars = 1, includeDelimiter: bool = False, keepPartial: bool = False, fromRight: bool = False, regex: bool = False) -> Tuple

      Peel off one or more delimited fields from each string (similar
      to string.partition), returning two new arrays of strings.
      *Warning*: This function is experimental and not guaranteed to work.

      :param delimiter: The separator where the split will occur
      :type delimiter: Union[bytes, str_scalars]
      :param times: The number of times the delimiter is sought, i.e. skip over
                    the first (times-1) delimiters
      :type times: Union[int, np.int64]
      :param includeDelimiter: If true, append the delimiter to the end of the first return
                               array. By default, it is prepended to the beginning of the
                               second return array.
      :type includeDelimiter: bool
      :param keepPartial: If true, a string that does not contain <times> instances of
                          the delimiter will be returned in the first array. By default,
                          such strings are returned in the second array.
      :type keepPartial: bool
      :param fromRight: If true, peel from the right instead of the left (see also rpeel)
      :type fromRight: bool
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2 (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns:

                left: Strings
                    The field(s) peeled from the end of each string (unless
                    fromRight is true)
                right: Strings
                    The remainder of each string after peeling (unless fromRight
                    is true)
      :rtype: Tuple[Strings, Strings]

      :raises TypeError: Raised if the delimiter parameter is not byte or str_scalars, if
          times is not int64, or if includeDelimiter, keepPartial, or
          fromRight is not bool
      :raises ValueError: Raised if times is < 1 or if delimiter is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`rpeel`, :obj:`stick`, :obj:`lstick`

      .. rubric:: Examples

      >>> s = ak.array(['a.b', 'c.d', 'e.f.g'])
      >>> s.peel('.')
      (array(['a', 'c', 'e']), array(['b', 'd', 'f.g']))
      >>> s.peel('.', includeDelimiter=True)
      (array(['a.', 'c.', 'e.']), array(['b', 'd', 'f.g']))
      >>> s.peel('.', times=2)
      (array(['', '', 'e.f']), array(['a.b', 'c.d', 'g']))
      >>> s.peel('.', times=2, keepPartial=True)
      (array(['a.b', 'c.d', 'e.f']), array(['', '', 'g']))


   .. py:method:: rpeel(self, delimiter: Union[bytes, arkouda.dtypes.str_scalars], times: arkouda.dtypes.int_scalars = 1, includeDelimiter: bool = False, keepPartial: bool = False, regex: bool = False)

      Peel off one or more delimited fields from the end of each string
      (similar to string.rpartition), returning two new arrays of strings.
      *Warning*: This function is experimental and not guaranteed to work.

      :param delimiter: The separator where the split will occur
      :type delimiter: Union[bytes, str_scalars]
      :param times: The number of times the delimiter is sought, i.e. skip over
                    the last (times-1) delimiters
      :type times: Union[int, np.int64]
      :param includeDelimiter: If true, prepend the delimiter to the start of the first return
                               array. By default, it is appended to the end of the
                               second return array.
      :type includeDelimiter: bool
      :param keepPartial: If true, a string that does not contain <times> instances of
                          the delimiter will be returned in the second array. By default,
                          such strings are returned in the first array.
      :type keepPartial: bool
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2 (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns:

                left: Strings
                    The remainder of the string after peeling
                right: Strings
                    The field(s) that were peeled from the right of each string
      :rtype: Tuple[Strings, Strings]

      :raises TypeError: Raised if the delimiter parameter is not bytes or str_scalars or
          if times is not int64
      :raises ValueError: Raised if times is < 1 or if delimiter is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`peel`, :obj:`stick`, :obj:`lstick`

      .. rubric:: Examples

      >>> s = ak.array(['a.b', 'c.d', 'e.f.g'])
      >>> s.rpeel('.')
      (array(['a', 'c', 'e.f']), array(['b', 'd', 'g']))
      # Compared against peel
      >>> s.peel('.')
      (array(['a', 'c', 'e']), array(['b', 'd', 'f.g']))


   .. py:method:: stick(self, other: Strings, delimiter: Union[bytes, arkouda.dtypes.str_scalars] = '', toLeft: bool = False) -> Strings

      Join the strings from another array onto one end of the strings
      of this array, optionally inserting a delimiter.
      *Warning*: This function is experimental and not guaranteed to work.

      :param other: The strings to join onto self's strings
      :type other: Strings
      :param delimiter: String inserted between self and other
      :type delimiter: str
      :param toLeft: If true, join other strings to the left of self. By default,
                     other is joined to the right of self.
      :type toLeft: bool

      :returns: The array of joined strings
      :rtype: Strings

      :raises TypeError: Raised if the delimiter parameter is not bytes or str_scalars
          or if the other parameter is not a Strings instance
      :raises ValueError: Raised if times is < 1
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`lstick`, :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> s = ak.array(['a', 'c', 'e'])
      >>> t = ak.array(['b', 'd', 'f'])
      >>> s.stick(t, delimiter='.')
      array(['a.b', 'c.d', 'e.f'])


   .. py:method:: __add__(self, other: Strings) -> Strings


   .. py:method:: lstick(self, other: Strings, delimiter: Union[bytes, arkouda.dtypes.str_scalars] = '') -> Strings

      Join the strings from another array onto the left of the strings
      of this array, optionally inserting a delimiter.
      *Warning*: This function is experimental and not guaranteed to work.

      :param other: The strings to join onto self's strings
      :type other: Strings
      :param delimiter: String inserted between self and other
      :type delimiter: Union[bytes,str_scalars]

      :returns: The array of joined strings, as other + self
      :rtype: Strings

      :raises TypeError: Raised if the delimiter parameter is neither bytes nor a str
          or if the other parameter is not a Strings instance
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`stick`, :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> s = ak.array(['a', 'c', 'e'])
      >>> t = ak.array(['b', 'd', 'f'])
      >>> s.lstick(t, delimiter='.')
      array(['b.a', 'd.c', 'f.e'])


   .. py:method:: __radd__(self, other: Strings) -> Strings


   .. py:method:: hash(self) -> Tuple[arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray]

      Compute a 128-bit hash of each string.

      :returns: A tuple of two int64 pdarrays. The ith hash value is the concatenation
                of the ith values from each array.
      :rtype: Tuple[pdarray,pdarray]

      .. rubric:: Notes

      The implementation uses SipHash128, a fast and balanced hash function (used
      by Python for dictionaries and sets). For realistic numbers of strings (up
      to about 10**15), the probability of a collision between two 128-bit hash
      values is negligible.


   .. py:method:: group(self) -> arkouda.pdarrayclass.pdarray

      Return the permutation that groups the array, placing equivalent
      strings together. All instances of the same string are guaranteed to lie
      in one contiguous block of the permuted array, but the blocks are not
      necessarily ordered.

      :returns: The permutation that groups the array by value
      :rtype: pdarray

      .. seealso:: :obj:`GroupBy`, :obj:`unique`

      .. rubric:: Notes

      If the arkouda server is compiled with "-sSegmentedArray.useHash=true",
      then arkouda uses 128-bit hash values to group strings, rather than sorting
      the strings directly. This method is fast, but the resulting permutation
      merely groups equivalent strings and does not sort them. If the "useHash"
      parameter is false, then a full sort is performed.

      :raises RuntimeError: Raised if there is a server-side error in executing group request or
          creating the pdarray encapsulating the return message


   .. py:method:: _get_grouping_keys(self) -> List[arkouda.pdarrayclass.pdarray]

      Private method for generating grouping keys used by GroupBy.

      API: this method must be defined by all groupable arrays, and it
      must return a list of arrays that can be (co)argsorted.


   .. py:method:: to_ndarray(self) -> numpy.ndarray

      Convert the array to a np.ndarray, transferring array data from the
      arkouda server to Python. If the array exceeds a built-in size limit,
      a RuntimeError is raised.

      :returns: A numpy ndarray with the same strings as this array
      :rtype: np.ndarray

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``arkouda.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting ak.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`

      .. rubric:: Examples

      >>> a = ak.array(["hello", "my", "world"])
      >>> a.to_ndarray()
      array(['hello', 'my', 'world'], dtype='<U5')
      >>> type(a.to_ndarray())
      numpy.ndarray


   .. py:method:: _comp_to_ndarray(self, comp: str) -> numpy.ndarray

      This is an internal helper function to perform the to_ndarray for one
      of the string components.

      :param comp: The strings component to request
      :type comp: str

      :returns: A numpy ndarray with the same attributes and data as the pdarray
      :rtype: np.ndarray

      :raises RuntimeError: Raised if there is a server-side error thrown, if the pdarray size
          exceeds the built-in client.maxTransferBytes size limit, or if the bytes
          received does not match expected number of bytes

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.


   .. py:method:: astype(self, dtype) -> arkouda.pdarrayclass.pdarray

      Cast values of Strings object to provided dtype

      :param dtype: Dtype to cast to
      :type dtype: np.dtype or str

      :returns: An arkouda pdarray with values converted to the specified data type
      :rtype: ak.pdarray

      .. rubric:: Notes

      This is essentially shorthand for ak.cast(x, '<dtype>') where x is a pdarray.


   .. py:method:: save(self, prefix_path: str, dataset: str = 'strings_array', mode: str = 'truncate', save_offsets: bool = True, compressed: bool = False, file_format: str = 'HDF5') -> str

      Save the Strings object to HDF5 or Parquet. The result is a collection of
      files, one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the Strings array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: The name of the Strings dataset to be written, defaults to strings_array
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Strings dataset within existing files.
      :type mode: str {'truncate' | 'append'}
      :param save_offsets: Defaults to True which will instruct the server to save the offsets array to HDF5
                           If False the offsets array will not be save and will be derived from the string values
                           upon load/read. This is not supported for Parquet files.
      :type save_offsets: bool
      :param compressed: Defaults to False. When True, files will be written with Snappy compression
                         and RLE bit packing. This is currently only supported on Parquet files and will
                         not impact the generated files when writing HDF5 files.
      :type compressed: bool
      :param file_format: By default, saved files will be written to the HDF5 file format. If
                          'Parquet', the files will be written to the Parquet file format. This
                          is case insensitive.
      :type file_format: str

      :rtype: String message indicating result of save operation

      :raises ValueError: Raised if the lengths of columns and values differ, or the mode is
          neither 'truncate' nor 'append'
      :raises TypeError: Raised if prefix_path, dataset, or mode is not a str

      .. seealso:: :obj:`pdarrayIO.save`

      .. rubric:: Notes

      Important implementation notes: (1) Strings state is saved as two datasets
      within an hdf5 group: one for the string characters and one for the
      segments corresponding to the start of each string, (2) the hdf5 group is named
      via the dataset parameter.


   .. py:method:: save_parquet(self, prefix_path: str, dataset: str = 'strings_array', mode: str = 'truncate', compressed: bool = False) -> str

      Save the Strings object to Parquet. The result is a collection of Parquet files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the Strings array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: The name of the Strings dataset to be written, defaults to strings_array
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Strings dataset within existing files.
      :type mode: str {'truncate' | 'append'}
      :param compressed: Defaults to False. When True, files will be written with Snappy compression
                         and RLE bit packing.
      :type compressed: bool

      :rtype: String message indicating result of save operation

      :raises ValueError: Raised if the lengths of columns and values differ, or the mode is
          neither 'truncate' nor 'append'
      :raises TypeError: Raised if prefix_path, dataset, or mode is not a str

      .. seealso:: :obj:`strings.save`, :obj:`pdarray.save_parquet`


   .. py:method:: save_hdf(self, prefix_path: str, dataset: str = 'strings_array', mode: str = 'truncate', save_offsets: bool = True) -> str

      Save the Strings object to HDF5. The result is a collection of HDF5 files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the Strings array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: The name of the Strings dataset to be written, defaults to strings_array
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Strings dataset within existing files.
      :type mode: str {'truncate' | 'append'}
      :param save_offsets: Defaults to True which will instruct the server to save the offsets array to HDF5
                           If False the offsets array will not be save and will be derived from the string values
                           upon load/read.
      :type save_offsets: bool

      :rtype: String message indicating result of save operation

      :raises ValueError: Raised if the lengths of columns and values differ, or the mode is
          neither 'truncate' nor 'append'
      :raises TypeError: Raised if prefix_path, dataset, or mode is not a str

      .. seealso:: :obj:`strings.save`, :obj:`pdarray.save`


   .. py:method:: is_registered(self) -> numpy.bool_

      Return True iff the object is contained in the registry

      :param None:

      :returns: Indicates if the object is contained in the registry
      :rtype: bool

      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: _list_component_names(self) -> List[str]

      Internal Function that returns a list of all component names

      :param None:

      :returns: List of all component names
      :rtype: List[str]


   .. py:method:: info(self) -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str


   .. py:method:: pretty_print_info(self) -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None


   .. py:method:: register(self, user_defined_name: str) -> Strings

      Register this Strings object with a user defined name in the arkouda server
      so it can be attached to later using Strings.attach()
      This is an in-place operation, registering a Strings object more than once will
      update the name in the registry and remove the previously registered name.
      A name can only be registered to one object at a time.

      :param user_defined_name: user defined name which the Strings object is to be registered under
      :type user_defined_name: str

      :returns: The same Strings object which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support a fluid programming style.
                Please note you cannot register two different objects with the same name.
      :rtype: Strings

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the Strings object with the user_defined_name
          If the user is attempting to register more than one object with the same name, the former should be
          unregistered first to free up the registration name.

      .. seealso:: :obj:`attach`, :obj:`unregister`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion
      until they are unregistered.


   .. py:method:: unregister(self) -> None

      Unregister a Strings object in the arkouda server which was previously
      registered using register() and/or attached to using attach()


      :rtype: None

      :raises RuntimeError: Raised if the server could not find the internal name/symbol to remove

      .. seealso:: :obj:`register`, :obj:`attach`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion until
      they are unregistered.


   .. py:method:: attach(user_defined_name: str) -> Strings
      :staticmethod:

      class method to return a Strings object attached to the registered name in the arkouda
      server which was registered using register()

      :param user_defined_name: user defined name which the Strings object was registered under
      :type user_defined_name: str

      :returns: the Strings object registered with user_defined_name in the arkouda server
      :rtype: Strings object

      :raises TypeError: Raised if user_defined_name is not a str

      .. seealso:: :obj:`register`, :obj:`unregister`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion
      until they are unregistered.


   .. py:method:: unregister_strings_by_name(user_defined_name: str) -> None
      :staticmethod:

      Unregister a Strings object in the arkouda server previously registered via register()

      :param user_defined_name: The registered name of the Strings object
      :type user_defined_name: str

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`attach`, :obj:`is_registered`



.. py:class:: CachedAccessor(name: str, accessor)

   Custom property-like object.
   A descriptor for caching accessors.
   :param name: Namespace that will be accessed under, e.g. ``df.foo``.
   :type name: str
   :param accessor: Class with the extension methods.
   :type accessor: cls

   .. rubric:: Notes

   For accessor, The class's __init__ method assumes that one of
   ``Series``, ``DataFrame`` or ``Index`` as the
   single argument ``data``.

   .. py:method:: __get__(self, obj, cls)



.. py:function:: string_operators(cls)


.. py:function:: date_operators(cls)


.. py:class:: Properties

   .. py:method:: _make_op(cls, name)
      :classmethod:



.. py:class:: DatetimeAccessor(series)

   Bases: :py:obj:`Properties`


.. py:class:: StringAccessor(series)

   Bases: :py:obj:`Properties`


