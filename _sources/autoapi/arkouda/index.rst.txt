:py:mod:`arkouda`
=================

.. py:module:: arkouda


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   _version/index.rst
   categorical/index.rst
   client/index.rst
   dtypes/index.rst
   groupbyclass/index.rst
   infoclass/index.rst
   io_util/index.rst
   join/index.rst
   logger/index.rst
   match/index.rst
   matcher/index.rst
   message/index.rst
   numeric/index.rst
   pdarrayIO/index.rst
   pdarrayclass/index.rst
   pdarraycreation/index.rst
   pdarraysetops/index.rst
   security/index.rst
   sorting/index.rst
   strings/index.rst
   timeclass/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   arkouda.ErrorMode
   arkouda.GroupBy
   arkouda.Strings
   arkouda.Categorical



Functions
~~~~~~~~~

.. autoapisummary::

   arkouda.get_versions
   arkouda.check_np_dtype
   arkouda.translate_np_dtype
   arkouda.resolve_scalar_dtype
   arkouda.get_byteorder
   arkouda.get_server_byteorder
   arkouda.argsort
   arkouda.coargsort
   arkouda.sort
   arkouda.unique
   arkouda.in1d
   arkouda.concatenate
   arkouda.union1d
   arkouda.intersect1d
   arkouda.setdiff1d
   arkouda.setxor1d
   arkouda.array
   arkouda.zeros
   arkouda.ones
   arkouda.zeros_like
   arkouda.ones_like
   arkouda.arange
   arkouda.linspace
   arkouda.randint
   arkouda.uniform
   arkouda.standard_normal
   arkouda.random_strings_uniform
   arkouda.random_strings_lognormal
   arkouda.from_series
   arkouda.cast
   arkouda.abs
   arkouda.log
   arkouda.exp
   arkouda.cumsum
   arkouda.cumprod
   arkouda.sin
   arkouda.cos
   arkouda.hash
   arkouda.where
   arkouda.histogram
   arkouda.value_counts
   arkouda.isnan
   arkouda.ls_hdf
   arkouda.read_hdf
   arkouda.read_all
   arkouda.load
   arkouda.get_datasets
   arkouda.load_all
   arkouda.save_all
   arkouda.read_parquet
   arkouda.broadcast
   arkouda.join_on_eq_with_dt
   arkouda.enableVerbose
   arkouda.disableVerbose
   arkouda.information
   arkouda.list_registry
   arkouda.list_symbol_table
   arkouda.pretty_print_information



Attributes
~~~~~~~~~~

.. autoapisummary::

   arkouda.__version__
   arkouda.DTypes
   arkouda.DTypeObjects
   arkouda.dtype
   arkouda.bool
   arkouda.int64
   arkouda.float64
   arkouda.uint8
   arkouda.uint64
   arkouda.str_
   arkouda.ARKOUDA_SUPPORTED_DTYPES
   arkouda.bool_scalars
   arkouda.float_scalars
   arkouda.int_scalars
   arkouda.numeric_scalars
   arkouda.numpy_scalars
   arkouda.str_scalars
   arkouda.all_scalars
   arkouda.SortingAlgorithm
   arkouda.GROUPBY_REDUCTION_TYPES
   arkouda.AllSymbols
   arkouda.RegisteredSymbols


.. py:function:: get_versions()

   Get version information or return default if unable to do so.


.. py:data:: __version__
   

   

.. py:data:: DTypes
   

   

.. py:data:: DTypeObjects
   

   

.. py:data:: dtype
   

   

.. py:data:: bool
   

   

.. py:data:: int64
   

   

.. py:data:: float64
   

   

.. py:data:: uint8
   

   

.. py:data:: uint64
   

   

.. py:data:: str_
   

   

.. py:function:: check_np_dtype(dt: numpy.dtype) -> None

   Assert that numpy dtype dt is one of the dtypes supported
   by arkouda, otherwise raise TypeError.

   :raises TypeError: Raised if the dtype is not in supported dtypes or if
       dt is not a np.dtype


.. py:function:: translate_np_dtype(dt: numpy.dtype) -> Tuple[str, int]

   Split numpy dtype dt into its kind and byte size, raising
   TypeError for unsupported dtypes.

   :raises TypeError: Raised if the dtype is not in supported dtypes or if
       dt is not a np.dtype


.. py:function:: resolve_scalar_dtype(val: object) -> str

   Try to infer what dtype arkouda_server should treat val as.


.. py:data:: ARKOUDA_SUPPORTED_DTYPES
   

   

.. py:data:: bool_scalars
   

   

.. py:data:: float_scalars
   

   

.. py:data:: int_scalars
   

   

.. py:data:: numeric_scalars
   

   

.. py:data:: numpy_scalars
   

   

.. py:data:: str_scalars
   

   

.. py:data:: all_scalars
   

   The DType enum defines the supported Arkouda data types in string form.

.. py:function:: get_byteorder(dt: numpy.dtype) -> str

   Get a concrete byteorder (turns '=' into '<' or '>')


.. py:function:: get_server_byteorder() -> str

   Get the server's byteorder


.. py:function:: argsort(pda: Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, arkouda.categorical.Categorical], algorithm: SortingAlgorithm = SortingAlgorithm.RadixSortLSD) -> arkouda.pdarrayclass.pdarray

   Return the permutation that sorts the array.

   :param pda: The array to sort (int64, uint64, or float64)
   :type pda: pdarray or Strings or Categorical

   :returns: The indices such that ``pda[indices]`` is sorted
   :rtype: pdarray, int64

   :raises TypeError: Raised if the parameter is other than a pdarray or Strings

   .. seealso:: :obj:`coargsort`

   .. rubric:: Notes

   Uses a least-significant-digit radix sort, which is stable and
   resilient to non-uniformity in data but communication intensive.

   .. rubric:: Examples

   >>> a = ak.randint(0, 10, 10)
   >>> perm = ak.argsort(a)
   >>> a[perm]
   array([0, 1, 1, 3, 4, 5, 7, 8, 8, 9])


.. py:function:: coargsort(arrays: Sequence[Union[arkouda.strings.Strings, arkouda.pdarrayclass.pdarray, arkouda.categorical.Categorical]], algorithm: SortingAlgorithm = SortingAlgorithm.RadixSortLSD) -> arkouda.pdarrayclass.pdarray

   Return the permutation that groups the rows (left-to-right), if the
   input arrays are treated as columns. The permutation sorts numeric
   columns, but not strings/Categoricals -- strings/Categoricals are grouped, but not ordered.

   :param arrays: The columns (int64, uint64, float64, Strings, or Categorical) to sort by row
   :type arrays: Sequence[Union[Strings, pdarray, Categorical]]

   :returns: The indices that permute the rows to grouped order
   :rtype: pdarray, int64

   :raises ValueError: Raised if the pdarrays are not of the same size or if the parameter
       is not an Iterable containing pdarrays, Strings, or Categoricals

   .. seealso:: :obj:`argsort`

   .. rubric:: Notes

   Uses a least-significant-digit radix sort, which is stable and resilient
   to non-uniformity in data but communication intensive. Starts with the
   last array and moves forward. This sort operates directly on numeric types,
   but for Strings, it operates on a hash. Thus, while grouping of equivalent
   strings is guaranteed, lexicographic ordering of the groups is not. For Categoricals,
   coargsort sorts based on Categorical.codes which guarantees grouping of equivalent categories
   but not lexicographic ordering of those groups.

   .. rubric:: Examples

   >>> a = ak.array([0, 1, 0, 1])
   >>> b = ak.array([1, 1, 0, 0])
   >>> perm = ak.coargsort([a, b])
   >>> perm
   array([2, 0, 3, 1])
   >>> a[perm]
   array([0, 0, 1, 1])
   >>> b[perm]
   array([0, 1, 0, 1])


.. py:function:: sort(pda: arkouda.pdarrayclass.pdarray, algorithm: SortingAlgorithm = SortingAlgorithm.RadixSortLSD) -> arkouda.pdarrayclass.pdarray

   Return a sorted copy of the array. Only sorts numeric arrays;
   for Strings, use argsort.

   :param pda: The array to sort (int64, uint64, or float64)
   :type pda: pdarray or Categorical

   :returns: The sorted copy of pda
   :rtype: pdarray, int64, uint64, or float64

   :raises TypeError: Raised if the parameter is not a pdarray
   :raises ValueError: Raised if sort attempted on a pdarray with an unsupported dtype
       such as bool

   .. seealso:: :obj:`argsort`

   .. rubric:: Notes

   Uses a least-significant-digit radix sort, which is stable and resilient
   to non-uniformity in data but communication intensive.

   .. rubric:: Examples

   >>> a = ak.randint(0, 10, 10)
   >>> sorted = ak.sort(a)
   >>> a
   array([0, 1, 1, 3, 4, 5, 7, 8, 8, 9])


.. py:data:: SortingAlgorithm
   

   

.. py:function:: unique(pda: Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, Categorical], return_counts: bool = False) -> Union[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, Categorical], Tuple[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, Categorical], Optional[arkouda.pdarrayclass.pdarray]]]

   Find the unique elements of an array.

   Returns the unique elements of an array, sorted if the values are integers.
   There is an optional output in addition to the unique elements: the number
   of times each unique value comes up in the input array.

   :param pda: Input array.
   :type pda: pdarray or Strings or Categorical
   :param return_counts: If True, also return the number of times each unique item appears
                         in `pda`.
   :type return_counts: bool, optional

   :returns: * **unique** (*pdarray or Strings*) -- The unique values. If input dtype is int64, return values will be sorted.
             * **unique_counts** (*pdarray, optional*) -- The number of times each of the unique values comes up in the
               original array. Only provided if `return_counts` is True.

   :raises TypeError: Raised if pda is not a pdarray or Strings object
   :raises RuntimeError: Raised if the pdarray or Strings dtype is unsupported

   .. rubric:: Notes

   For integer arrays, this function checks to see whether `pda` is sorted
   and, if so, whether it is already unique. This step can save considerable
   computation. Otherwise, this function will sort `pda`.

   .. rubric:: Examples

   >>> A = ak.array([3, 2, 1, 1, 2, 3])
   >>> ak.unique(A)
   array([1, 2, 3])


.. py:function:: in1d(pda1: Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, Categorical], pda2: Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, Categorical], invert: bool = False) -> arkouda.pdarrayclass.pdarray

   Test whether each element of a 1-D array is also present in a second array.

   Returns a boolean array the same length as `pda1` that is True
   where an element of `pda1` is in `pda2` and False otherwise.

   :param pda1: Input array.
   :type pda1: pdarray or Strings or Categorical
   :param pda2: The values against which to test each value of `pda1`. Must be the
                same type as `pda1`.
   :type pda2: pdarray or Strings or Categorical
   :param invert: If True, the values in the returned array are inverted (that is,
                  False where an element of `pda1` is in `pda2` and True otherwise).
                  Default is False. ``ak.in1d(a, b, invert=True)`` is equivalent
                  to (but is faster than) ``~ak.in1d(a, b)``.
   :type invert: bool, optional

   :returns: The values `pda1[in1d]` are in `pda2`.
   :rtype: pdarray, bool

   :raises TypeError: Raised if either pda1 or pda2 is not a pdarray, Strings, or
       Categorical object or if invert is not a bool
   :raises RuntimeError: Raised if the dtype of either array is not supported

   .. seealso:: :obj:`unique`, :obj:`intersect1d`, :obj:`union1d`

   .. rubric:: Notes

   `in1d` can be considered as an element-wise function version of the
   python keyword `in`, for 1-D sequences. ``in1d(a, b)`` is logically
   equivalent to ``ak.array([item in b for item in a])``, but is much
   faster and scales to arbitrarily large ``a``.

   ak.in1d is not supported for bool or float64 pdarrays

   .. rubric:: Examples

   >>> ak.in1d(ak.array([-1, 0, 1]), ak.array([-2, 0, 2]))
   array([False, True, False])

   >>> ak.in1d(ak.array(['one','two']),ak.array(['two', 'three','four','five']))
   array([False, True])


.. py:function:: concatenate(arrays: Sequence[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, Categorical]], ordered: bool = True) -> Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, Categorical]

   Concatenate a list or tuple of ``pdarray`` or ``Strings`` objects into
   one ``pdarray`` or ``Strings`` object, respectively.

   :param arrays: The arrays to concatenate. Must all have same dtype.
   :type arrays: Sequence[Union[pdarray,Strings,Categorical]]
   :param ordered: If True (default), the arrays will be appended in the
                   order given. If False, array data may be interleaved
                   in blocks, which can greatly improve performance but
                   results in non-deterministic ordering of elements.
   :type ordered: bool

   :returns: Single pdarray or Strings object containing all values, returned in
             the original order
   :rtype: Union[pdarray,Strings,Categorical]

   :raises ValueError: Raised if arrays is empty or if 1..n pdarrays have
       differing dtypes
   :raises TypeError: Raised if arrays is not a pdarrays or Strings python Sequence such as a
       list or tuple
   :raises RuntimeError: Raised if 1..n array elements are dtypes for which
       concatenate has not been implemented.

   .. rubric:: Examples

   >>> ak.concatenate([ak.array([1, 2, 3]), ak.array([4, 5, 6])])
   array([1, 2, 3, 4, 5, 6])

   >>> ak.concatenate([ak.array([True,False,True]),ak.array([False,True,True])])
   array([True, False, True, False, True, True])

   >>> ak.concatenate([ak.array(['one','two']),ak.array(['three','four','five'])])
   array(['one', 'two', 'three', 'four', 'five'])


.. py:function:: union1d(pda1: arkouda.pdarrayclass.pdarray, pda2: arkouda.pdarrayclass.pdarray) -> arkouda.pdarrayclass.pdarray

   Find the union of two arrays.

   Return the unique, sorted array of values that are in either
   of the two input arrays.

   :param pda1: Input array
   :type pda1: pdarray
   :param pda2: Input array
   :type pda2: pdarray

   :returns: Unique, sorted union of the input arrays.
   :rtype: pdarray

   :raises TypeError: Raised if either pda1 or pda2 is not a pdarray
   :raises RuntimeError: Raised if the dtype of either array is not supported

   .. seealso:: :obj:`intersect1d`, :obj:`unique`

   .. rubric:: Notes

   ak.union1d is not supported for bool or float64 pdarrays

   .. rubric:: Examples

   >>> ak.union1d(ak.array([-1, 0, 1]), ak.array([-2, 0, 2]))
   array([-2, -1, 0, 1, 2])


.. py:function:: intersect1d(pda1: arkouda.pdarrayclass.pdarray, pda2: arkouda.pdarrayclass.pdarray, assume_unique: bool = False) -> arkouda.pdarrayclass.pdarray

   Find the intersection of two arrays.

   Return the sorted, unique values that are in both of the input arrays.

   :param pda1: Input array
   :type pda1: pdarray
   :param pda2: Input array
   :type pda2: pdarray
   :param assume_unique: If True, the input arrays are both assumed to be unique, which
                         can speed up the calculation.  Default is False.
   :type assume_unique: bool

   :returns: Sorted 1D array of common and unique elements.
   :rtype: pdarray

   :raises TypeError: Raised if either pda1 or pda2 is not a pdarray
   :raises RuntimeError: Raised if the dtype of either pdarray is not supported

   .. seealso:: :obj:`unique`, :obj:`union1d`

   .. rubric:: Notes

   ak.intersect1d is not supported for bool or float64 pdarrays

   .. rubric:: Examples

   >>> ak.intersect1d([1, 3, 4, 3], [3, 1, 2, 1])
   array([1, 3])


.. py:function:: setdiff1d(pda1: arkouda.pdarrayclass.pdarray, pda2: arkouda.pdarrayclass.pdarray, assume_unique: bool = False) -> arkouda.pdarrayclass.pdarray

   Find the set difference of two arrays.

   Return the sorted, unique values in `pda1` that are not in `pda2`.

   :param pda1: Input array.
   :type pda1: pdarray
   :param pda2: Input comparison array.
   :type pda2: pdarray
   :param assume_unique: If True, the input arrays are both assumed to be unique, which
                         can speed up the calculation.  Default is False.
   :type assume_unique: bool

   :returns: Sorted 1D array of values in `pda1` that are not in `pda2`.
   :rtype: pdarray

   :raises TypeError: Raised if either pda1 or pda2 is not a pdarray
   :raises RuntimeError: Raised if the dtype of either pdarray is not supported

   .. seealso:: :obj:`unique`, :obj:`setxor1d`

   .. rubric:: Notes

   ak.setdiff1d is not supported for bool or float64 pdarrays

   .. rubric:: Examples

   >>> a = ak.array([1, 2, 3, 2, 4, 1])
   >>> b = ak.array([3, 4, 5, 6])
   >>> ak.setdiff1d(a, b)
   array([1, 2])


.. py:function:: setxor1d(pda1: arkouda.pdarrayclass.pdarray, pda2: arkouda.pdarrayclass.pdarray, assume_unique: bool = False) -> arkouda.pdarrayclass.pdarray

   Find the set exclusive-or (symmetric difference) of two arrays.

   Return the sorted, unique values that are in only one (not both) of the
   input arrays.

   :param pda1: Input array.
   :type pda1: pdarray
   :param pda2: Input array.
   :type pda2: pdarray
   :param assume_unique: If True, the input arrays are both assumed to be unique, which
                         can speed up the calculation.  Default is False.
   :type assume_unique: bool

   :returns: Sorted 1D array of unique values that are in only one of the input
             arrays.
   :rtype: pdarray

   :raises TypeError: Raised if either pda1 or pda2 is not a pdarray
   :raises RuntimeError: Raised if the dtype of either pdarray is not supported

   .. rubric:: Notes

   ak.setxor1d is not supported for bool or float64 pdarrays

   .. rubric:: Examples

   >>> a = ak.array([1, 2, 3, 2, 4])
   >>> b = ak.array([2, 3, 5, 7, 5])
   >>> ak.setxor1d(a,b)
   array([1, 4, 5, 7])


.. py:function:: array(a: Union[arkouda.pdarrayclass.pdarray, numpy.ndarray, Iterable]) -> Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]

   Convert a Python or Numpy Iterable to a pdarray or Strings object, sending
   the corresponding data to the arkouda server.

   :param a: Rank-1 array of a supported dtype
   :type a: Union[pdarray, np.ndarray]

   :returns: A pdarray instance stored on arkouda server or Strings instance, which
             is composed of two pdarrays stored on arkouda server
   :rtype: pdarray or Strings

   :raises TypeError: Raised if a is not a pdarray, np.ndarray, or Python Iterable such as a
       list, array, tuple, or deque
   :raises RuntimeError: Raised if a is not one-dimensional, nbytes > maxTransferBytes, a.dtype is
       not supported (not in DTypes), or if the product of a size and
       a.itemsize > maxTransferBytes
   :raises ValueError: Raised if the returned message is malformed or does not contain the fields
       required to generate the array.

   .. seealso:: :obj:`pdarray.to_ndarray`

   .. rubric:: Notes

   The number of bytes in the input array cannot exceed `arkouda.maxTransferBytes`,
   otherwise a RuntimeError will be raised. This is to protect the user
   from overwhelming the connection between the Python client and the arkouda
   server, under the assumption that it is a low-bandwidth connection. The user
   may override this limit by setting ak.maxTransferBytes to a larger value,
   but should proceed with caution.

   If the pdrray or ndarray is of type U, this method is called twice recursively
   to create the Strings object and the two corresponding pdarrays for string
   bytes and offsets, respectively.

   .. rubric:: Examples

   >>> ak.array(np.arange(1,10))
   array([1, 2, 3, 4, 5, 6, 7, 8, 9])

   >>> ak.array(range(1,10))
   array([1, 2, 3, 4, 5, 6, 7, 8, 9])

   >>> strings = ak.array(['string {}'.format(i) for i in range(0,5)])
   >>> type(strings)
   <class 'arkouda.strings.Strings'>


.. py:function:: zeros(size: arkouda.dtypes.int_scalars, dtype=float64) -> arkouda.pdarrayclass.pdarray

   Create a pdarray filled with zeros.

   :param size: Size of the array (only rank-1 arrays supported)
   :type size: int_scalars
   :param dtype: Type of resulting array, default float64
   :type dtype: all_scalars

   :returns: Zeros of the requested size and dtype
   :rtype: pdarray

   :raises TypeError: Raised if the supplied dtype is not supported or if the size
       parameter is neither an int nor a str that is parseable to an int.

   .. seealso:: :obj:`ones`, :obj:`zeros_like`

   .. rubric:: Examples

   >>> ak.zeros(5, dtype=ak.int64)
   array([0, 0, 0, 0, 0])

   >>> ak.zeros(5, dtype=ak.float64)
   array([0, 0, 0, 0, 0])

   >>> ak.zeros(5, dtype=ak.bool)
   array([False, False, False, False, False])


.. py:function:: ones(size: arkouda.dtypes.int_scalars, dtype=float64) -> arkouda.pdarrayclass.pdarray

   Create a pdarray filled with ones.

   :param size: Size of the array (only rank-1 arrays supported)
   :type size: int_scalars
   :param dtype: Resulting array type, default float64
   :type dtype: Union[float64, int64, bool]

   :returns: Ones of the requested size and dtype
   :rtype: pdarray

   :raises TypeError: Raised if the supplied dtype is not supported or if the size
       parameter is neither an int nor a str that is parseable to an int.

   .. seealso:: :obj:`zeros`, :obj:`ones_like`

   .. rubric:: Examples

   >>> ak.ones(5, dtype=ak.int64)
   array([1, 1, 1, 1, 1])

   >>> ak.ones(5, dtype=ak.float64)
   array([1, 1, 1, 1, 1])

   >>> ak.ones(5, dtype=ak.bool)
   array([True, True, True, True, True])


.. py:function:: zeros_like(pda: arkouda.pdarrayclass.pdarray) -> arkouda.pdarrayclass.pdarray

   Create a zero-filled pdarray of the same size and dtype as an existing
   pdarray.

   :param pda: Array to use for size and dtype
   :type pda: pdarray

   :returns: Equivalent to ak.zeros(pda.size, pda.dtype)
   :rtype: pdarray

   :raises TypeError: Raised if the pda parameter is not a pdarray.

   .. seealso:: :obj:`zeros`, :obj:`ones_like`

   .. rubric:: Examples

   >>> zeros = ak.zeros(5, dtype=ak.int64)
   >>> ak.zeros_like(zeros)
   array([0, 0, 0, 0, 0])

   >>> zeros = ak.zeros(5, dtype=ak.float64)
   >>> ak.zeros_like(zeros)
   array([0, 0, 0, 0, 0])

   >>> zeros = ak.zeros(5, dtype=ak.bool)
   >>> ak.zeros_like(zeros)
   array([False, False, False, False, False])


.. py:function:: ones_like(pda: arkouda.pdarrayclass.pdarray) -> arkouda.pdarrayclass.pdarray

   Create a one-filled pdarray of the same size and dtype as an existing
   pdarray.

   :param pda: Array to use for size and dtype
   :type pda: pdarray

   :returns: Equivalent to ak.ones(pda.size, pda.dtype)
   :rtype: pdarray

   :raises TypeError: Raised if the pda parameter is not a pdarray.

   .. seealso:: :obj:`ones`, :obj:`zeros_like`

   .. rubric:: Notes

   Logic for generating the pdarray is delegated to the ak.ones method.
   Accordingly, the supported dtypes match are defined by the ak.ones method.

   .. rubric:: Examples

   >>> ones = ak.ones(5, dtype=ak.int64)
    >>> ak.ones_like(ones)
   array([1, 1, 1, 1, 1])

   >>> ones = ak.ones(5, dtype=ak.float64)
   >>> ak.ones_like(ones)
   array([1, 1, 1, 1, 1])

   >>> ones = ak.ones(5, dtype=ak.bool)
   >>> ak.ones_like(ones)
   array([True, True, True, True, True])


.. py:function:: arange(*args, **kwargs) -> arkouda.pdarrayclass.pdarray

   arange([start,] stop[, stride,] dtype=int64)

   Create a pdarray of consecutive integers within the interval [start, stop).
   If only one arg is given then arg is the stop parameter. If two args are
   given, then the first arg is start and second is stop. If three args are
   given, then the first arg is start, second is stop, third is stride.

   The return value is cast to type dtype

   :param start: Starting value (inclusive)
   :type start: int_scalars, optional
   :param stop: Stopping value (exclusive)
   :type stop: int_scalars
   :param stride: The difference between consecutive elements, the default stride is 1,
                  if stride is specified then start must also be specified.
   :type stride: int_scalars, optional

   :returns: Integers from start (inclusive) to stop (exclusive) by stride
   :rtype: pdarray, dtype

   :raises TypeError: Raised if start, stop, or stride is not an int object
   :raises ZeroDivisionError: Raised if stride == 0

   .. seealso:: :obj:`linspace`, :obj:`zeros`, :obj:`ones`, :obj:`randint`

   .. rubric:: Notes

   Negative strides result in decreasing values. Currently, only int64
   pdarrays can be created with this method. For float64 arrays, use
   the linspace method.

   .. rubric:: Examples

   >>> ak.arange(0, 5, 1)
   array([0, 1, 2, 3, 4])

   >>> ak.arange(5, 0, -1)
   array([5, 4, 3, 2, 1])

   >>> ak.arange(0, 10, 2)
   array([0, 2, 4, 6, 8])

   >>> ak.arange(-5, -10, -1)
   array([-5, -6, -7, -8, -9])


.. py:function:: linspace(start: arkouda.dtypes.numeric_scalars, stop: arkouda.dtypes.numeric_scalars, length: arkouda.dtypes.int_scalars) -> arkouda.pdarrayclass.pdarray

   Create a pdarray of linearly-spaced floats in a closed interval.

   :param start: Start of interval (inclusive)
   :type start: numeric_scalars
   :param stop: End of interval (inclusive)
   :type stop: numeric_scalars
   :param length: Number of points
   :type length: int_scalars

   :returns: Array of evenly spaced float values along the interval
   :rtype: pdarray, float64

   :raises TypeError: Raised if start or stop is not a float or int or if length is not an int

   .. seealso:: :obj:`arange`

   .. rubric:: Notes

   If that start is greater than stop, the pdarray values are generated
   in descending order.

   .. rubric:: Examples

   >>> ak.linspace(0, 1, 5)
   array([0, 0.25, 0.5, 0.75, 1])

   >>> ak.linspace(start=1, stop=0, length=5)
   array([1, 0.75, 0.5, 0.25, 0])

   >>> ak.linspace(start=-5, stop=0, length=5)
   array([-5, -3.75, -2.5, -1.25, 0])


.. py:function:: randint(low: arkouda.dtypes.numeric_scalars, high: arkouda.dtypes.numeric_scalars, size: arkouda.dtypes.int_scalars, dtype=int64, seed: arkouda.dtypes.int_scalars = None) -> arkouda.pdarrayclass.pdarray

   Generate a pdarray of randomized int, float, or bool values in a
   specified range bounded by the low and high parameters.

   :param low: The low value (inclusive) of the range
   :type low: numeric_scalars
   :param high: The high value (exclusive for int, inclusive for float) of the range
   :type high: numeric_scalars
   :param size: The length of the returned array
   :type size: int_scalars
   :param dtype: The dtype of the array
   :type dtype: Union[int64, float64, bool]
   :param seed: Index for where to pull the first returned value
   :type seed: int_scalars

   :returns: Values drawn uniformly from the specified range having the desired dtype
   :rtype: pdarray

   :raises TypeError: Raised if dtype.name not in DTypes, size is not an int, low or high is
       not an int or float, or seed is not an int
   :raises ValueError: Raised if size < 0 or if high < low

   .. rubric:: Notes

   Calling randint with dtype=float64 will result in uniform non-integral
   floating point values.

   .. rubric:: Examples

   >>> ak.randint(0, 10, 5)
   array([5, 7, 4, 8, 3])

   >>> ak.randint(0, 1, 3, dtype=ak.float64)
   array([0.92176432277231968, 0.083130710959903542, 0.68894208386667544])

   >>> ak.randint(0, 1, 5, dtype=ak.bool)
   array([True, False, True, True, True])

   >>> ak.randint(1, 5, 10, seed=2)
   array([4, 3, 1, 3, 4, 4, 2, 4, 3, 2])

   >>> ak.randint(1, 5, 3, dtype=ak.float64, seed=2)
   array([2.9160772326374946, 4.353429832157099, 4.5392023718621486])

   >>> ak.randint(1, 5, 10, dtype=ak.bool, seed=2)
   array([False, True, True, True, True, False, True, True, True, True])


.. py:function:: uniform(size: arkouda.dtypes.int_scalars, low: arkouda.dtypes.numeric_scalars = float(0.0), high: arkouda.dtypes.numeric_scalars = 1.0, seed: Union[None, arkouda.dtypes.int_scalars] = None) -> arkouda.pdarrayclass.pdarray

   Generate a pdarray with uniformly distributed random float values
   in a specified range.

   :param low: The low value (inclusive) of the range, defaults to 0.0
   :type low: float_scalars
   :param high: The high value (inclusive) of the range, defaults to 1.0
   :type high: float_scalars
   :param size: The length of the returned array
   :type size: int_scalars
   :param seed: Value used to initialize the random number generator
   :type seed: int_scalars, optional

   :returns: Values drawn uniformly from the specified range
   :rtype: pdarray, float64

   :raises TypeError: Raised if dtype.name not in DTypes, size is not an int, or if
       either low or high is not an int or float
   :raises ValueError: Raised if size < 0 or if high < low

   .. rubric:: Notes

   The logic for uniform is delegated to the ak.randint method which
   is invoked with a dtype of float64

   .. rubric:: Examples

   >>> ak.uniform(3)
   array([0.92176432277231968, 0.083130710959903542, 0.68894208386667544])

   >>> ak.uniform(size=3,low=0,high=5,seed=0)
   array([0.30013431967121934, 0.47383036230759112, 1.0441791878997098])


.. py:function:: standard_normal(size: arkouda.dtypes.int_scalars, seed: Union[None, arkouda.dtypes.int_scalars] = None) -> arkouda.pdarrayclass.pdarray

   Draw real numbers from the standard normal distribution.

   :param size: The number of samples to draw (size of the returned array)
   :type size: int_scalars
   :param seed: Value used to initialize the random number generator
   :type seed: int_scalars

   :returns: The array of random numbers
   :rtype: pdarray, float64

   :raises TypeError: Raised if size is not an int
   :raises ValueError: Raised if size < 0

   .. seealso:: :obj:`randint`

   .. rubric:: Notes

   For random samples from :math:`N(\mu, \sigma^2)`, use:

   ``(sigma * standard_normal(size)) + mu``

   .. rubric:: Examples

   >>> ak.standard_normal(3,1)
   array([-0.68586185091150265, 1.1723810583573375, 0.567584107142031])


.. py:function:: random_strings_uniform(minlen: arkouda.dtypes.int_scalars, maxlen: arkouda.dtypes.int_scalars, size: arkouda.dtypes.int_scalars, characters: str = 'uppercase', seed: Union[None, arkouda.dtypes.int_scalars] = None) -> arkouda.strings.Strings

   Generate random strings with lengths uniformly distributed between
   minlen and maxlen, and with characters drawn from a specified set.

   :param minlen: The minimum allowed length of string
   :type minlen: int_scalars
   :param maxlen: The maximum allowed length of string
   :type maxlen: int_scalars
   :param size: The number of strings to generate
   :type size: int_scalars
   :param characters: The set of characters to draw from
   :type characters: (uppercase, lowercase, numeric, printable, binary)
   :param seed: Value used to initialize the random number generator
   :type seed: Union[None, int_scalars], optional

   :returns: The array of random strings
   :rtype: Strings

   :raises ValueError: Raised if minlen < 0, maxlen < minlen, or size < 0

   .. seealso:: :obj:`random_strings_lognormal`, :obj:`randint`

   .. rubric:: Examples

   >>> ak.random_strings_uniform(minlen=1, maxlen=5, seed=1, size=5)
   array(['TVKJ', 'EWAB', 'CO', 'HFMD', 'U'])

   >>> ak.random_strings_uniform(minlen=1, maxlen=5, seed=1, size=5,
   ... characters='printable')
   array(['+5"f', '-P]3', '4k', '~HFF', 'F'])


.. py:function:: random_strings_lognormal(logmean: arkouda.dtypes.numeric_scalars, logstd: arkouda.dtypes.numeric_scalars, size: arkouda.dtypes.int_scalars, characters: str = 'uppercase', seed: Optional[arkouda.dtypes.int_scalars] = None) -> arkouda.strings.Strings

   Generate random strings with log-normally distributed lengths and
   with characters drawn from a specified set.

   :param logmean: The log-mean of the length distribution
   :type logmean: numeric_scalars
   :param logstd: The log-standard-deviation of the length distribution
   :type logstd: numeric_scalars
   :param size: The number of strings to generate
   :type size: int_scalars
   :param characters: The set of characters to draw from
   :type characters: (uppercase, lowercase, numeric, printable, binary)
   :param seed: Value used to initialize the random number generator
   :type seed: int_scalars, optional

   :returns: The Strings object encapsulating a pdarray of random strings
   :rtype: Strings

   :raises TypeError: Raised if logmean is neither a float nor a int, logstd is not a float,
       size is not an int, or if characters is not a str
   :raises ValueError: Raised if logstd <= 0 or size < 0

   .. seealso:: :obj:`random_strings_lognormal`, :obj:`randint`

   .. rubric:: Notes

   The lengths of the generated strings are distributed $Lognormal(\mu, \sigma^2)$,
   with :math:`\mu = logmean` and :math:`\sigma = logstd`. Thus, the strings will
   have an average length of :math:`exp(\mu + 0.5*\sigma^2)`, a minimum length of
   zero, and a heavy tail towards longer strings.

   .. rubric:: Examples

   >>> ak.random_strings_lognormal(2, 0.25, 5, seed=1)
   array(['TVKJTE', 'ABOCORHFM', 'LUDMMGTB', 'KWOQNPHZ', 'VSXRRL'])

   >>> ak.random_strings_lognormal(2, 0.25, 5, seed=1, characters='printable')
   array(['+5"fp-', ']3Q4kC~HF', '=F=`,IE!', 'DjkBa'9(', '5oZ1)='])


.. py:function:: from_series(series: pandas.Series, dtype: Optional[Union[type, str]] = None) -> Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]

   Converts a Pandas Series to an Arkouda pdarray or Strings object. If
   dtype is None, the dtype is inferred from the Pandas Series. Otherwise,
   the dtype parameter is set if the dtype of the Pandas Series is to be
   overridden or is  unknown (for example, in situations where the Series
   dtype is object).

   :param series: The Pandas Series with a dtype of bool, float64, int64, or string
   :type series: Pandas Series
   :param dtype: The valid dtype types are np.bool, np.float64, np.int64, and np.str
   :type dtype: Optional[type]

   :rtype: Union[pdarray,Strings]

   :raises TypeError: Raised if series is not a Pandas Series object
   :raises ValueError: Raised if the Series dtype is not bool, float64, int64, string, datetime, or timedelta

   .. rubric:: Examples

   >>> ak.from_series(pd.Series(np.random.randint(0,10,5)))
   array([9, 0, 4, 7, 9])

   >>> ak.from_series(pd.Series(['1', '2', '3', '4', '5']),dtype=np.int64)
   array([1, 2, 3, 4, 5])

   >>> ak.from_series(pd.Series(np.random.uniform(low=0.0,high=1.0,size=3)))
   array([0.57600036956445599, 0.41619265571741659, 0.6615356693784662])

   >>> ak.from_series(pd.Series(['0.57600036956445599', '0.41619265571741659',
                      '0.6615356693784662']), dtype=np.float64)
   array([0.57600036956445599, 0.41619265571741659, 0.6615356693784662])

   >>> ak.from_series(pd.Series(np.random.choice([True, False],size=5)))
   array([True, False, True, True, True])

   >>> ak.from_series(pd.Series(['True', 'False', 'False', 'True', 'True']), dtype=np.bool)
   array([True, True, True, True, True])

   >>> ak.from_series(pd.Series(['a', 'b', 'c', 'd', 'e'], dtype="string"))
   array(['a', 'b', 'c', 'd', 'e'])

   >>> ak.from_series(pd.Series(['a', 'b', 'c', 'd', 'e']),dtype=np.str)
   array(['a', 'b', 'c', 'd', 'e'])

   >>> ak.from_series(pd.Series(pd.to_datetime(['1/1/2018', np.datetime64('2018-01-01')])))
   array([1514764800000000000, 1514764800000000000])

   .. rubric:: Notes

   The supported datatypes are bool, float64, int64, string, and datetime64[ns]. The
   data type is either inferred from the the Series or is set via the dtype parameter.

   Series of datetime or timedelta are converted to Arkouda arrays of dtype int64 (nanoseconds)

   A Pandas Series containing strings has a dtype of object. Arkouda assumes the Series
   contains strings and sets the dtype to str


.. py:function:: cast(pda: Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings], dt: Union[numpy.dtype, str], errors: ErrorMode = ErrorMode.strict) -> Union[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings], Tuple[arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray]]

   Cast an array to another dtype.

   :param pda: The array of values to cast
   :type pda: pdarray or Strings
   :param dtype: The target dtype to cast values to
   :type dtype: np.dtype or str
   :param errors: Controls how errors are handled when casting strings to a numeric type
                  (ignored for casts from numeric types).
                      - strict: raise RuntimeError if *any* string cannot be converted
                      - ignore: never raise an error. Uninterpretable strings get
                          converted to NaN (float64), -2**63 (int64), zero (uint64 and
                          uint8), or False (bool)
                      - return_validity: in addition to returning the same output as
                        "ignore", also return a bool array indicating where the cast
                        was successful.
   :type errors: {strict, ignore, return_validity}

   :returns: * *pdarray or Strings* -- Array of values cast to desired dtype
             * **[validity** (*pdarray(bool)]*) -- If errors="return_validity" and input is Strings, a second array is
               returned with True where the cast succeeded and False where it failed.

   .. rubric:: Notes

   The cast is performed according to Chapel's casting rules and is NOT safe
   from overflows or underflows. The user must ensure that the target dtype
   has the precision and capacity to hold the desired result.

   .. rubric:: Examples

   >>> ak.cast(ak.linspace(1.0,5.0,5), dt=ak.int64)
   array([1, 2, 3, 4, 5])

   >>> ak.cast(ak.arange(0,5), dt=ak.float64).dtype
   dtype('float64')

   >>> ak.cast(ak.arange(0,5), dt=ak.bool)
   array([False, True, True, True, True])

   >>> ak.cast(ak.linspace(0,4,5), dt=ak.bool)
   array([False, True, True, True, True])


.. py:function:: abs(pda: arkouda.pdarrayclass.pdarray) -> arkouda.pdarrayclass.pdarray

   Return the element-wise absolute value of the array.

   :param pda:
   :type pda: pdarray

   :returns: A pdarray containing absolute values of the input array elements
   :rtype: pdarray

   :raises TypeError: Raised if the parameter is not a pdarray

   .. rubric:: Examples

   >>> ak.abs(ak.arange(-5,-1))
   array([5, 4, 3, 2])

   >>> ak.abs(ak.linspace(-5,-1,5))
   array([5, 4, 3, 2, 1])


.. py:function:: log(pda: arkouda.pdarrayclass.pdarray) -> arkouda.pdarrayclass.pdarray

   Return the element-wise natural log of the array.

   :param pda:
   :type pda: pdarray

   :returns: A pdarray containing natural log values of the input
             array elements
   :rtype: pdarray

   :raises TypeError: Raised if the parameter is not a pdarray

   .. rubric:: Notes

   Logarithms with other bases can be computed as follows:

   .. rubric:: Examples

   >>> A = ak.array([1, 10, 100])
   # Natural log
   >>> ak.log(A)
   array([0, 2.3025850929940459, 4.6051701859880918])
   # Log base 10
   >>> ak.log(A) / np.log(10)
   array([0, 1, 2])
   # Log base 2
   >>> ak.log(A) / np.log(2)
   array([0, 3.3219280948873626, 6.6438561897747253])


.. py:function:: exp(pda: arkouda.pdarrayclass.pdarray) -> arkouda.pdarrayclass.pdarray

   Return the element-wise exponential of the array.

   :param pda:
   :type pda: pdarray

   :returns: A pdarray containing exponential values of the input
             array elements
   :rtype: pdarray

   :raises TypeError: Raised if the parameter is not a pdarray

   .. rubric:: Examples

   >>> ak.exp(ak.arange(1,5))
   array([2.7182818284590451, 7.3890560989306504, 20.085536923187668, 54.598150033144236])

   >>> ak.exp(ak.uniform(5,1.0,5.0))
   array([11.84010843172504, 46.454368507659211, 5.5571769623557188,
          33.494295836924771, 13.478894913238722])


.. py:function:: cumsum(pda: arkouda.pdarrayclass.pdarray) -> arkouda.pdarrayclass.pdarray

   Return the cumulative sum over the array.

   The sum is inclusive, such that the ``i`` th element of the
   result is the sum of elements up to and including ``i``.

   :param pda:
   :type pda: pdarray

   :returns: A pdarray containing cumulative sums for each element
             of the original pdarray
   :rtype: pdarray

   :raises TypeError: Raised if the parameter is not a pdarray

   .. rubric:: Examples

   >>> ak.cumsum(ak.arange([1,5]))
   array([1, 3, 6])

   >>> ak.cumsum(ak.uniform(5,1.0,5.0))
   array([3.1598310770203937, 5.4110385860243131, 9.1622479306453748,
          12.710615785506533, 13.945880905466208])

   >>> ak.cumsum(ak.randint(0, 1, 5, dtype=ak.bool))
   array([0, 1, 1, 2, 3])


.. py:function:: cumprod(pda: arkouda.pdarrayclass.pdarray) -> arkouda.pdarrayclass.pdarray

   Return the cumulative product over the array.

   The product is inclusive, such that the ``i`` th element of the
   result is the product of elements up to and including ``i``.

   :param pda:
   :type pda: pdarray

   :returns: A pdarray containing cumulative products for each element
             of the original pdarray
   :rtype: pdarray

   :raises TypeError: Raised if the parameter is not a pdarray

   .. rubric:: Examples

   >>> ak.cumprod(ak.arange(1,5))
   array([1, 2, 6, 24]))

   >>> ak.cumprod(ak.uniform(5,1.0,5.0))
   array([1.5728783400481925, 7.0472855509390593, 33.78523998586553,
          134.05309592737584, 450.21589865655358])


.. py:function:: sin(pda: arkouda.pdarrayclass.pdarray) -> arkouda.pdarrayclass.pdarray

   Return the element-wise sine of the array.

   :param pda:
   :type pda: pdarray

   :returns: A pdarray containing sin for each element
             of the original pdarray
   :rtype: pdarray

   :raises TypeError: Raised if the parameter is not a pdarray


.. py:function:: cos(pda: arkouda.pdarrayclass.pdarray) -> arkouda.pdarrayclass.pdarray

   Return the element-wise cosine of the array.

   :param pda:
   :type pda: pdarray

   :returns: A pdarray containing cosine for each element
             of the original pdarray
   :rtype: pdarray

   :raises TypeError: Raised if the parameter is not a pdarray


.. py:function:: hash(pda: arkouda.pdarrayclass.pdarray, full: bool = True) -> Union[Tuple[arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray], arkouda.pdarrayclass.pdarray]

   Return an element-wise hash of the array.

   :param pda:
   :type pda: pdarray
   :param full: By default, a 128-bit hash is computed and returned as
                two int64 arrays. If full=False, then a 64-bit hash
                is computed and returned as a single int64 array.
   :type full: bool

   :returns: If full=True, a 2-tuple of pdarrays containing the high
             and low 64 bits of each hash, respectively.
             If full=False, a single pdarray containing a 64-bit hash
   :rtype: hashes

   :raises TypeError: Raised if the parameter is not a pdarray

   .. rubric:: Notes

   This function uses the SIPhash algorithm, which can output
   either a 64-bit or 128-bit hash. However, the 64-bit hash
   runs a significant risk of collisions when applied to more
   than a few million unique values. Unless the number of unique
   values is known to be small, the 128-bit hash is strongly
   recommended.

   Note that this hash should not be used for security, or for
   any cryptographic application. Not only is SIPhash not
   intended for such uses, but this implementation employs a
   fixed key for the hash, which makes it possible for an
   adversary with control over input to engineer collisions.


.. py:function:: where(condition: arkouda.pdarrayclass.pdarray, A: Union[arkouda.dtypes.numeric_scalars, arkouda.pdarrayclass.pdarray], B: Union[arkouda.dtypes.numeric_scalars, arkouda.pdarrayclass.pdarray]) -> arkouda.pdarrayclass.pdarray

   Returns an array with elements chosen from A and B based upon a
   conditioning array. As is the case with numpy.where, the return array
   consists of values from the first array (A) where the conditioning array
   elements are True and from the second array (B) where the conditioning
   array elements are False.

   :param condition: Used to choose values from A or B
   :type condition: pdarray
   :param A: Value(s) used when condition is True
   :type A: Union[numeric_scalars, pdarray]
   :param B: Value(s) used when condition is False
   :type B: Union[numeric_scalars, pdarray]

   :returns: Values chosen from A where the condition is True and B where
             the condition is False
   :rtype: pdarray

   :raises TypeError: Raised if the condition object is not a pdarray, if A or B is not
       an int, np.int64, float, np.float64, or pdarray, if pdarray dtypes
       are not supported or do not match, or multiple condition clauses (see
       Notes section) are applied
   :raises ValueError: Raised if the shapes of the condition, A, and B pdarrays are unequal

   .. rubric:: Examples

   >>> a1 = ak.arange(1,10)
   >>> a2 = ak.ones(9, dtype=np.int64)
   >>> cond = a1 < 5
   >>> ak.where(cond,a1,a2)
   array([1, 2, 3, 4, 1, 1, 1, 1, 1])

   >>> a1 = ak.arange(1,10)
   >>> a2 = ak.ones(9, dtype=np.int64)
   >>> cond = a1 == 5
   >>> ak.where(cond,a1,a2)
   array([1, 1, 1, 1, 5, 1, 1, 1, 1])

   >>> a1 = ak.arange(1,10)
   >>> a2 = 10
   >>> cond = a1 < 5
   >>> ak.where(cond,a1,a2)
   array([1, 2, 3, 4, 10, 10, 10, 10, 10])

   .. rubric:: Notes

   A and B must have the same dtype and only one conditional clause
   is supported e.g., n < 5, n > 1, which is supported in numpy
   is not currently supported in Arkouda


.. py:function:: histogram(pda: arkouda.pdarrayclass.pdarray, bins: arkouda.dtypes.int_scalars = 10) -> arkouda.pdarrayclass.pdarray

   Compute a histogram of evenly spaced bins over the range of an array.

   :param pda: The values to histogram
   :type pda: pdarray
   :param bins: The number of equal-size bins to use (default: 10)
   :type bins: int_scalars

   :returns: The number of values present in each bin
   :rtype: pdarray, int64 or float64

   :raises TypeError: Raised if the parameter is not a pdarray or if bins is
       not an int.
   :raises ValueError: Raised if bins < 1
   :raises NotImplementedError: Raised if pdarray dtype is bool or uint8

   .. seealso:: :obj:`value_counts`

   .. rubric:: Notes

   The bins are evenly spaced in the interval [pda.min(), pda.max()].
   Currently, the user must re-compute the bin edges, e.g. with np.linspace
   (see below) in order to plot the histogram.

   .. rubric:: Examples

   >>> import matplotlib.pyplot as plt
   >>> A = ak.arange(0, 10, 1)
   >>> nbins = 3
   >>> h = ak.histogram(A, bins=nbins)
   >>> h
   array([3, 3, 4])
   # Recreate the bin edges in NumPy
   >>> binEdges = np.linspace(A.min(), A.max(), nbins+1)
   >>> binEdges
   array([0., 3., 6., 9.])
   # To plot, use only the left edges, and export the histogram to NumPy
   >>> plt.plot(binEdges[:-1], h.to_ndarray())


.. py:function:: value_counts(pda: arkouda.pdarrayclass.pdarray) -> Union[Categorical, Tuple[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings], Optional[arkouda.pdarrayclass.pdarray]]]

   Count the occurrences of the unique values of an array.

   :param pda: The array of values to count
   :type pda: pdarray, int64

   :returns: * **unique_values** (*pdarray, int64 or Strings*) -- The unique values, sorted in ascending order
             * **counts** (*pdarray, int64*) -- The number of times the corresponding unique value occurs

   :raises TypeError: Raised if the parameter is not a pdarray

   .. seealso:: :obj:`unique`, :obj:`histogram`

   .. rubric:: Notes

   This function differs from ``histogram()`` in that it only returns
   counts for values that are present, leaving out empty "bins". This
   function delegates all logic to the unique() method where the
   return_counts parameter is set to True.

   .. rubric:: Examples

   >>> A = ak.array([2, 0, 2, 4, 0, 0])
   >>> ak.value_counts(A)
   (array([0, 2, 4]), array([3, 2, 1]))


.. py:function:: isnan(pda: arkouda.pdarrayclass.pdarray) -> arkouda.pdarrayclass.pdarray

   Test a pdarray for Not a number / NaN values
   Currently only supports float-value-based arrays

   :param pda:
   :type pda: pdarray to test

   :rtype: pdarray consisting of True / False values; True where NaN, False otherwise

   :raises TypeError: Raised if the parameter is not a pdarray
   :raises RuntimeError: if the underlying pdarray is not float-based


.. py:class:: ErrorMode

   Bases: :py:obj:`enum.Enum`

   Generic enumeration.

   Derive from this class to define new enumerations.

   .. py:attribute:: strict
      :annotation: = strict

      

   .. py:attribute:: ignore
      :annotation: = ignore

      

   .. py:attribute:: return_validity
      :annotation: = return_validity

      


.. py:function:: ls_hdf(filename: str, is_parquet=False) -> List[str]

   This function calls the h5ls utility on a filename visible to the
   arkouda server.

   :param filename: The name of the file to pass to h5ls
   :type filename: str
   :param is_parquet: Is filename a Parquet file; false by default
   :type is_parquet: bool

   :returns: The string output of `h5ls <filename>` from the server
   :rtype: str

   :raises TypeError: Raised if filename is not a str
   :raises ValueError: Raised if filename is empty or contains only whitespace
   :raises RuntimeError: Raised if error occurs in executing ls on an HDF5 file


.. py:function:: read_hdf(dsetName: str, filenames: Union[str, List[str]], strictTypes: bool = True, allow_errors: bool = False, calc_string_offsets: bool = False) -> Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]

   Read a single dataset from multiple HDF5 files into an Arkouda
   pdarray or Strings object.

   :param dsetName: The name of the dataset (must be the same across all files)
   :type dsetName: str
   :param filenames: Either a list of filenames or shell expression
   :type filenames: list or str
   :param strictTypes: If True (default), require all dtypes in all files to have the
                       same precision and sign. If False, allow dtypes of different
                       precision and sign across different files. For example, if one
                       file contains a uint32 dataset and another contains an int64
                       dataset, the contents of both will be read into an int64 pdarray.
   :type strictTypes: bool
   :param allow_errors: Default False, if True will allow files with read errors to be skipped
                        instead of failing.  A warning will be included in the return containing
                        the total number of files skipped due to failure and up to 10 filenames.
   :type allow_errors: bool
   :param calc_string_offsets: Default False, if True this will tell the server to calculate the
                               offsets/segments array on the server versus loading them from HDF5 files.
                               In the future this option may be set to True as the default.
   :type calc_string_offsets: bool

   :returns: A pdarray or Strings instance pointing to the server-side data
   :rtype: Union[pdarray,Strings]

   :raises TypeError: Raised if dsetName is not a str or if filenames is neither a string
       nor a list of strings
   :raises ValueError: Raised if all datasets are not present in all hdf5 files
   :raises RuntimeError: Raised if one or more of the specified files cannot be opened

   .. seealso:: :obj:`get_datasets`, :obj:`ls_hdf`, :obj:`read_all`, :obj:`load`, :obj:`save`

   .. rubric:: Notes

   If filenames is a string, it is interpreted as a shell expression
   (a single filename is a valid expression, so it will work) and is
   expanded with glob to read all matching files. Use ``get_datasets`` to
   show the names of datasets in HDF5 files.

   If dsetName is not present in all files, a TypeError is raised.


.. py:function:: read_all(filenames: Union[str, List[str]], datasets: Optional[Union[str, List[str]]] = None, iterative: bool = False, strictTypes: bool = True, allow_errors: bool = False, calc_string_offsets=False) -> Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, Mapping[str, Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]]

   Read datasets from HDF5 files.

   :param filenames: Either a list of filenames or shell expression
   :type filenames: list or str
   :param datasets: (List of) name(s) of dataset(s) to read (default: all available)
   :type datasets: list or str or None
   :param iterative: Iterative (True) or Single (False) function call(s) to server
   :type iterative: bool
   :param strictTypes: If True (default), require all dtypes of a given dataset to have the
                       same precision and sign. If False, allow dtypes of different
                       precision and sign across different files. For example, if one
                       file contains a uint32 dataset and another contains an int64
                       dataset with the same name, the contents of both will be read
                       into an int64 pdarray.
   :type strictTypes: bool
   :param allow_errors: Default False, if True will allow files with read errors to be skipped
                        instead of failing.  A warning will be included in the return containing
                        the total number of files skipped due to failure and up to 10 filenames.
   :type allow_errors: bool
   :param calc_string_offsets: Default False, if True this will tell the server to calculate the
                               offsets/segments array on the server versus loading them from HDF5 files.
                               In the future this option may be set to True as the default.
   :type calc_string_offsets: bool

   :returns: * *For a single dataset returns an Arkouda pdarray or Arkouda Strings object*
             * *and for multiple datasets returns a dictionary of Arkouda pdarrays or*
             * *Arkouda Strings.* -- Dictionary of {datasetName: pdarray or String}

   :raises ValueError: Raised if all datasets are not present in all hdf5 files or if one or
       more of the specified files do not exist
   :raises RuntimeError: Raised if one or more of the specified files cannot be opened.
       If `allow_errors` is true this may be raised if no values are returned
       from the server.
   :raises TypeError: Raised if we receive an unknown arkouda_type returned from the server

   .. seealso:: :obj:`read_hdf`, :obj:`get_datasets`, :obj:`ls_hdf`

   .. rubric:: Notes

   If filenames is a string, it is interpreted as a shell expression
   (a single filename is a valid expression, so it will work) and is
   expanded with glob to read all matching files.

   If iterative == True each dataset name and file names are passed to
   the server as independent sequential strings while if iterative == False
   all dataset names and file names are passed to the server in a single
   string.

   If datasets is None, infer the names of datasets from the first file
   and read all of them. Use ``get_datasets`` to show the names of datasets
   to HDF5 files.


.. py:function:: load(path_prefix: str, dataset: str = 'array', calc_string_offsets: bool = False) -> Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]

   Load a pdarray previously saved with ``pdarray.save()``.

   :param path_prefix: Filename prefix used to save the original pdarray
   :type path_prefix: str
   :param dataset: Dataset name where the pdarray was saved, defaults to 'array'
   :type dataset: str
   :param calc_string_offsets: If True the server will ignore Segmented Strings 'offsets' array and derive
                               it from the null-byte terminators.  Defaults to False currently
   :type calc_string_offsets: bool

   :returns: The pdarray or Strings that was previously saved
   :rtype: Union[pdarray, Strings]

   :raises TypeError: Raised if either path_prefix or dataset is not a str
   :raises ValueError: Raised if the dataset is not present in all hdf5 files or if the
       path_prefix does not correspond to files accessible to Arkouda
   :raises RuntimeError: Raised if the hdf5 files are present but there is an error in opening
       one or more of them

   .. seealso:: :obj:`save`, :obj:`load_all`, :obj:`read_hdf`, :obj:`read_all`


.. py:function:: get_datasets(filename: str, is_parquet=False) -> List[str]

   Get the names of datasets in an HDF5 file.

   :param filename: Name of an HDF5/Parquet file visible to the arkouda server
   :type filename: str
   :param is_parquet: Is filename a Parquet file; false by default
   :type is_parquet: bool

   :returns: Names of the datasets in the file
   :rtype: List[str]

   :raises TypeError: Raised if filename is not a str
   :raises ValueError: Raised if filename is empty or contains only whitespace
   :raises RuntimeError: Raised if error occurs in executing ls on an HDF5 file

   .. seealso:: :obj:`ls_hdf`


.. py:function:: load_all(path_prefix: str) -> Mapping[str, Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, arkouda.categorical.Categorical]]

   Load multiple pdarrays or Strings previously saved with ``save_all()``.

   :param path_prefix: Filename prefix used to save the original pdarray
   :type path_prefix: str

   :returns: Dictionary of {datsetName: pdarray} with the previously saved pdarrays
   :rtype: Mapping[str,pdarray]

   :raises TypeError:: Raised if path_prefix is not a str
   :raises ValueError: Raised if all datasets are not present in all hdf5 files or if the
       path_prefix does not correspond to files accessible to Arkouda
   :raises RuntimeError: Raised if the hdf5 files are present but there is an error in opening
       one or more of them

   .. seealso:: :obj:`save_all`, :obj:`load`, :obj:`read_hdf`, :obj:`read_all`


.. py:function:: save_all(columns: Union[Mapping[str, arkouda.pdarrayclass.pdarray], List[arkouda.pdarrayclass.pdarray]], prefix_path: str, names: List[str] = None, mode: str = 'truncate') -> None

   Save multiple named pdarrays to HDF5 files.

   :param columns: Collection of arrays to save
   :type columns: dict or list of pdarrays
   :param prefix_path: Directory and filename prefix for output files
   :type prefix_path: str
   :param names: Dataset names for the pdarrays
   :type names: list of str
   :param mode: By default, truncate (overwrite) the output files if they exist.
                If 'append', attempt to create new dataset in existing files.
   :type mode: {'truncate' | 'append'}

   :rtype: None

   :raises ValueError: Raised if (1) the lengths of columns and values differ or (2) the mode
       is not 'truncate' or 'append'

   .. seealso:: :obj:`save`, :obj:`load_all`

   .. rubric:: Notes

   Creates one file per locale containing that locale's chunk of each pdarray.
   If columns is a dictionary, the keys are used as the HDF5 dataset names.
   Otherwise, if no names are supplied, 0-up integers are used. By default,
   any existing files at path_prefix will be overwritten, unless the user
   specifies the 'append' mode, in which case arkouda will attempt to add
   <columns> as new datasets to existing files. If the wrong number of files
   is present or dataset names already exist, a RuntimeError is raised.


.. py:function:: read_parquet(filenames: Union[str, List[str]], dsetname: Union[str, List[str]] = 'array', strictTypes: bool = True, allow_errors: bool = False) -> Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings, Mapping[str, Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]]

   Read a single dataset from multiple Parquet files into an Arkouda
   pdarray object.

   :param filenames: Either a list of filenames or shell expression
   :type filenames: list or str
   :param dsetName: The name of the dataset (must be the same across all files).
                    Defaults to 'array'.
   :type dsetName: str
   :param strictTypes: If True (default), require all dtypes in all files to have the
                       same precision and sign. If False, allow dtypes of different
                       precision and sign across different files. For example, if one
                       file contains a uint32 dataset and another contains an int64
                       dataset, the contents of both will be read into an int64 pdarray.
   :type strictTypes: bool
   :param allow_errors: Default False, if True will allow files with read errors to be skipped
                        instead of failing.  A warning will be included in the return containing
                        the total number of files skipped due to failure and up to 10 filenames.
   :type allow_errors: bool

   :returns: A pdarray instance pointing to the server-side data
   :rtype: pdarray

   :raises TypeError: Raised if dsetName is not a str or if filenames is neither a string
       nor a list of strings
   :raises ValueError: Raised if all datasets are not present in all parquet files
   :raises RuntimeError: Raised if one or more of the specified files cannot be opened

   .. seealso:: :obj:`read_hdf`, :obj:`get_datasets`, :obj:`ls_hdf`, :obj:`read_all`, :obj:`load`, :obj:`save`

   .. rubric:: Notes

   If filenames is a string, it is interpreted as a shell expression
   (a single filename is a valid expression, so it will work) and is
   expanded with glob to read all matching files. Use ``get_datasets`` to
   show the names of datasets in Parquet files.

   If dsetName is not present in all files, a TypeError is raised.


.. py:class:: GroupBy(keys: groupable, assume_sorted: bool = False, hash_strings: bool = True)

   Group an array or list of arrays by value, usually in preparation
   for aggregating the within-group values of another array.

   :param keys: The array to group by value, or if list, the column arrays to group by row
   :type keys: (list of) pdarray, int64, Strings, or Categorical
   :param assume_sorted: If True, assume keys is already sorted (Default: False)
   :type assume_sorted: bool

   .. attribute:: nkeys

      The number of key arrays (columns)

      :type: int

   .. attribute:: size

      The length of the input array(s), i.e. number of rows

      :type: int

   .. attribute:: permutation

      The permutation that sorts the keys array(s) by value (row)

      :type: pdarray

   .. attribute:: unique_keys

      The unique values of the keys array(s), in grouped order

      :type: (list of) pdarray, Strings, or Categorical

   .. attribute:: ngroups

      The length of the unique_keys array(s), i.e. number of groups

      :type: int

   .. attribute:: segments

      The start index of each group in the grouped array(s)

      :type: pdarray

   .. attribute:: logger

      Used for all logging operations

      :type: ArkoudaLogger

   :raises TypeError: Raised if keys is a pdarray with a dtype other than int64

   .. rubric:: Notes

   Only accepts (list of) pdarrays of int64 dtype, Strings, or Categorical.

   .. py:attribute:: Reductions
      

      

   .. py:method:: find_segments(self) -> None


   .. py:method:: count(self) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Count the number of elements in each group, i.e. the number of times
      each key appears.

      :param none:

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **counts** (*pdarray, int64*) -- The number of times each unique key appears

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 2, 3, 1, 2, 4, 3, 4, 3, 4])
      >>> g = ak.GroupBy(a)
      >>> keys,counts = g.count()
      >>> keys
      array([1, 2, 3, 4])
      >>> counts
      array([1, 2, 4, 3])


   .. py:method:: aggregate(self, values: groupable, operator: str, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group another
      array of values and apply a reduction to each group's values.

      :param values: The values to group and reduce
      :type values: pdarray
      :param operator: The name of the reduction operator to use
      :type operator: str

      :returns: * **unique_keys** (*groupable*) -- The unique keys, in grouped order
                * **aggregates** (*groupable*) -- One aggregate value per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if the requested operator is not supported for the
          values dtype

      .. rubric:: Examples

      >>> keys = ak.arange(0, 10)
      >>> vals = ak.linspace(-1, 1, 10)
      >>> g = ak.GroupBy(keys)
      >>> g.aggregate(vals, 'sum')
      (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([-1, -0.77777777777777768,
      -0.55555555555555536, -0.33333333333333348, -0.11111111111111116,
      0.11111111111111116, 0.33333333333333348, 0.55555555555555536, 0.77777777777777768,
      1]))
      >>> g.aggregate(vals, 'min')
      (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([-1, -0.77777777777777779,
      -0.55555555555555558, -0.33333333333333337, -0.11111111111111116, 0.11111111111111116,
      0.33333333333333326, 0.55555555555555536, 0.77777777777777768, 1]))


   .. py:method:: sum(self, values: arkouda.pdarrayclass.pdarray, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and sum each group's values.

      :param values: The values to group and sum
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_sums** (*pdarray*) -- One sum per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array

      .. rubric:: Notes

      The grouped sum of a boolean ``pdarray`` returns integers.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.sum(b)
      (array([2, 3, 4]), array([8, 14, 6]))


   .. py:method:: prod(self, values: arkouda.pdarrayclass.pdarray, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and compute the product of each group's
      values.

      :param values: The values to group and multiply
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_products** (*pdarray, float64*) -- One product per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object
      :raises ValueError: Raised if the key array size does not match the values size
          or if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if prod is not supported for the values dtype

      .. rubric:: Notes

      The return dtype is always float64.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.prod(b)
      (array([2, 3, 4]), array([12, 108.00000000000003, 8.9999999999999982]))


   .. py:method:: mean(self, values: arkouda.pdarrayclass.pdarray, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and compute the mean of each group's
      values.

      :param values: The values to group and average
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_means** (*pdarray, float64*) -- One mean value per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object
      :raises ValueError: Raised if the key array size does not match the values size
          or if the operator is not in the GroupBy.Reductions array

      .. rubric:: Notes

      The return dtype is always float64.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.mean(b)
      (array([2, 3, 4]), array([2.6666666666666665, 2.7999999999999998, 3]))


   .. py:method:: min(self, values: arkouda.pdarrayclass.pdarray, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the minimum of each group's
      values.

      :param values: The values to group and find minima
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_minima** (*pdarray*) -- One minimum per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if min is
          not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values size
          or if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if min is not supported for the values dtype

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.min(b)
      (array([2, 3, 4]), array([1, 1, 3]))


   .. py:method:: max(self, values: arkouda.pdarrayclass.pdarray, skipna: bool = True) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the maximum of each
      group's values.

      :param values: The values to group and find maxima
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_maxima** (*pdarray*) -- One maximum per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if max is
          not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if max is not supported for the values dtype

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.max(b)
      (array([2, 3, 4]), array([4, 4, 3]))


   .. py:method:: argmin(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the location of the first
      minimum of each group's values.

      :param values: The values to group and find argmin
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_argminima** (*pdarray, int64*) -- One index per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if argmax
          is not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values
          size or if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if argmin is not supported for the values dtype

      .. rubric:: Notes

      The returned indices refer to the original values array as
      passed in, not the permutation applied by the GroupBy instance.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.argmin(b)
      (array([2, 3, 4]), array([5, 4, 2]))


   .. py:method:: argmax(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and return the location of the first
      maximum of each group's values.

      :param values: The values to group and find argmax
      :type values: pdarray

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_argmaxima** (*pdarray, int64*) -- One index per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray object or if argmax
          is not supported for the values dtype
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array

      .. rubric:: Notes

      The returned indices refer to the original values array as passed in,
      not the permutation applied by the GroupBy instance.

      .. rubric:: Examples

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> g = ak.GroupBy(a)
      >>> g.keys
      array([3, 3, 4, 3, 3, 2, 3, 2, 4, 2])
      >>> b = ak.randint(1,5,10)
      >>> b
      array([3, 3, 3, 4, 1, 1, 3, 3, 3, 4])
      >>> g.argmax(b)
      (array([2, 3, 4]), array([9, 3, 2]))


   .. py:method:: nunique(self, values: groupable) -> Tuple[groupable, arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group another
      array of values and return the number of unique values in each group.

      :param values: The values to group and find unique values
      :type values: pdarray, int64

      :returns: * **unique_keys** (*groupable*) -- The unique keys, in grouped order
                * **group_nunique** (*groupable*) -- Number of unique values per unique key in the GroupBy instance

      :raises TypeError: Raised if the dtype(s) of values array(s) does/do not support
          the nunique method
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if nunique is not supported for the values dtype

      .. rubric:: Examples

      >>> data = ak.array([3, 4, 3, 1, 1, 4, 3, 4, 1, 4])
      >>> data
      array([3, 4, 3, 1, 1, 4, 3, 4, 1, 4])
      >>> labels = ak.array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4])
      >>> labels
      ak.array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4])
      >>> g = ak.GroupBy(labels)
      >>> g.keys
      ak.array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4])
      >>> g.nunique(data)
      array([1,2,3,4]), array([2, 2, 3, 1])
      #    Group (1,1,1) has values [3,4,3] -> there are 2 unique values 3&4
      #    Group (2,2,2) has values [1,1,4] -> 2 unique values 1&4
      #    Group (3,3,3) has values [3,4,1] -> 3 unique values
      #    Group (4) has values [4] -> 1 unique value


   .. py:method:: any(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[Union[arkouda.pdarrayclass.pdarray, List[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]], arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group another
      array of values and perform an "or" reduction on each group.

      :param values: The values to group and reduce with "or"
      :type values: pdarray, bool

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_any** (*pdarray, bool*) -- One bool per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not bool
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array


   .. py:method:: all(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[Union[arkouda.pdarrayclass.pdarray, List[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]], arkouda.pdarrayclass.pdarray]

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform an "and" reduction on
      each group.

      :param values: The values to group and reduce with "and"
      :type values: pdarray, bool

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **group_any** (*pdarray, bool*) -- One bool per unique key in the GroupBy instance

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not bool
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype


   .. py:method:: OR(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[Union[arkouda.pdarrayclass.pdarray, List[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]], arkouda.pdarrayclass.pdarray]

      Bitwise OR of values in each segment.

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform a bitwise OR reduction on
      each group.

      :param values: The values to group and reduce with OR
      :type values: pdarray, int64

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **result** (*pdarray, int64*) -- Bitwise OR of values in segments corresponding to keys

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not int64
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype


   .. py:method:: AND(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[Union[arkouda.pdarrayclass.pdarray, List[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]], arkouda.pdarrayclass.pdarray]

      Bitwise AND of values in each segment.

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform a bitwise AND reduction on
      each group.

      :param values: The values to group and reduce with AND
      :type values: pdarray, int64

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **result** (*pdarray, int64*) -- Bitwise AND of values in segments corresponding to keys

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not int64
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype


   .. py:method:: XOR(self, values: arkouda.pdarrayclass.pdarray) -> Tuple[Union[arkouda.pdarrayclass.pdarray, List[Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]], arkouda.pdarrayclass.pdarray]

      Bitwise XOR of values in each segment.

      Using the permutation stored in the GroupBy instance, group
      another array of values and perform a bitwise XOR reduction on
      each group.

      :param values: The values to group and reduce with XOR
      :type values: pdarray, int64

      :returns: * **unique_keys** (*(list of) pdarray or Strings*) -- The unique keys, in grouped order
                * **result** (*pdarray, int64*) -- Bitwise XOR of values in segments corresponding to keys

      :raises TypeError: Raised if the values array is not a pdarray or if the pdarray
          dtype is not int64
      :raises ValueError: Raised if the key array size does not match the values size or
          if the operator is not in the GroupBy.Reductions array
      :raises RuntimeError: Raised if all is not supported for the values dtype


   .. py:method:: broadcast(self, values: arkouda.pdarrayclass.pdarray, permute: bool = True) -> arkouda.pdarrayclass.pdarray

      Fill each group's segment with a constant value.

      :param values: The values to put in each group's segment
      :type values: pdarray
      :param permute: If True (default), permute broadcast values back to the ordering
                      of the original array on which GroupBy was called. If False, the
                      broadcast values are grouped by value.
      :type permute: bool

      :returns: The broadcast values
      :rtype: pdarray

      :raises TypeError: Raised if value is not a pdarray object
      :raises ValueError: Raised if the values array does not have one
          value per segment

      .. rubric:: Notes

      This function is a sparse analog of ``np.broadcast``. If a
      GroupBy object represents a sparse matrix (tensor), then
      this function takes a (dense) column vector and replicates
      each value to the non-zero elements in the corresponding row.

      .. rubric:: Examples

      >>> a = ak.array([0, 1, 0, 1, 0])
      >>> values = ak.array([3, 5])
      >>> g = ak.GroupBy(a)
      # By default, result is in original order
      >>> g.broadcast(values)
      array([3, 5, 3, 5, 3])

      # With permute=False, result is in grouped order
      >>> g.broadcast(values, permute=False)
      array([3, 3, 3, 5, 5]

      >>> a = ak.randint(1,5,10)
      >>> a
      array([3, 1, 4, 4, 4, 1, 3, 3, 2, 2])
      >>> g = ak.GroupBy(a)
      >>> keys,counts = g.count()
      >>> g.broadcast(counts > 2)
      array([True False True True True False True True False False])
      >>> g.broadcast(counts == 3)
      array([True False True True True False True True False False])
      >>> g.broadcast(counts < 4)
      array([True True True True True True True True True True])



.. py:function:: broadcast(segments: arkouda.pdarrayclass.pdarray, values: arkouda.pdarrayclass.pdarray, size: Union[int, numpy.int64, numpy.uint64] = -1, permutation: Union[arkouda.pdarrayclass.pdarray, None] = None)

   Broadcast a dense column vector to the rows of a sparse matrix or grouped array.

   :param segments: Offsets of the start of each row in the sparse matrix or grouped array.
                    Must be sorted in ascending order.
   :type segments: pdarray, int64
   :param values: The values to broadcast, one per row (or group)
   :type values: pdarray
   :param size: The total number of nonzeros in the matrix. If permutation is given, this
                argument is ignored and the size is inferred from the permutation array.
   :type size: int
   :param permutation: The permutation to go from the original ordering of nonzeros to the ordering
                       grouped by row. To broadcast values back to the original ordering, this
                       permutation will be inverted. If no permutation is supplied, it is assumed
                       that the original nonzeros were already grouped by row. In this case, the
                       size argument must be given.
   :type permutation: pdarray, int64

   :returns: The broadcast values, one per nonzero
   :rtype: pdarray

   :raises ValueError: - If segments and values are different sizes
       - If segments are empty
       - If number of nonzeros (either user-specified or inferred from permutation)
         is less than one

   .. rubric:: Examples

   # Define a sparse matrix with 3 rows and 7 nonzeros
   >>> row_starts = ak.array([0, 2, 5])
   >>> nnz = 7
   # Broadcast the row number to each nonzero element
   >>> row_number = ak.arange(3)
   >>> ak.broadcast(row_starts, row_number, nnz)
   array([0 0 1 1 1 2 2])

   # If the original nonzeros were in reverse order...
   >>> permutation = ak.arange(6, -1, -1)
   >>> ak.broadcast(row_starts, row_number, permutation=permutation)
   array([2 2 1 1 1 0 0])


.. py:data:: GROUPBY_REDUCTION_TYPES
   

   

.. py:class:: Strings(strings_pdarray: arkouda.pdarrayclass.pdarray, bytes_size: arkouda.dtypes.int_scalars)

   Represents an array of strings whose data resides on the
   arkouda server. The user should not call this class directly;
   rather its instances are created by other arkouda functions.

   .. attribute:: entry

      Encapsulation of a Segmented Strings array contained on
      the arkouda server.  This is a composite of
       - offsets array: starting indices for each string
       - bytes array: raw bytes of all strings joined by nulls

      :type: pdarray

   .. attribute:: size

      The number of strings in the array

      :type: int_scalars

   .. attribute:: nbytes

      The total number of bytes in all strings

      :type: int_scalars

   .. attribute:: ndim

      The rank of the array (currently only rank 1 arrays supported)

      :type: int_scalars

   .. attribute:: shape

      The sizes of each dimension of the array

      :type: tuple

   .. attribute:: dtype

      The dtype is ak.str

      :type: dtype

   .. attribute:: logger

      Used for all logging operations

      :type: ArkoudaLogger

   .. rubric:: Notes

   Strings is composed of two pdarrays: (1) offsets, which contains the
   starting indices for each string and (2) bytes, which contains the
   raw bytes of all strings, delimited by nulls.

   .. py:attribute:: BinOps
      

      

   .. py:attribute:: objtype
      :annotation: = str

      

   .. py:method:: from_return_msg(rep_msg: str) -> Strings
      :staticmethod:

      Factory method for creating a Strings object from an Arkouda server
      response message

      :param rep_msg: Server response message currently of form
                      `created name type size ndim shape itemsize+created bytes.size 1234`
      :type rep_msg: str

      :returns: object representing a segmented strings array on the server
      :rtype: Strings

      :raises RuntimeError: Raised if there's an error converting a server-returned str-descriptor

      .. rubric:: Notes

      We really don't have an itemsize because these are variable length strings.
      In the future we could probably use this position to store the total bytes.


   .. py:method:: from_parts(offset_attrib: Union[arkouda.pdarrayclass.pdarray, str], bytes_attrib: Union[arkouda.pdarrayclass.pdarray, str]) -> Strings
      :staticmethod:

      Factory method for creating a Strings object from an Arkouda server
      response where the arrays are separate components.

      :param offset_attrib: the array containing the offsets
      :type offset_attrib: Union[pdarray, str]
      :param bytes_attrib: the array containing the string values
      :type bytes_attrib: Union[pdarray, str]

      :returns: object representing a segmented strings array on the server
      :rtype: Strings

      :raises RuntimeError: Raised if there's an error converting a server-returned str-descriptor

      .. rubric:: Notes

      This factory method is used when we construct the parts of a Strings
      object on the client side and transfer the offsets & bytes separately
      to the server.  This results in two entries in the symbol table and we
      need to instruct the server to assemble the into a composite entity.


   .. py:method:: __iter__(self)
      :abstractmethod:


   .. py:method:: __len__(self) -> int


   .. py:method:: __str__(self) -> str

      Return str(self).


   .. py:method:: __repr__(self) -> str

      Return repr(self).


   .. py:method:: _binop(self, other: Union[Strings, arkouda.dtypes.str_scalars], op: str) -> arkouda.pdarrayclass.pdarray

      Executes the requested binop on this Strings instance and the
      parameter Strings object and returns the results within
      a pdarray object.

      :param other: the other object is a Strings object
      :type other: Strings, str_scalars
      :param op: name of the binary operation to be performed
      :type op: str

      :returns: encapsulating the results of the requested binop
      :rtype: pdarray

      :raises ValueError: Raised if (1) the op is not in the self.BinOps set, or (2) if the
          sizes of this and the other instance don't match, or (3) the other
          object is not a Strings object
      :raises RuntimeError: Raised if a server-side error is thrown while executing the
          binary operation


   .. py:method:: __eq__(self, other) -> bool

      Return self==value.


   .. py:method:: __ne__(self, other) -> bool

      Return self!=value.


   .. py:method:: __getitem__(self, key)


   .. py:method:: get_lengths(self) -> arkouda.pdarrayclass.pdarray

      Return the length of each string in the array.

      :returns: The length of each string
      :rtype: pdarray, int

      :raises RuntimeError: Raised if there is a server-side error thrown


   .. py:method:: cached_regex_patterns(self) -> List

      Returns the regex patterns for which Match objects have been cached


   .. py:method:: purge_cached_regex_patterns(self) -> None

      purges cached regex patterns


   .. py:method:: _get_matcher(self, pattern: Union[bytes, arkouda.dtypes.str_scalars], create: bool = True)

      internal function to fetch cached Matcher objects


   .. py:method:: find_locations(self, pattern: Union[bytes, arkouda.dtypes.str_scalars]) -> Tuple[arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray]

      Finds pattern matches and returns pdarrays containing the number, start postitions, and lengths of matches

      :param pattern: The regex pattern used to find matches
      :type pattern: str_scalars

      :returns: * *pdarray, int64* -- For each original string, the number of pattern matches
                * *pdarray, int64* -- The start positons of pattern matches
                * *pdarray, int64* -- The lengths of pattern matches

      :raises TypeError: Raised if the pattern parameter is not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.findall`, :obj:`Strings.match`

      .. rubric:: Examples

      >>> strings = ak.array(['{} string {}'.format(i, i) for i in range(1, 6)])
      >>> num_matches, starts, lens = strings.find_locations('\d')
      >>> num_matches
      array([2, 2, 2, 2, 2])
      >>> starts
      array([0, 9, 0, 9, 0, 9, 0, 9, 0, 9])
      >>> lens
      array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))


   .. py:method:: search(self, pattern: Union[bytes, arkouda.dtypes.str_scalars]) -> arkouda.match.Match

      Returns a match object with the first location in each element where pattern produces a match.
      Elements match if any part of the string matches the regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: str

      :returns: Match object where elements match if any part of the string matches the regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.search('_+')
      <ak.Match object: matched=True, span=(1, 2); matched=True, span=(0, 4); matched=False; matched=True, span=(0, 2); matched=False>


   .. py:method:: match(self, pattern: Union[bytes, arkouda.dtypes.str_scalars]) -> arkouda.match.Match

      Returns a match object where elements match only if the beginning of the string matches the regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: str

      :returns: Match object where elements match only if the beginning of the string matches the regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.match('_+')
      <ak.Match object: matched=False; matched=True, span=(0, 4); matched=False; matched=True, span=(0, 2); matched=False>


   .. py:method:: fullmatch(self, pattern: Union[bytes, arkouda.dtypes.str_scalars]) -> arkouda.match.Match

      Returns a match object where elements match only if the whole string matches the regular expression pattern

      :param pattern: Regex used to find matches
      :type pattern: str

      :returns: Match object where elements match only if the whole string matches the regular expression pattern
      :rtype: Match

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.fullmatch('_+')
      <ak.Match object: matched=False; matched=True, span=(0, 4); matched=False; matched=False; matched=False>


   .. py:method:: split(self, pattern: Union[bytes, arkouda.dtypes.str_scalars], maxsplit: int = 0, return_segments: bool = False) -> Union[Strings, Tuple]

      Returns a new Strings split by the occurrences of pattern. If maxsplit is nonzero, at most maxsplit splits occur

      :param pattern: Regex used to split strings into substrings
      :type pattern: str
      :param maxsplit: The max number of pattern match occurences in each element to split.
                       The default maxsplit=0 splits on all occurences
      :type maxsplit: int
      :param return_segments: If True, return mapping of original strings to first substring
                              in return array.
      :type return_segments: bool

      :returns: * *Strings* -- Substrings with pattern matches removed
                * *pdarray, int64 (optional)* -- For each original string, the index of first corresponding substring
                  in the return array

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.split('_+', maxsplit=2, return_segments=True)
      (array(['1', '2', '', '', '', '3', '', '4', '5____6___7', '']), array([0 3 5 6 9]))


   .. py:method:: findall(self, pattern: Union[bytes, arkouda.dtypes.str_scalars], return_match_origins: bool = False) -> Union[Strings, Tuple]

      Return a new Strings containg all non-overlapping matches of pattern

      :param pattern: Regex used to find matches
      :type pattern: str_scalars
      :param return_match_origins: If True, return a pdarray containing the index of the original string each pattern match is from
      :type return_match_origins: bool

      :returns: * *Strings* -- Strings object containing only pattern matches
                * *pdarray, int64 (optional)* -- The index of the original string each pattern match is from

      :raises TypeError: Raised if the pattern parameter is not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.find_locations`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.findall('_+', return_match_origins=True)
      (array(['_', '___', '____', '__', '___', '____', '___']), array([0 0 1 3 3 3 3]))


   .. py:method:: sub(self, pattern: Union[bytes, arkouda.dtypes.str_scalars], repl: Union[bytes, arkouda.dtypes.str_scalars], count: int = 0) -> Strings

      Return new Strings obtained by replacing non-overlapping occurrences of pattern with the replacement repl.
      If count is nonzero, at most count substitutions occur

      :param pattern: The regex to substitue
      :type pattern: str_scalars
      :param repl: The substring to replace pattern matches with
      :type repl: str_scalars
      :param count: The max number of pattern match occurences in each element to replace.
                    The default count=0 replaces all occurences of pattern with repl
      :type count: int

      :returns: Strings with pattern matches replaced
      :rtype: Strings

      :raises TypeError: Raised if pattern or repl are not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.subn`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.sub(pattern='_+', repl='-', count=2)
      array(['1-2-', '-', '3', '-4-5____6___7', ''])


   .. py:method:: subn(self, pattern: Union[bytes, arkouda.dtypes.str_scalars], repl: Union[bytes, arkouda.dtypes.str_scalars], count: int = 0) -> Tuple

      Perform the same operation as sub(), but return a tuple (new_Strings, number_of_substitions)

      :param pattern: The regex to substitue
      :type pattern: str_scalars
      :param repl: The substring to replace pattern matches with
      :type repl: str_scalars
      :param count: The max number of pattern match occurences in each element to replace.
                    The default count=0 replaces all occurences of pattern with repl
      :type count: int

      :returns: * *Strings* -- Strings with pattern matches replaced
                * *pdarray, int64* -- The number of substitutions made for each element of Strings

      :raises TypeError: Raised if pattern or repl are not bytes or str_scalars
      :raises ValueError: Raised if pattern is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.sub`

      .. rubric:: Examples

      >>> strings = ak.array(['1_2___', '____', '3', '__4___5____6___7', ''])
      >>> strings.subn(pattern='_+', repl='-', count=2)
      (array(['1-2-', '-', '3', '-4-5____6___7', '']), array([2 1 0 2 0]))


   .. py:method:: contains(self, substr: Union[bytes, arkouda.dtypes.str_scalars], regex: bool = False) -> arkouda.pdarrayclass.pdarray

      Check whether each element contains the given substring.

      :param substr: The substring in the form of string or byte array to search for
      :type substr: str_scalars
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2 (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: True for elements that contain substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not bytes or str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.startswith`, :obj:`Strings.endswith`

      .. rubric:: Examples

      >>> strings = ak.array(['{} string {}'.format(i, i) for i in range(1, 6)])
      >>> strings
      array(['1 string 1', '2 string 2', '3 string 3', '4 string 4', '5 string 5'])
      >>> strings.contains('string')
      array([True, True, True, True, True])
      >>> strings.contains('string \d', regex=True)
      array([True, True, True, True, True])


   .. py:method:: startswith(self, substr: Union[bytes, arkouda.dtypes.str_scalars], regex: bool = False) -> arkouda.pdarrayclass.pdarray

      Check whether each element starts with the given substring.

      :param substr: The prefix to search for
      :type substr: Union[bytes, str_scalars]
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2 (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: True for elements that start with substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not a bytes ior str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.contains`, :obj:`Strings.endswith`

      .. rubric:: Examples

      >>> strings_end = ak.array(['string {}'.format(i) for i in range(1, 6)])
      >>> strings_end
      array(['string 1', 'string 2', 'string 3', 'string 4', 'string 5'])
      >>> strings_end.startswith('string')
      array([True, True, True, True, True])
      >>> strings_start = ak.array(['{} string'.format(i) for i in range(1,6)])
      >>> strings_start
      array(['1 string', '2 string', '3 string', '4 string', '5 string'])
      >>> strings_start.startswith('\d str', regex = True)
      array([True, True, True, True, True])


   .. py:method:: endswith(self, substr: Union[bytes, arkouda.dtypes.str_scalars], regex: bool = False) -> arkouda.pdarrayclass.pdarray

      Check whether each element ends with the given substring.

      :param substr: The suffix to search for
      :type substr: Union[bytes, str_scalars]
      :param regex: Indicates whether substr is a regular expression
                    Note: only handles regular expressions supported by re2 (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: True for elements that end with substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if the substr parameter is not bytes or str_scalars
      :raises ValueError: Rasied if substr is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`Strings.contains`, :obj:`Strings.startswith`

      .. rubric:: Examples

      >>> strings_start = ak.array(['{} string'.format(i) for i in range(1,6)])
      >>> strings_start
      array(['1 string', '2 string', '3 string', '4 string', '5 string'])
      >>> strings_start.endswith('ing')
      array([True, True, True, True, True])
      >>> strings_end = ak.array(['string {}'.format(i) for i in range(1, 6)])
      >>> strings_end
      array(['string 1', 'string 2', 'string 3', 'string 4', 'string 5'])
      >>> strings_end.endswith('ing \d', regex = True)
      array([True, True, True, True, True])


   .. py:method:: flatten(self, delimiter: str, return_segments: bool = False, regex: bool = False) -> Union[Strings, Tuple]

      Unpack delimiter-joined substrings into a flat array.

      :param delimiter: Characters used to split strings into substrings
      :type delimiter: str
      :param return_segments: If True, also return mapping of original strings to first substring
                              in return array.
      :type return_segments: bool
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2 (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns: * *Strings* -- Flattened substrings with delimiters removed
                * *pdarray, int64 (optional)* -- For each original string, the index of first corresponding substring
                  in the return array

      .. seealso:: :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> orig = ak.array(['one|two', 'three|four|five', 'six'])
      >>> orig.flatten('|')
      array(['one', 'two', 'three', 'four', 'five', 'six'])
      >>> flat, map = orig.flatten('|', return_segments=True)
      >>> map
      array([0, 2, 5])
      >>> under = ak.array(['one_two', 'three_____four____five', 'six'])
      >>> under_flat, under_map = under.flatten('_+', return_segments=True, regex=True)
      >>> under_flat
      array(['one', 'two', 'three', 'four', 'five', 'six'])
      >>> under_map
      array([0, 2, 5])


   .. py:method:: peel(self, delimiter: Union[bytes, arkouda.dtypes.str_scalars], times: arkouda.dtypes.int_scalars = 1, includeDelimiter: bool = False, keepPartial: bool = False, fromRight: bool = False, regex: bool = False) -> Tuple

      Peel off one or more delimited fields from each string (similar
      to string.partition), returning two new arrays of strings.
      *Warning*: This function is experimental and not guaranteed to work.

      :param delimiter: The separator where the split will occur
      :type delimiter: Union[bytes, str_scalars]
      :param times: The number of times the delimiter is sought, i.e. skip over
                    the first (times-1) delimiters
      :type times: Union[int, np.int64]
      :param includeDelimiter: If true, append the delimiter to the end of the first return
                               array. By default, it is prepended to the beginning of the
                               second return array.
      :type includeDelimiter: bool
      :param keepPartial: If true, a string that does not contain <times> instances of
                          the delimiter will be returned in the first array. By default,
                          such strings are returned in the second array.
      :type keepPartial: bool
      :param fromRight: If true, peel from the right instead of the left (see also rpeel)
      :type fromRight: bool
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2 (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns:

                left: Strings
                    The field(s) peeled from the end of each string (unless
                    fromRight is true)
                right: Strings
                    The remainder of each string after peeling (unless fromRight
                    is true)
      :rtype: Tuple[Strings, Strings]

      :raises TypeError: Raised if the delimiter parameter is not byte or str_scalars, if
          times is not int64, or if includeDelimiter, keepPartial, or
          fromRight is not bool
      :raises ValueError: Raised if times is < 1 or if delimiter is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`rpeel`, :obj:`stick`, :obj:`lstick`

      .. rubric:: Examples

      >>> s = ak.array(['a.b', 'c.d', 'e.f.g'])
      >>> s.peel('.')
      (array(['a', 'c', 'e']), array(['b', 'd', 'f.g']))
      >>> s.peel('.', includeDelimiter=True)
      (array(['a.', 'c.', 'e.']), array(['b', 'd', 'f.g']))
      >>> s.peel('.', times=2)
      (array(['', '', 'e.f']), array(['a.b', 'c.d', 'g']))
      >>> s.peel('.', times=2, keepPartial=True)
      (array(['a.b', 'c.d', 'e.f']), array(['', '', 'g']))


   .. py:method:: rpeel(self, delimiter: Union[bytes, arkouda.dtypes.str_scalars], times: arkouda.dtypes.int_scalars = 1, includeDelimiter: bool = False, keepPartial: bool = False, regex: bool = False)

      Peel off one or more delimited fields from the end of each string
      (similar to string.rpartition), returning two new arrays of strings.
      *Warning*: This function is experimental and not guaranteed to work.

      :param delimiter: The separator where the split will occur
      :type delimiter: Union[bytes, str_scalars]
      :param times: The number of times the delimiter is sought, i.e. skip over
                    the last (times-1) delimiters
      :type times: Union[int, np.int64]
      :param includeDelimiter: If true, prepend the delimiter to the start of the first return
                               array. By default, it is appended to the end of the
                               second return array.
      :type includeDelimiter: bool
      :param keepPartial: If true, a string that does not contain <times> instances of
                          the delimiter will be returned in the second array. By default,
                          such strings are returned in the first array.
      :type keepPartial: bool
      :param regex: Indicates whether delimiter is a regular expression
                    Note: only handles regular expressions supported by re2 (does not support lookaheads/lookbehinds)
      :type regex: bool

      :returns:

                left: Strings
                    The remainder of the string after peeling
                right: Strings
                    The field(s) that were peeled from the right of each string
      :rtype: Tuple[Strings, Strings]

      :raises TypeError: Raised if the delimiter parameter is not bytes or str_scalars or
          if times is not int64
      :raises ValueError: Raised if times is < 1 or if delimiter is not a valid regex
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`peel`, :obj:`stick`, :obj:`lstick`

      .. rubric:: Examples

      >>> s = ak.array(['a.b', 'c.d', 'e.f.g'])
      >>> s.rpeel('.')
      (array(['a', 'c', 'e.f']), array(['b', 'd', 'g']))
      # Compared against peel
      >>> s.peel('.')
      (array(['a', 'c', 'e']), array(['b', 'd', 'f.g']))


   .. py:method:: stick(self, other: Strings, delimiter: Union[bytes, arkouda.dtypes.str_scalars] = '', toLeft: bool = False) -> Strings

      Join the strings from another array onto one end of the strings
      of this array, optionally inserting a delimiter.
      *Warning*: This function is experimental and not guaranteed to work.

      :param other: The strings to join onto self's strings
      :type other: Strings
      :param delimiter: String inserted between self and other
      :type delimiter: str
      :param toLeft: If true, join other strings to the left of self. By default,
                     other is joined to the right of self.
      :type toLeft: bool

      :returns: The array of joined strings
      :rtype: Strings

      :raises TypeError: Raised if the delimiter parameter is not bytes or str_scalars
          or if the other parameter is not a Strings instance
      :raises ValueError: Raised if times is < 1
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`lstick`, :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> s = ak.array(['a', 'c', 'e'])
      >>> t = ak.array(['b', 'd', 'f'])
      >>> s.stick(t, delimiter='.')
      array(['a.b', 'c.d', 'e.f'])


   .. py:method:: __add__(self, other: Strings) -> Strings


   .. py:method:: lstick(self, other: Strings, delimiter: Union[bytes, arkouda.dtypes.str_scalars] = '') -> Strings

      Join the strings from another array onto the left of the strings
      of this array, optionally inserting a delimiter.
      *Warning*: This function is experimental and not guaranteed to work.

      :param other: The strings to join onto self's strings
      :type other: Strings
      :param delimiter: String inserted between self and other
      :type delimiter: Union[bytes,str_scalars]

      :returns: The array of joined strings, as other + self
      :rtype: Strings

      :raises TypeError: Raised if the delimiter parameter is neither bytes nor a str
          or if the other parameter is not a Strings instance
      :raises RuntimeError: Raised if there is a server-side error thrown

      .. seealso:: :obj:`stick`, :obj:`peel`, :obj:`rpeel`

      .. rubric:: Examples

      >>> s = ak.array(['a', 'c', 'e'])
      >>> t = ak.array(['b', 'd', 'f'])
      >>> s.lstick(t, delimiter='.')
      array(['b.a', 'd.c', 'f.e'])


   .. py:method:: __radd__(self, other: Strings) -> Strings


   .. py:method:: hash(self) -> Tuple[arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray]

      Compute a 128-bit hash of each string.

      :returns: A tuple of two int64 pdarrays. The ith hash value is the concatenation
                of the ith values from each array.
      :rtype: Tuple[pdarray,pdarray]

      .. rubric:: Notes

      The implementation uses SipHash128, a fast and balanced hash function (used
      by Python for dictionaries and sets). For realistic numbers of strings (up
      to about 10**15), the probability of a collision between two 128-bit hash
      values is negligible.


   .. py:method:: group(self) -> arkouda.pdarrayclass.pdarray

      Return the permutation that groups the array, placing equivalent
      strings together. All instances of the same string are guaranteed to lie
      in one contiguous block of the permuted array, but the blocks are not
      necessarily ordered.

      :returns: The permutation that groups the array by value
      :rtype: pdarray

      .. seealso:: :obj:`GroupBy`, :obj:`unique`

      .. rubric:: Notes

      If the arkouda server is compiled with "-sSegmentedArray.useHash=true",
      then arkouda uses 128-bit hash values to group strings, rather than sorting
      the strings directly. This method is fast, but the resulting permutation
      merely groups equivalent strings and does not sort them. If the "useHash"
      parameter is false, then a full sort is performed.

      :raises RuntimeError: Raised if there is a server-side error in executing group request or
          creating the pdarray encapsulating the return message


   .. py:method:: to_ndarray(self) -> numpy.ndarray

      Convert the array to a np.ndarray, transferring array data from the
      arkouda server to Python. If the array exceeds a built-in size limit,
      a RuntimeError is raised.

      :returns: A numpy ndarray with the same strings as this array
      :rtype: np.ndarray

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``arkouda.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting ak.maxTransferBytes to a larger
      value, but proceed with caution.

      .. seealso:: :obj:`array`

      .. rubric:: Examples

      >>> a = ak.array(["hello", "my", "world"])
      >>> a.to_ndarray()
      array(['hello', 'my', 'world'], dtype='<U5')
      >>> type(a.to_ndarray())
      numpy.ndarray


   .. py:method:: _comp_to_ndarray(self, comp: str) -> numpy.ndarray

      This is an internal helper function to perform the to_ndarray for one
      of the string components.

      :param comp: The strings component to request
      :type comp: str

      :returns: A numpy ndarray with the same attributes and data as the pdarray
      :rtype: np.ndarray

      :raises RuntimeError: Raised if there is a server-side error thrown, if the pdarray size
          exceeds the built-in client.maxTransferBytes size limit, or if the bytes
          received does not match expected number of bytes

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``client.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting client.maxTransferBytes to a larger
      value, but proceed with caution.


   .. py:method:: astype(self, dtype) -> arkouda.pdarrayclass.pdarray

      Cast values of Strings object to provided dtype

      :param dtype: Dtype to cast to
      :type dtype: np.dtype or str

      :returns: An arkouda pdarray with values converted to the specified data type
      :rtype: ak.pdarray

      .. rubric:: Notes

      This is essentially shorthand for ak.cast(x, '<dtype>') where x is a pdarray.


   .. py:method:: save(self, prefix_path: str, dataset: str = 'strings_array', mode: str = 'truncate', save_offsets: bool = True) -> str

      Save the Strings object to HDF5. The result is a collection of HDF5 files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the Strings array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: The name of the Strings dataset to be written, defaults to strings_array
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Strings dataset within existing files.
      :type mode: str {'truncate' | 'append'}
      :param save_offsets: Defaults to True which will instruct the server to save the offsets array to HDF5
                           If False the offsets array will not be save and will be derived from the string values
                           upon load/read.
      :type save_offsets: bool

      :rtype: String message indicating result of save operation

      :raises ValueError: Raised if the lengths of columns and values differ, or the mode is
          neither 'truncate' nor 'append'
      :raises TypeError: Raised if prefix_path, dataset, or mode is not a str

      .. seealso:: :obj:`pdarrayIO.save`

      .. rubric:: Notes

      Important implementation notes: (1) Strings state is saved as two datasets
      within an hdf5 group: one for the string characters and one for the
      segments corresponding to the start of each string, (2) the hdf5 group is named
      via the dataset parameter.


   .. py:method:: is_registered(self) -> numpy.bool_

      Return True iff the object is contained in the registry

      :param None:

      :returns: Indicates if the object is contained in the registry
      :rtype: bool

      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: _list_component_names(self) -> List[str]

      Internal Function that returns a list of all component names

      :param None:

      :returns: List of all component names
      :rtype: List[str]


   .. py:method:: info(self) -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str


   .. py:method:: pretty_print_info(self) -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None


   .. py:method:: register(self, user_defined_name: str) -> Strings

      Register this Strings object with a user defined name in the arkouda server
      so it can be attached to later using Strings.attach()
      This is an in-place operation, registering a Strings object more than once will
      update the name in the registry and remove the previously registered name.
      A name can only be registered to one object at a time.

      :param user_defined_name: user defined name which the Strings object is to be registered under
      :type user_defined_name: str

      :returns: The same Strings object which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support a fluid programming style.
                Please note you cannot register two different objects with the same name.
      :rtype: Strings

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the Strings object with the user_defined_name
          If the user is attempting to register more than one object with the same name, the former should be
          unregistered first to free up the registration name.

      .. seealso:: :obj:`attach`, :obj:`unregister`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion
      until they are unregistered.


   .. py:method:: unregister(self) -> None

      Unregister a Strings object in the arkouda server which was previously
      registered using register() and/or attached to using attach()


      :rtype: None

      :raises RuntimeError: Raised if the server could not find the internal name/symbol to remove

      .. seealso:: :obj:`register`, :obj:`attach`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion until
      they are unregistered.


   .. py:method:: attach(user_defined_name: str) -> Strings
      :staticmethod:

      class method to return a Strings object attached to the registered name in the arkouda
      server which was registered using register()

      :param user_defined_name: user defined name which the Strings object was registered under
      :type user_defined_name: str

      :returns: the Strings object registered with user_defined_name in the arkouda server
      :rtype: Strings object

      :raises TypeError: Raised if user_defined_name is not a str

      .. seealso:: :obj:`register`, :obj:`unregister`

      .. rubric:: Notes

      Registered names/Strings objects in the server are immune to deletion
      until they are unregistered.


   .. py:method:: unregister_strings_by_name(user_defined_name: str) -> None
      :staticmethod:

      Unregister a Strings object in the arkouda server previously registered via register()

      :param user_defined_name: The registered name of the Strings object
      :type user_defined_name: str

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`attach`, :obj:`is_registered`



.. py:function:: join_on_eq_with_dt(a1: arkouda.pdarrayclass.pdarray, a2: arkouda.pdarrayclass.pdarray, t1: arkouda.pdarrayclass.pdarray, t2: arkouda.pdarrayclass.pdarray, dt: Union[int, numpy.int64], pred: str, result_limit: Union[int, numpy.int64] = 1000) -> Tuple[arkouda.pdarrayclass.pdarray, arkouda.pdarrayclass.pdarray]

   Performs an inner-join on equality between two integer arrays where
   the time-window predicate is also true

   :param a1: pdarray to be joined
   :type a1: pdarray, int64
   :param a2: pdarray to be joined
   :type a2: pdarray, int64
   :param t1: timestamps in millis corresponding to the a1 pdarray
   :type t1: pdarray
   :param t2: timestamps in millis corresponding to the a2 pdarray
   :type t2: pdarray,
   :param dt: time delta
   :type dt: Union[int,np.int64]
   :param pred: time window predicate
   :type pred: str
   :param result_limit: size limit for returned result
   :type result_limit: Union[int,np.int64]

   :returns: * **result_array_one** (*pdarray, int64*) -- a1 indices where a1 == a2
             * **result_array_one** (*pdarray, int64*) -- a2 indices where a2 == a1

   :raises TypeError: Raised if a1, a2, t1, or t2 is not a pdarray, or if dt or
       result_limit is not an int
   :raises ValueError: if a1, a2, t1, or t2 dtype is not int64, pred is not
       'true_dt', 'abs_dt', or 'pos_dt', or result_limit is < 0


.. py:class:: Categorical(values, **kwargs)

   Represents an array of values belonging to named categories. Converting a
   Strings object to Categorical often saves memory and speeds up operations,
   especially if there are many repeated values, at the cost of some one-time
   work in initialization.

   :param values: String values to convert to categories
   :type values: Strings

   .. attribute:: categories

      The set of category labels (determined automatically)

      :type: Strings

   .. attribute:: codes

      The category indices of the values or -1 for N/A

      :type: pdarray, int64

   .. attribute:: permutation

      The permutation that groups the values in the same order as categories

      :type: pdarray, int64

   .. attribute:: segments

      When values are grouped, the starting offset of each group

      :type: pdarray, int64

   .. attribute:: size

      The number of items in the array

      :type: Union[int,np.int64]

   .. attribute:: nlevels

      The number of distinct categories

      :type: Union[int,np.int64]

   .. attribute:: ndim

      The rank of the array (currently only rank 1 arrays supported)

      :type: Union[int,np.int64]

   .. attribute:: shape

      The sizes of each dimension of the array

      :type: tuple

   .. py:attribute:: BinOps
      

      

   .. py:attribute:: RegisterablePieces
      

      

   .. py:attribute:: RequiredPieces
      

      

   .. py:attribute:: objtype
      :annotation: = category

      

   .. py:attribute:: permutation
      

      

   .. py:attribute:: segments
      

      

   .. py:method:: from_codes(cls, codes: arkouda.pdarrayclass.pdarray, categories: arkouda.strings.Strings, permutation=None, segments=None, uses_all_categories=False) -> Categorical
      :classmethod:

      Make a Categorical from codes and categories arrays. If codes and
      categories have already been pre-computed, this constructor saves
      time. If not, please use the normal constructor.

      :param codes: Category indices of each value
      :type codes: pdarray, int64
      :param categories: Unique category labels
      :type categories: Strings
      :param permutation: The permutation that groups the values in the same order
                          as categories
      :type permutation: pdarray, int64
      :param segments: When values are grouped, the starting offset of each group
      :type segments: pdarray, int64

      :returns: The Categorical object created from the input parameters
      :rtype: Categorical

      :raises TypeError: Raised if codes is not a pdarray of int64 objects or if
          categories is not a Strings object


   .. py:method:: to_ndarray(self) -> numpy.ndarray

      Convert the array to a np.ndarray, transferring array data from
      the arkouda server to Python. This conversion discards category
      information and produces an ndarray of strings. If the arrays
      exceeds a built-in size limit, a RuntimeError is raised.

      :returns: A numpy ndarray of strings corresponding to the values in
                this array
      :rtype: np.ndarray

      .. rubric:: Notes

      The number of bytes in the array cannot exceed ``arkouda.maxTransferBytes``,
      otherwise a ``RuntimeError`` will be raised. This is to protect the user
      from overflowing the memory of the system on which the Python client
      is running, under the assumption that the server is running on a
      distributed system with much more memory than the client. The user
      may override this limit by setting ak.maxTransferBytes to a larger
      value, but proceed with caution.


   .. py:method:: __iter__(self)
      :abstractmethod:


   .. py:method:: __len__(self)


   .. py:method:: __str__(self)

      Return str(self).


   .. py:method:: __repr__(self)

      Return repr(self).


   .. py:method:: _binop(self, other: Union[Categorical, arkouda.dtypes.str_scalars], op: arkouda.dtypes.str_scalars) -> arkouda.pdarrayclass.pdarray

      Executes the requested binop on this Categorical instance and returns
      the results within a pdarray object.

      :param other: the other object is a Categorical object or string scalar
      :type other: Union[Categorical,str_scalars]
      :param op: name of the binary operation to be performed
      :type op: str_scalars

      :returns: encapsulating the results of the requested binop
      :rtype: pdarray

      :raises ValueError: Raised if (1) the op is not in the self.BinOps set, or (2) if the
          sizes of this and the other instance don't match
      :raises RuntimeError: Raised if a server-side error is thrown while executing the
          binary operation


   .. py:method:: _r_binop(self, other: Union[Categorical, arkouda.dtypes.str_scalars], op: arkouda.dtypes.str_scalars) -> arkouda.pdarrayclass.pdarray

          Executes the requested reverse binop on this Categorical instance and
          returns the results within a pdarray object.

          Parameters
          ----------
          other : Union[Categorical,str_scalars]
              the other object is a Categorical object or string scalar
          op : str_scalars
              name of the binary operation to be performed

          Returns
          -------
          pdarray
              encapsulating the results of the requested binop

          Raises
      -   -----
          ValueError
              Raised if (1) the op is not in the self.BinOps set, or (2) if the
              sizes of this and the other instance don't match
          RuntimeError
              Raised if a server-side error is thrown while executing the
              binary operation



   .. py:method:: __eq__(self, other)

      Return self==value.


   .. py:method:: __ne__(self, other)

      Return self!=value.


   .. py:method:: __getitem__(self, key) -> Categorical


   .. py:method:: reset_categories(self) -> Categorical

      Recompute the category labels, discarding any unused labels. This
      method is often useful after slicing or indexing a Categorical array,
      when the resulting array only contains a subset of the original
      categories. In this case, eliminating unused categories can speed up
      other operations.

      :returns: A Categorical object generated from the current instance
      :rtype: Categorical


   .. py:method:: contains(self, substr: str) -> arkouda.pdarrayclass.pdarray

      Check whether each element contains the given substring.

      :param substr: The substring to search for
      :type substr: str

      :returns: True for elements that contain substr, False otherwise
      :rtype: pdarray, bool

      :raises TypeError: Raised if substr is not a str

      .. rubric:: Notes

      This method can be significantly faster than the corresponding method
      on Strings objects, because it searches the unique category labels
      instead of the full array.

      .. seealso:: :obj:`Categorical.startswith`, :obj:`Categorical.endswith`


   .. py:method:: startswith(self, substr: str) -> arkouda.pdarrayclass.pdarray

      Check whether each element starts with the given substring.

      :param substr: The substring to search for
      :type substr: str

      :raises TypeError: Raised if substr is not a str

      :returns: True for elements that contain substr, False otherwise
      :rtype: pdarray, bool

      .. rubric:: Notes

      This method can be significantly faster than the corresponding
      method on Strings objects, because it searches the unique category
      labels instead of the full array.

      .. seealso:: :obj:`Categorical.contains`, :obj:`Categorical.endswith`


   .. py:method:: endswith(self, substr: str) -> arkouda.pdarrayclass.pdarray

      Check whether each element ends with the given substring.

      :param substr: The substring to search for
      :type substr: str

      :raises TypeError: Raised if substr is not a str

      :returns: True for elements that contain substr, False otherwise
      :rtype: pdarray, bool

      .. rubric:: Notes

      This method can be significantly faster than the corresponding method
      on Strings objects, because it searches the unique category labels
      instead of the full array.

      .. seealso:: :obj:`Categorical.startswith`, :obj:`Categorical.contains`


   .. py:method:: in1d(self, test: Union[arkouda.strings.Strings, Categorical]) -> arkouda.pdarrayclass.pdarray

      Test whether each element of the Categorical object is
      also present in the test Strings or Categorical object.

      Returns a boolean array the same length as `self` that is True
      where an element of `self` is in `test` and False otherwise.

      :param test: The values against which to test each value of 'self`.
      :type test: Union[Strings,Categorical]

      :returns: The values `self[in1d]` are in the `test` Strings or Categorical object.
      :rtype: pdarray, bool

      :raises TypeError: Raised if test is not a Strings or Categorical object

      .. seealso:: :obj:`unique`, :obj:`intersect1d`, :obj:`union1d`

      .. rubric:: Notes

      `in1d` can be considered as an element-wise function version of the
      python keyword `in`, for 1-D sequences. ``in1d(a, b)`` is logically
      equivalent to ``ak.array([item in b for item in a])``, but is much
      faster and scales to arbitrarily large ``a``.

      .. rubric:: Examples

      >>> strings = ak.array(['String {}'.format(i) for i in range(0,5)])
      >>> cat = ak.Categorical(strings)
      >>> ak.in1d(cat,strings)
      array([True, True, True, True, True])
      >>> strings = ak.array(['String {}'.format(i) for i in range(5,9)])
      >>> catTwo = ak.Categorical(strings)
      >>> ak.in1d(cat,catTwo)
      array([False, False, False, False, False])


   .. py:method:: unique(self) -> Categorical


   .. py:method:: group(self) -> arkouda.pdarrayclass.pdarray

      Return the permutation that groups the array, placing equivalent
      categories together. All instances of the same category are guaranteed
      to lie in one contiguous block of the permuted array, but the blocks
      are not necessarily ordered.

      :returns: The permutation that groups the array by value
      :rtype: pdarray

      .. seealso:: :obj:`GroupBy`, :obj:`unique`

      .. rubric:: Notes

      This method is faster than the corresponding Strings method. If the
      Categorical was created from a Strings object, then this function
      simply returns the cached permutation. Even if the Categorical was
      created using from_codes(), this function will be faster than
      Strings.group() because it sorts dense integer values, rather than
      128-bit hash values.


   .. py:method:: argsort(self)


   .. py:method:: sort(self)


   .. py:method:: concatenate(self, others: Sequence[Categorical], ordered: bool = True) -> Categorical

      Merge this Categorical with other Categorical objects in the array,
      concatenating the arrays and synchronizing the categories.

      :param others: The Categorical arrays to concatenate and merge with this one
      :type others: Sequence[Categorical]
      :param ordered: If True (default), the arrays will be appended in the
                      order given. If False, array data may be interleaved
                      in blocks, which can greatly improve performance but
                      results in non-deterministic ordering of elements.
      :type ordered: bool

      :returns: The merged Categorical object
      :rtype: Categorical

      :raises TypeError: Raised if any others array objects are not Categorical objects

      .. rubric:: Notes

      This operation can be expensive -- slower than concatenating Strings.


   .. py:method:: save(self, prefix_path: str, dataset: str = 'categorical_array', mode: str = 'truncate') -> str

      Save the Categorical object to HDF5. The result is a collection of HDF5 files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path and dataset. Each locale saves its chunk of the Strings array to its
      corresponding file.

      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in HDF5 files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', create a new Categorical dataset within existing files.
      :type mode: str {'truncate' | 'append'}

      :rtype: String message indicating result of save operation

      :raises ValueError: Raised if the lengths of columns and values differ, or the mode is
          neither 'truncate' nor 'append'
      :raises TypeError: Raised if prefix_path, dataset, or mode is not a str

      .. seealso:: :obj:`pdarrayIO.save`, :obj:`pdarrayIO.load_all`

      .. rubric:: Notes

      Important implementation notes: (1) Strings state is saved as two datasets
      within an hdf5 group: one for the string characters and one for the
      segments corresponding to the start of each string, (2) the hdf5 group is named
      via the dataset parameter.


   .. py:method:: register(self, user_defined_name: str) -> Categorical

      Register this Categorical object and underlying components with the Arkouda server

      :param user_defined_name: user defined name the Categorical is to be registered under,
                                this will be the root name for underlying components
      :type user_defined_name: str

      :returns: The same Categorical which is now registered with the arkouda server and has an updated name.
                This is an in-place modification, the original is returned to support a fluid programming style.
                Please note you cannot register two different Categoricals with the same name.
      :rtype: Categorical

      :raises TypeError: Raised if user_defined_name is not a str
      :raises RegistrationError: If the server was unable to register the Categorical with the user_defined_name

      .. seealso:: :obj:`unregister`, :obj:`attach`, :obj:`unregister_categorical_by_name`, :obj:`is_registered`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.


   .. py:method:: unregister(self) -> None

      Unregister this Categorical object in the arkouda server which was previously
      registered using register() and/or attached to using attach()

      :raises RegistrationError: If the object is already unregistered or if there is a server error
          when attempting to unregister

      .. seealso:: :obj:`register`, :obj:`attach`, :obj:`unregister_categorical_by_name`, :obj:`is_registered`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.


   .. py:method:: is_registered(self) -> numpy.bool_

       Return True iff the object is contained in the registry

      :returns: Indicates if the object is contained in the registry
      :rtype: numpy.bool

      :raises RegistrationError: Raised if there's a server-side error or a mis-match of registered components

      .. seealso:: :obj:`register`, :obj:`attach`, :obj:`unregister`, :obj:`unregister_categorical_by_name`

      .. rubric:: Notes

      Objects registered with the server are immune to deletion until
      they are unregistered.


   .. py:method:: _get_components_dict(self) -> Dict

      Internal function that returns a dictionary with all required or non-None components of self

      Required Categorical components (Codes and Categories) are always included in returned components_dict
      Optional Categorical components (Permutation and Segments) are only included if they've been set (are not None)

      :returns:

                Dictionary of all required or non-None components of self
                    Keys: component names (Codes, Categories, Permutation, Segments)
                    Values: components of self
      :rtype: Dict


   .. py:method:: _list_component_names(self) -> List[str]

      Internal function that returns a list of all component names

      :param None:

      :returns: List of all component names
      :rtype: List[str]


   .. py:method:: info(self) -> str

      Returns a JSON formatted string containing information about all components of self

      :param None:

      :returns: JSON string containing information about all components of self
      :rtype: str


   .. py:method:: pretty_print_info(self) -> None

      Prints information about all components of self in a human readable format

      :param None:

      :rtype: None


   .. py:method:: attach(user_defined_name: str) -> Categorical
      :staticmethod:

       Function to return a Categorical object attached to the registered name in the
       arkouda server which was registered using register()

       Parameters
       ----------
       user_defined_name : str
           user defined name which Categorical object was registered under

       Returns
       -------
       Categorical
              The Categorical object created by re-attaching to the corresponding server components

      :raises TypeError:     if user_defined_name is not a string
          
          .. seealso:: :obj:`register`, :obj:`is_registered`, :obj:`unregister`, :obj:`unregister_categorical_by_name`


   .. py:method:: unregister_categorical_by_name(user_defined_name: str) -> None
      :staticmethod:

      Function to unregister Categorical object by name which was registered
      with the arkouda server via register()

      :param user_defined_name: Name under which the Categorical object was registered
      :type user_defined_name: str

      :raises TypeError: if user_defined_name is not a string
      :raises RegistrationError: if there is an issue attempting to unregister any underlying components

      .. seealso:: :obj:`register`, :obj:`unregister`, :obj:`attach`, :obj:`is_registered`


   .. py:method:: parse_hdf_categoricals(d: Mapping[str, Union[arkouda.pdarrayclass.pdarray, arkouda.strings.Strings]]) -> Tuple[List[str], Dict[str, Categorical]]
      :staticmethod:

      This function should be used in conjunction with the load_all function which reads hdf5 files and reconstitutes
      Categorical objects.  Categorical objects use a naming convention and HDF5 structure so they can be identified
      and constructed for the user.

      In general you should not call this method directly

      :param d:
      :type d: Dictionary of String to either Pdarray or Strings object

      :returns: * *2-Tuple of List of strings containing key names which should be removed and Dictionary of base name to*
                * *Categorical object*

      .. seealso:: :obj:`Categorical.save`, :obj:`load_all`



.. py:function:: enableVerbose() -> None

   Enables verbose logging (DEBUG log level) for all ArkoudaLoggers


.. py:function:: disableVerbose(logLevel: LogLevel = LogLevel.INFO) -> None

   Disables verbose logging (DEBUG log level) for all ArkoudaLoggers, setting
   the log level for each to the logLevel parameter

   :param logLevel: The new log level, defaultts to LogLevel.INFO
   :type logLevel: LogLevel

   :raises TypeError: Raised if logLevel is not a LogLevel enum


.. py:data:: AllSymbols
   :annotation: = __AllSymbols__

   

.. py:data:: RegisteredSymbols
   :annotation: = __RegisteredSymbols__

   

.. py:function:: information(names: Union[List[str], str] = RegisteredSymbols) -> str

   Returns JSON formatted string containing information about the objects in names

   :param names: names is either the name of an object or list of names of objects to retrieve info
                 if names is ak.AllSymbols, retrieves info for all symbols in the symbol table
                 if names is ak.RegisteredSymbols, retrieves info for all symbols in the registry
   :type names: Union[List[str], str]

   :returns: JSON formatted string containing a list of information for each object in names
   :rtype: str

   :raises RuntimeError: Raised if a server-side error is thrown in the process of
       retrieving information about the objects in names


.. py:function:: list_registry() -> List[str]

   Return a list containing the names of all registered objects

   :param None:

   :returns: List of all object names in the registry
   :rtype: list

   :raises RuntimeError: Raised if there's a server-side error thrown


.. py:function:: list_symbol_table() -> List[str]

   Return a list containing the names of all objects in the symbol table

   :param None:

   :returns: List of all object names in the symbol table
   :rtype: list

   :raises RuntimeError: Raised if there's a server-side error thrown


.. py:function:: pretty_print_information(names: Union[List[str], str] = RegisteredSymbols) -> None

   Prints verbose information for each object in names in a human readable format

   :param names: names is either the name of an object or list of names of objects to retrieve info
                 if names is ak.AllSymbols, retrieves info for all symbols in the symbol table
                 if names is ak.RegisteredSymbols, retrieves info for all symbols in the registry
   :type names: Union[List[str], str]

   :rtype: None

   :raises RuntimeError: Raised if a server-side error is thrown in the process of
       retrieving information about the objects in names


