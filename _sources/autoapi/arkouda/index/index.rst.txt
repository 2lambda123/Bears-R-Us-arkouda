:py:mod:`arkouda.index`
=======================

.. py:module:: arkouda.index


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   arkouda.index.Index
   arkouda.index.MultiIndex




.. py:class:: Index(values: Union[List, arkouda.pdarrayclass.pdarray, arkouda.Strings, pandas.Index, Index], name: Optional[str] = None)

   .. py:property:: index

      This is maintained to support older code

   .. py:property:: shape


   .. py:property:: is_unique

      Property indicating if all values in the index are unique
      :rtype: bool - True if all values are unique, False otherwise.

   .. py:method:: __getitem__(key)


   .. py:method:: __repr__()

      Return repr(self).


   .. py:method:: __len__()


   .. py:method:: __eq__(v)

      Return self==value.


   .. py:method:: factory(index)
      :staticmethod:


   .. py:method:: to_pandas()


   .. py:method:: to_ndarray()


   .. py:method:: to_list()


   .. py:method:: set_dtype(dtype)

      Change the data type of the index

      Currently only aku.ip_address and ak.array are supported.


   .. py:method:: register(label)


   .. py:method:: is_registered()

      Return True if the object is contained in the registry

      :returns: Indicates if the object is contained in the registry
      :rtype: bool

      :raises RuntimeError: Raised if there's a server-side error thrown


   .. py:method:: to_dict(label)


   .. py:method:: _check_types(other)


   .. py:method:: _merge(other)


   .. py:method:: _merge_all(idx_list)


   .. py:method:: _check_aligned(other)


   .. py:method:: argsort(ascending=True)


   .. py:method:: concat(other)


   .. py:method:: lookup(key)


   .. py:method:: to_hdf(prefix_path: str, dataset: str = 'index', mode: str = 'truncate', file_type: str = 'distribute') -> str


   .. py:method:: to_parquet(prefix_path: str, dataset: str = 'index', mode: str = 'truncate', compression: Optional[str] = None)


   .. py:method:: save(prefix_path: str, dataset: str = 'index', mode: str = 'truncate', compression: Optional[str] = None, file_format: str = 'HDF5', file_type: str = 'distribute') -> str

      DEPRECATED
      Save the index to HDF5 or Parquet. The result is a collection of files,
      one file per locale of the arkouda server, where each filename starts
      with prefix_path. Each locale saves its chunk of the array to its
      corresponding file.
      :param prefix_path: Directory and filename prefix that all output files share
      :type prefix_path: str
      :param dataset: Name of the dataset to create in files (must not already exist)
      :type dataset: str
      :param mode: By default, truncate (overwrite) output files, if they exist.
                   If 'append', attempt to create new dataset in existing files.
      :type mode: str {'truncate' | 'append'}
      :param compression: (None | "snappy" | "gzip" | "brotli" | "zstd" | "lz4")
                          Sets the compression type used with Parquet files
      :type compression: str (Optional)
      :param file_format: By default, saved files will be written to the HDF5 file format. If
                          'Parquet', the files will be written to the Parquet file format. This
                          is case insensitive.
      :type file_format: str {'HDF5', 'Parquet'}
      :param file_type: Default: "distribute"
                        When set to single, dataset is written to a single file.
                        When distribute, dataset is written on a file per locale.
                        This is only supported by HDF5 files and will have no impact of Parquet Files.
      :type file_type: str ("single" | "distribute")

      :rtype: string message indicating result of save operation

      :raises RuntimeError: Raised if a server-side error is thrown saving the pdarray
      :raises ValueError: Raised if there is an error in parsing the prefix path pointing to
          file write location or if the mode parameter is neither truncate
          nor append
      :raises TypeError: Raised if any one of the prefix_path, dataset, or mode parameters
          is not a string

      .. seealso:: :obj:`save_all`, :obj:`load`, :obj:`read`, :obj:`to_parquet`, :obj:`to_hdf`

      .. rubric:: Notes

      The prefix_path must be visible to the arkouda server and the user must
      have write permission.
      Output files have names of the form ``<prefix_path>_LOCALE<i>``, where ``<i>``
      ranges from 0 to ``numLocales``. If any of the output files already exist and
      the mode is 'truncate', they will be overwritten. If the mode is 'append'
      and the number of output files is less than the number of locales or a
      dataset with the same name already exists, a ``RuntimeError`` will result.
      Previously all files saved in Parquet format were saved with a ``.parquet`` file extension.
      This will require you to use load as if you saved the file with the extension. Try this if
      an older file is not being found.
      Any file extension can be used. The file I/O does not rely on the extension to determine the
      file format.



.. py:class:: MultiIndex(values)

   Bases: :py:obj:`Index`

   .. py:property:: index

      This is maintained to support older code

   .. py:method:: __getitem__(key)


   .. py:method:: __repr__()

      Return repr(self).


   .. py:method:: __len__()


   .. py:method:: __eq__(v)

      Return self==value.


   .. py:method:: to_pandas()


   .. py:method:: set_dtype(dtype)

      Change the data type of the index

      Currently only aku.ip_address and ak.array are supported.


   .. py:method:: register(label)


   .. py:method:: to_dict(labels)


   .. py:method:: _merge(other)


   .. py:method:: _merge_all(array)


   .. py:method:: argsort(ascending=True)


   .. py:method:: concat(other)


   .. py:method:: lookup(key)



