
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Data I/O &#8212; arkouda 0+untagged.1.g4ae49c0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Arithmetic and Numeric Operations" href="arithmetic.html" />
    <link rel="prev" title="Creating Arrays" href="creation.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="data-i-o">
<span id="io-label"></span><h1>Data I/O<a class="headerlink" href="#data-i-o" title="Permalink to this heading">¶</a></h1>
<section id="between-client-and-server">
<h2>Between client and server<a class="headerlink" href="#between-client-and-server" title="Permalink to this heading">¶</a></h2>
<p>Arkouda is designed to integrate with NumPy and Pandas, with arkouda handling large, distributed data in parallel while receiving and sending smaller input and output data to/from Python as NumPy <code class="docutils literal notranslate"><span class="pre">ndarray</span></code> objects. A common arkouda workflow looks like</p>
<ol class="arabic simple">
<li><p>Load in a large dataset with arkouda</p></li>
<li><p>Enter or create a small NumPy array with user data to compare against the large dataset</p></li>
<li><p>Convert the NumPy array to an arkouda array (transferring the data to the server)</p></li>
<li><p>Run computations that filter or summarize the large dataset</p></li>
<li><p>Pass the smaller result set back to Python as a NumPy array for plotting or inspection</p></li>
</ol>
<p>Below are the functions that enable both sides of this transfer.</p>
<dl class="py function">
<dt class="sig sig-object py" id="arkouda.array">
<span class="sig-prename descclassname"><span class="pre">arkouda.</span></span><span class="sig-name descname"><span class="pre">array</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../autoapi/arkouda/pdarrayclass/index.html#arkouda.pdarrayclass.pdarray" title="arkouda.pdarrayclass.pdarray"><span class="pre">pdarray</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Iterable</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">dtype</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">type</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../autoapi/arkouda/pdarrayclass/index.html#arkouda.pdarrayclass.pdarray" title="arkouda.pdarrayclass.pdarray"><span class="pre">pdarray</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../autoapi/arkouda/strings/index.html#arkouda.strings.Strings" title="arkouda.strings.Strings"><span class="pre">Strings</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#arkouda.array" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert a Python or Numpy Iterable to a pdarray or Strings object, sending
the corresponding data to the arkouda server.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>Union</em><em>[</em><a class="reference internal" href="pdarray.html#arkouda.pdarray" title="arkouda.pdarray"><em>pdarray</em></a><em>, </em><em>np.ndarray</em><em>]</em>) – Rank-1 array of a supported dtype</p></li>
<li><p><strong>dtype</strong> (<em>np.dtype</em><em>, </em><em>type</em><em>, or </em><em>str</em>) – The target dtype to cast values to</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A pdarray instance stored on arkouda server or Strings instance, which
is composed of two pdarrays stored on arkouda server</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="pdarray.html#arkouda.pdarray" title="arkouda.pdarray">pdarray</a> or <a class="reference internal" href="../autoapi/arkouda/index.html#id1099" title="arkouda.Strings">Strings</a></p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>TypeError</strong> – Raised if a is not a pdarray, np.ndarray, or Python Iterable such as a
    list, array, tuple, or deque</p></li>
<li><p><strong>RuntimeError</strong> – Raised if a is not one-dimensional, nbytes &gt; maxTransferBytes, a.dtype is
    not supported (not in DTypes), or if the product of a size and
    a.itemsize &gt; maxTransferBytes</p></li>
<li><p><strong>ValueError</strong> – Raised if the returned message is malformed or does not contain the fields
    required to generate the array.</p></li>
</ul>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="pdarray.html#arkouda.pdarray.to_ndarray" title="arkouda.pdarray.to_ndarray"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pdarray.to_ndarray</span></code></a></p>
</div>
<p class="rubric">Notes</p>
<p>The number of bytes in the input array cannot exceed <cite>arkouda.maxTransferBytes</cite>,
otherwise a RuntimeError will be raised. This is to protect the user
from overwhelming the connection between the Python client and the arkouda
server, under the assumption that it is a low-bandwidth connection. The user
may override this limit by setting ak.maxTransferBytes to a larger value,
but should proceed with caution.</p>
<p>If the pdrray or ndarray is of type U, this method is called twice recursively
to create the Strings object and the two corresponding pdarrays for string
bytes and offsets, respectively.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ak</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="go">array([1, 2, 3, 4, 5, 6, 7, 8, 9])</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ak</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="go">array([1, 2, 3, 4, 5, 6, 7, 8, 9])</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">strings</span> <span class="o">=</span> <span class="n">ak</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="sa">f</span><span class="s1">&#39;string </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">type</span><span class="p">(</span><span class="n">strings</span><span class="p">)</span>
<span class="go">&lt;class &#39;arkouda.strings.Strings&#39;&gt;</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="arkouda.pdarray.to_ndarray">
<span class="sig-prename descclassname"><span class="pre">arkouda.pdarray.</span></span><span class="sig-name descname"><span class="pre">to_ndarray</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="headerlink" href="#arkouda.pdarray.to_ndarray" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert the array to a np.ndarray, transferring array data from the
Arkouda server to client-side Python. Note: if the pdarray size exceeds
client.maxTransferBytes, a RuntimeError is raised.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A numpy ndarray with the same attributes and data as the pdarray</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>np.ndarray</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>RuntimeError</strong> – Raised if there is a server-side error thrown, if the pdarray size
    exceeds the built-in client.maxTransferBytes size limit, or if the bytes
    received does not match expected number of bytes</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The number of bytes in the array cannot exceed <code class="docutils literal notranslate"><span class="pre">client.maxTransferBytes</span></code>,
otherwise a <code class="docutils literal notranslate"><span class="pre">RuntimeError</span></code> will be raised. This is to protect the user
from overflowing the memory of the system on which the Python client
is running, under the assumption that the server is running on a
distributed system with much more memory than the client. The user
may override this limit by setting client.maxTransferBytes to a larger
value, but proceed with caution.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">array</span></code>, <a class="reference internal" href="../autoapi/arkouda/index.html#id962" title="arkouda.pdarray.to_list"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_list</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">ak</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">to_ndarray</span><span class="p">()</span>
<span class="go">array([0, 1, 2, 3, 4])</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">type</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">to_ndarray</span><span class="p">())</span>
<span class="go">numpy.ndarray</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="arkouda.Strings.to_ndarray">
<span class="sig-prename descclassname"><span class="pre">arkouda.Strings.</span></span><span class="sig-name descname"><span class="pre">to_ndarray</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="headerlink" href="#arkouda.Strings.to_ndarray" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert the array to a np.ndarray, transferring array data from the
arkouda server to Python. If the array exceeds a built-in size limit,
a RuntimeError is raised.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A numpy ndarray with the same strings as this array</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>np.ndarray</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The number of bytes in the array cannot exceed <code class="docutils literal notranslate"><span class="pre">arkouda.maxTransferBytes</span></code>,
otherwise a <code class="docutils literal notranslate"><span class="pre">RuntimeError</span></code> will be raised. This is to protect the user
from overflowing the memory of the system on which the Python client
is running, under the assumption that the server is running on a
distributed system with much more memory than the client. The user
may override this limit by setting ak.maxTransferBytes to a larger
value, but proceed with caution.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">array</span></code>, <a class="reference internal" href="../autoapi/arkouda/index.html#id1153" title="arkouda.Strings.to_list"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_list</span></code></a></p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">ak</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s2">&quot;hello&quot;</span><span class="p">,</span> <span class="s2">&quot;my&quot;</span><span class="p">,</span> <span class="s2">&quot;world&quot;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">to_ndarray</span><span class="p">()</span>
<span class="go">array([&#39;hello&#39;, &#39;my&#39;, &#39;world&#39;], dtype=&#39;&lt;U5&#39;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">type</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">to_ndarray</span><span class="p">())</span>
<span class="go">numpy.ndarray</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="large-datasets">
<h2>Large Datasets<a class="headerlink" href="#large-datasets" title="Permalink to this heading">¶</a></h2>
<section id="supported-file-formats">
<span id="data-preprocessing-label"></span><h3>Supported File Formats<a class="headerlink" href="#supported-file-formats" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><dl class="simple">
<dt>HDF5</dt><dd><ul>
<li><p>Default File Format</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Parquet</dt><dd><ul>
<li><p>Requires <cite>pyarrow</cite></p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="data-preprocessing">
<h3>Data Preprocessing<a class="headerlink" href="#data-preprocessing" title="Permalink to this heading">¶</a></h3>
<p>Arkouda is designed to work primarily with columnar data spread across multiple files of non-uniform size. All disk-based I/O uses HDF5 or Parquet file format and associates each column of data with an HDF5/Parquet dataset present at the root level of all files.</p>
<p>Files are processed in parallel with one file per locale. While HDF5 has an MPI layer for concurrent reading and writing of a single file from multiple nodes, arkouda does not yet support this functionality.</p>
<p>Because most data does not come in HDF5/Parquet format, the arkouda developers use arkouda in conjunction with several data preprocessing pipelines. While each dataset requires a unique conversion strategy, all preprocessing should:</p>
<ul class="simple">
<li><p>Transpose row-based formats (e.g. CSV) to columns and output each column as an HDF5 dataset</p></li>
<li><p>NOT aggregate input files too aggressively, but keep them separate to enable parallel I/O (hundreds or thousands of files is appropriate, in our experience)</p></li>
<li><p>Convert text to numeric types where possible</p></li>
</ul>
<p>Much of this preprocessing can be accomplished with the Pandas <code class="docutils literal notranslate"><span class="pre">read*</span></code> functions for ingest and the <code class="docutils literal notranslate"><span class="pre">h5py</span></code> or <code class="docutils literal notranslate"><span class="pre">pyarrow</span></code> module for output. See <a class="reference external" href="https://github.com/reuster986/hdflow">this example</a> for ideas.</p>
</section>
<section id="reading-data-from-disk">
<h3>Reading data from disk<a class="headerlink" href="#reading-data-from-disk" title="Permalink to this heading">¶</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="arkouda.read">
<span class="sig-prename descclassname"><span class="pre">arkouda.</span></span><span class="sig-name descname"><span class="pre">read</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filenames</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">datasets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iterative</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strictTypes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allow_errors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">calc_string_offsets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_format</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'infer'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../autoapi/arkouda/pdarrayclass/index.html#arkouda.pdarrayclass.pdarray" title="arkouda.pdarrayclass.pdarray"><span class="pre">pdarray</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../autoapi/arkouda/strings/index.html#arkouda.strings.Strings" title="arkouda.strings.Strings"><span class="pre">Strings</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Mapping</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../autoapi/arkouda/pdarrayclass/index.html#arkouda.pdarrayclass.pdarray" title="arkouda.pdarrayclass.pdarray"><span class="pre">pdarray</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../autoapi/arkouda/strings/index.html#arkouda.strings.Strings" title="arkouda.strings.Strings"><span class="pre">Strings</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#arkouda.read" title="Permalink to this definition">¶</a></dt>
<dd><p>Read datasets from HDF5 or Parquet files.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filenames</strong> (<em>list</em><em> or </em><em>str</em>) – Either a list of filenames or shell expression</p></li>
<li><p><strong>datasets</strong> (<em>list</em><em> or </em><em>str</em><em> or </em><em>None</em>) – (List of) name(s) of dataset(s) to read (default: all available)</p></li>
<li><p><strong>iterative</strong> (<em>bool</em>) – Iterative (True) or Single (False) function call(s) to server</p></li>
<li><p><strong>strictTypes</strong> (<em>bool</em>) – If True (default), require all dtypes of a given dataset to have the
same precision and sign. If False, allow dtypes of different
precision and sign across different files. For example, if one
file contains a uint32 dataset and another contains an int64
dataset with the same name, the contents of both will be read
into an int64 pdarray.</p></li>
<li><p><strong>allow_errors</strong> (<em>bool</em>) – Default False, if True will allow files with read errors to be skipped
instead of failing.  A warning will be included in the return containing
the total number of files skipped due to failure and up to 10 filenames.</p></li>
<li><p><strong>calc_string_offsets</strong> (<em>bool</em>) – Default False, if True this will tell the server to calculate the
offsets/segments array on the server versus loading them from HDF5 files.
In the future this option may be set to True as the default.</p></li>
<li><p><strong>file_format</strong> (<em>str</em>) – Default ‘infer’, if ‘HDF5’ or ‘Parquet’ (case insensitive), the file
type checking will be skipped and will execute expecting all files in
filenames to be of the specified type. Otherwise, will infer filetype
based off of first file in filenames, expanded if a glob expression.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>For a single dataset returns an Arkouda pdarray or Arkouda Strings object</em></p></li>
<li><p><em>and for multiple datasets returns a dictionary of Arkouda pdarrays or</em></p></li>
<li><p><em>Arkouda Strings.</em> – Dictionary of {datasetName: pdarray or String}</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ValueError</strong> – Raised if all datasets are not present in all hdf5/parquet files or if one or
    more of the specified files do not exist</p></li>
<li><p><strong>RuntimeError</strong> – Raised if one or more of the specified files cannot be opened.
    If <cite>allow_errors</cite> is true this may be raised if no values are returned
    from the server.</p></li>
<li><p><strong>TypeError</strong> – Raised if we receive an unknown arkouda_type returned from the server</p></li>
</ul>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#arkouda.read" title="arkouda.read"><code class="xref py py-obj docutils literal notranslate"><span class="pre">read</span></code></a>, <a class="reference internal" href="#arkouda.get_datasets" title="arkouda.get_datasets"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_datasets</span></code></a>, <a class="reference internal" href="../autoapi/arkouda/index.html#arkouda.ls" title="arkouda.ls"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ls</span></code></a></p>
</div>
<p class="rubric">Notes</p>
<p>If filenames is a string, it is interpreted as a shell expression
(a single filename is a valid expression, so it will work) and is
expanded with glob to read all matching files.</p>
<p>If iterative == True each dataset name and file names are passed to
the server as independent sequential strings while if iterative == False
all dataset names and file names are passed to the server in a single
string.</p>
<p>If datasets is None, infer the names of datasets from the first file
and read all of them. Use <code class="docutils literal notranslate"><span class="pre">get_datasets</span></code> to show the names of datasets
to HDF5/Parquet files.</p>
<p class="rubric">Examples</p>
<p>Read with file Extension
&gt;&gt;&gt; x = ak.read(‘path/name_prefix.h5’) # load HDF5 - processing determines file type not extension
Read without file Extension
&gt;&gt;&gt; x = ak.read(‘path/name_prefix.parquet’, file_format=’Parquet’) # load Parquet
Read Glob Expression
&gt;&gt;&gt; x = ak.read(‘path/name_prefix*’) # Reads HDF5</p>
</dd></dl>

<p>For convenience, multiple datasets can be read in to create a dictionary of pdarrays.</p>
<p>HDF5/Parquet files can be queried via the server for dataset names and sizes.</p>
<dl class="py function">
<dt class="sig sig-object py" id="arkouda.get_datasets">
<span class="sig-prename descclassname"><span class="pre">arkouda.</span></span><span class="sig-name descname"><span class="pre">get_datasets</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filename</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#arkouda.get_datasets" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the names of datasets in an HDF5 file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>filename</strong> (<em>str</em>) – Name of an HDF5/Parquet file visible to the arkouda server</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Names of the datasets in the file</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[str]</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>TypeError</strong> – Raised if filename is not a str</p></li>
<li><p><strong>ValueError</strong> – Raised if filename is empty or contains only whitespace</p></li>
<li><p><strong>RuntimeError</strong> – Raised if error occurs in executing ls on an HDF5 file</p></li>
</ul>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="../autoapi/arkouda/index.html#arkouda.ls" title="arkouda.ls"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ls</span></code></a></p>
</div>
</dd></dl>

</section>
<section id="persisting-pdarray-data-to-disk">
<h3>Persisting <code class="docutils literal notranslate"><span class="pre">pdarray</span></code> data to disk<a class="headerlink" href="#persisting-pdarray-data-to-disk" title="Permalink to this heading">¶</a></h3>
<p>Arkouda supports saving pdarrays to HDF5/Parquet files. Unfortunately, arkouda does not yet support writing to a single HDF5 file from multiple locales and must create one output file per locale.</p>
<dl class="py function">
<dt class="sig sig-object py" id="arkouda.pdarray.save">
<span class="sig-prename descclassname"><span class="pre">arkouda.pdarray.</span></span><span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'array'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'truncate'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compressed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_format</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'HDF5'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#arkouda.pdarray.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Save the pdarray to HDF5 or Parquet. The result is a collection of files,
one file per locale of the arkouda server, where each filename starts
with prefix_path. Each locale saves its chunk of the array to its
corresponding file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prefix_path</strong> (<em>str</em>) – Directory and filename prefix that all output files share</p></li>
<li><p><strong>dataset</strong> (<em>str</em>) – Name of the dataset to create in files (must not already exist)</p></li>
<li><p><strong>mode</strong> (<em>str {'truncate'</em><em> | </em><em>'append'}</em>) – By default, truncate (overwrite) output files, if they exist.
If ‘append’, attempt to create new dataset in existing files.</p></li>
<li><p><strong>compressed</strong> (<em>bool</em>) – Defaults to False. When True, files will be written with Snappy compression
and RLE bit packing. This is currently only supported on Parquet files and will
not impact the generated files when writing HDF5 files.</p></li>
<li><p><strong>file_format</strong> (<em>str {'HDF5'</em><em>, </em><em>'Parquet'}</em>) – By default, saved files will be written to the HDF5 file format. If
‘Parquet’, the files will be written to the Parquet file format. This
is case insensitive.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>string message indicating result of save operation</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>RuntimeError</strong> – Raised if a server-side error is thrown saving the pdarray</p></li>
<li><p><strong>ValueError</strong> – Raised if there is an error in parsing the prefix path pointing to
    file write location or if the mode parameter is neither truncate
    nor append</p></li>
<li><p><strong>TypeError</strong> – Raised if any one of the prefix_path, dataset, or mode parameters
    is not a string</p></li>
</ul>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_all</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">read</span></code></p>
</div>
<p class="rubric">Notes</p>
<p>The prefix_path must be visible to the arkouda server and the user must
have write permission.</p>
<p>Output files have names of the form <code class="docutils literal notranslate"><span class="pre">&lt;prefix_path&gt;_LOCALE&lt;i&gt;</span></code>, where <code class="docutils literal notranslate"><span class="pre">&lt;i&gt;</span></code>
ranges from 0 to <code class="docutils literal notranslate"><span class="pre">numLocales</span></code>. If any of the output files already exist and
the mode is ‘truncate’, they will be overwritten. If the mode is ‘append’
and the number of output files is less than the number of locales or a
dataset with the same name already exists, a <code class="docutils literal notranslate"><span class="pre">RuntimeError</span></code> will result.</p>
<p>Previously all files saved in Parquet format were saved with a <code class="docutils literal notranslate"><span class="pre">.parquet</span></code> file extension.
This will require you to use load as if you saved the file with the extension. Try this if
an older file is not being found.</p>
<p>Any file extension can be used.The file I/O does not rely on the extension to
determine the file format.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">ak</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">25</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Saving without an extension</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;path/prefix&#39;</span><span class="p">,</span> <span class="n">dataset</span><span class="o">=</span><span class="s1">&#39;array&#39;</span><span class="p">)</span>
<span class="go">Saves the array to numLocales HDF5 files with the name ``cwd/path/name_prefix_LOCALE####``</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Saving with an extension (HDF5)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;path/prefix.h5&#39;</span><span class="p">,</span> <span class="n">dataset</span><span class="o">=</span><span class="s1">&#39;array&#39;</span><span class="p">)</span>
<span class="go">Saves the array to numLocales HDF5 files with the name</span>
<span class="go">``cwd/path/name_prefix_LOCALE####.h5`` where #### is replaced by each locale number</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Saving with an extension (Parquet)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;path/prefix.parquet&#39;</span><span class="p">,</span> <span class="n">dataset</span><span class="o">=</span><span class="s1">&#39;array&#39;</span><span class="p">,</span> <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;Parquet&#39;</span><span class="p">)</span>
<span class="go">Saves the array in numLocales Parquet files with the name</span>
<span class="go">``cwd/path/name_prefix_LOCALE####.parquet`` where #### is replaced by each locale number</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="arkouda.save_all">
<span class="sig-prename descclassname"><span class="pre">arkouda.</span></span><span class="sig-name descname"><span class="pre">save_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">columns</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Mapping</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../autoapi/arkouda/pdarrayclass/index.html#arkouda.pdarrayclass.pdarray" title="arkouda.pdarrayclass.pdarray"><span class="pre">pdarray</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../autoapi/arkouda/pdarrayclass/index.html#arkouda.pdarrayclass.pdarray" title="arkouda.pdarrayclass.pdarray"><span class="pre">pdarray</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">names</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'HDF5'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'truncate'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#arkouda.save_all" title="Permalink to this definition">¶</a></dt>
<dd><p>Save multiple named pdarrays to HDF5 files.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>columns</strong> (<em>dict</em><em> or </em><em>list of pdarrays</em>) – Collection of arrays to save</p></li>
<li><p><strong>prefix_path</strong> (<em>str</em>) – Directory and filename prefix for output files</p></li>
<li><p><strong>names</strong> (<em>list of str</em>) – Dataset names for the pdarrays</p></li>
<li><p><strong>file_format</strong> (<em>str</em>) – ‘HDF5’ or ‘Parquet’. Defaults to hdf5</p></li>
<li><p><strong>mode</strong> (<em>{'truncate'</em><em> | </em><em>'append'}</em>) – By default, truncate (overwrite) the output files if they exist.
If ‘append’, attempt to create new dataset in existing files.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong> – Raised if (1) the lengths of columns and values differ or (2) the mode
    is not ‘truncate’ or ‘append’</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code>, <a class="reference internal" href="#arkouda.load_all" title="arkouda.load_all"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_all</span></code></a></p>
</div>
<p class="rubric">Notes</p>
<p>Creates one file per locale containing that locale’s chunk of each pdarray.
If columns is a dictionary, the keys are used as the HDF5 dataset names.
Otherwise, if no names are supplied, 0-up integers are used. By default,
any existing files at path_prefix will be overwritten, unless the user
specifies the ‘append’ mode, in which case arkouda will attempt to add
&lt;columns&gt; as new datasets to existing files. If the wrong number of files
is present or dataset names already exist, a RuntimeError is raised.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">ak</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">25</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">ak</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">25</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Save with mapping defining dataset names</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ak</span><span class="o">.</span><span class="n">save_all</span><span class="p">({</span><span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="n">a</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="n">b</span><span class="p">},</span> <span class="s1">&#39;path/name_prefix&#39;</span><span class="p">,</span> <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;Parquet&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Save using names instead of mapping</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ak</span><span class="o">.</span><span class="n">save_all</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="s1">&#39;path/name_prefix&#39;</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;Parquet&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="loading-persisted-arrays-from-disk">
<h3>Loading persisted arrays from disk<a class="headerlink" href="#loading-persisted-arrays-from-disk" title="Permalink to this heading">¶</a></h3>
<p>These functions allow loading <code class="docutils literal notranslate"><span class="pre">pdarray</span></code> data persisted with <code class="docutils literal notranslate"><span class="pre">save()</span></code> and <code class="docutils literal notranslate"><span class="pre">save_all()</span></code>.</p>
<dl class="py function">
<dt class="sig sig-object py" id="arkouda.load">
<span class="sig-prename descclassname"><span class="pre">arkouda.</span></span><span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path_prefix</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_format</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'INFER'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'array'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">calc_string_offsets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../autoapi/arkouda/pdarrayclass/index.html#arkouda.pdarrayclass.pdarray" title="arkouda.pdarrayclass.pdarray"><span class="pre">pdarray</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../autoapi/arkouda/strings/index.html#arkouda.strings.Strings" title="arkouda.strings.Strings"><span class="pre">Strings</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Mapping</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../autoapi/arkouda/pdarrayclass/index.html#arkouda.pdarrayclass.pdarray" title="arkouda.pdarrayclass.pdarray"><span class="pre">pdarray</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../autoapi/arkouda/strings/index.html#arkouda.strings.Strings" title="arkouda.strings.Strings"><span class="pre">Strings</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#arkouda.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Load a pdarray previously saved with <code class="docutils literal notranslate"><span class="pre">pdarray.save()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path_prefix</strong> (<em>str</em>) – Filename prefix used to save the original pdarray</p></li>
<li><p><strong>file_format</strong> (<em>str</em>) – ‘INFER’, ‘HDF5’ or ‘Parquet’. Defaults to ‘INFER’. Used to indicate the file type being loaded.
If INFER, this will be detected during processing</p></li>
<li><p><strong>dataset</strong> (<em>str</em>) – Dataset name where the pdarray was saved, defaults to ‘array’</p></li>
<li><p><strong>calc_string_offsets</strong> (<em>bool</em>) – If True the server will ignore Segmented Strings ‘offsets’ array and derive
it from the null-byte terminators.  Defaults to False currently</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The pdarray or Strings that was previously saved</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[<a class="reference internal" href="pdarray.html#arkouda.pdarray" title="arkouda.pdarray">pdarray</a>, <a class="reference internal" href="../autoapi/arkouda/index.html#id1099" title="arkouda.Strings">Strings</a>]</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>TypeError</strong> – Raised if either path_prefix or dataset is not a str</p></li>
<li><p><strong>ValueError</strong> – Raised if invalid file_format or if the dataset is not present in all hdf5 files or if the
    path_prefix does not correspond to files accessible to Arkouda</p></li>
<li><p><strong>RuntimeError</strong> – Raised if the hdf5 files are present but there is an error in opening
    one or more of them</p></li>
</ul>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code>, <a class="reference internal" href="#arkouda.load_all" title="arkouda.load_all"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_all</span></code></a>, <a class="reference internal" href="#arkouda.read" title="arkouda.read"><code class="xref py py-obj docutils literal notranslate"><span class="pre">read</span></code></a></p>
</div>
<p class="rubric">Notes</p>
<p>If you have a previously saved Parquet file that is raising a FileNotFound error, try loading it
with a .parquet appended to the prefix_path.
Parquet files were previously ALWAYS stored with a <code class="docutils literal notranslate"><span class="pre">.parquet</span></code> extension.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Loading from file without extension</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">obj</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;path/prefix&#39;</span><span class="p">)</span>
<span class="go">Loads the array from numLocales files with the name ``cwd/path/name_prefix_LOCALE####``.</span>
<span class="go">The file type is inferred during processing.</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Loading with an extension (HDF5)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">obj</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;path/prefix.test&#39;</span><span class="p">)</span>
<span class="go">Loads the object from numLocales files with the name ``cwd/path/name_prefix_LOCALE####.test`` where</span>
<span class="go">#### is replaced by each locale numbers. Because filetype is inferred during processing,</span>
<span class="go">the extension is not required to be a specific format.</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="arkouda.load_all">
<span class="sig-prename descclassname"><span class="pre">arkouda.</span></span><span class="sig-name descname"><span class="pre">load_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path_prefix</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_format</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'INFER'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Mapping</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../autoapi/arkouda/pdarrayclass/index.html#arkouda.pdarrayclass.pdarray" title="arkouda.pdarrayclass.pdarray"><span class="pre">pdarray</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../autoapi/arkouda/strings/index.html#arkouda.strings.Strings" title="arkouda.strings.Strings"><span class="pre">Strings</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../autoapi/arkouda/categorical/index.html#arkouda.categorical.Categorical" title="arkouda.categorical.Categorical"><span class="pre">Categorical</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#arkouda.load_all" title="Permalink to this definition">¶</a></dt>
<dd><p>Load multiple pdarrays or Strings previously saved with <code class="docutils literal notranslate"><span class="pre">save_all()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path_prefix</strong> (<em>str</em>) – Filename prefix used to save the original pdarray</p></li>
<li><p><strong>file_format</strong> (<em>str</em>) – ‘INFER’, ‘HDF5’ or ‘Parquet’. Defaults to ‘INFER’. Indicates the format being loaded.
When ‘INFER’ the processing will detect the format
Defaults to ‘HDF5’</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Dictionary of {datsetName: pdarray} with the previously saved pdarrays</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Mapping[str,<a class="reference internal" href="pdarray.html#arkouda.pdarray" title="arkouda.pdarray">pdarray</a>]</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>TypeError:</strong> – Raised if path_prefix is not a str</p></li>
<li><p><strong>ValueError</strong> – Raised if file_format/extension is encountered that is not hdf5 or parquet or
    if all datasets are not present in all hdf5/parquet files or if the
    path_prefix does not correspond to files accessible to Arkouda</p></li>
<li><p><strong>RuntimeError</strong> – Raised if the hdf5 files are present but there is an error in opening
    one or more of them</p></li>
</ul>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#arkouda.save_all" title="arkouda.save_all"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_all</span></code></a>, <a class="reference internal" href="#arkouda.load" title="arkouda.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>, <a class="reference internal" href="#arkouda.read" title="arkouda.read"><code class="xref py py-obj docutils literal notranslate"><span class="pre">read</span></code></a></p>
</div>
<p class="rubric">Notes</p>
<p>This function has been updated to determine the file extension based on the file format variable</p>
</dd></dl>

</section>
<section id="persisting-dataframe-data-to-disk">
<h3>Persisting <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> data to disk<a class="headerlink" href="#persisting-dataframe-data-to-disk" title="Permalink to this heading">¶</a></h3>
<p>Arkouda supports saving <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> objects to HDF5/Parquet files. This is done by creating a dictionary that maps the column name to the pdarray containing the column data. The column names are treated as datasets in the file.</p>
</section>
<section id="loading-persisted-dataframe-data-from-disk">
<h3>Loading persisted DataFrame data from disk<a class="headerlink" href="#loading-persisted-dataframe-data-from-disk" title="Permalink to this heading">¶</a></h3>
<p>This functionality allows the columns be loaded as datasets, which creates a mapping of column names to column data. This structure is supported by the <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> constructor and is used to reconstruct the <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code></p>
</section>
</section>
<section id="import-export">
<h2>Import/Export<a class="headerlink" href="#import-export" title="Permalink to this heading">¶</a></h2>
<p>Import allows users to import data written by pandas into arkouda. Export allows users to write arkouda data into a format pandas can read. The file formats supported are:</p>
<ul class="simple">
<li><p>HDF5</p></li>
<li><p>Parquet</p></li>
</ul>
<p>These save formats are customizable and allow for schemas to be created to fit specific needs. As a result, a file written by Arkouda is not always able to be read by other applications. The import/export features of Arkouda allow for files to be reformatted for reading by Pandas and vice versa.</p>
<p><strong>Import</strong>
Importing data takes a file that was saved using Pandas and reads it into Arkouda. The user is able to specify if they would like to save the result to a file that can be read by Arkouda and/or return the resulting Arkouda object.</p>
<p><strong>Export</strong>
Export takes a file taht was saved using Arkouda and reads it into Pandas. The user is able to specify if they would like to save the result to a file that can be read by Pandas and/or return the resulting Pandas object.</p>
<p>Note: If the file being read in is Parquet, the resulting file that can be read by Arkouda will also be Parquet. This is also true for HDF5.</p>
<p>This functionality is currently performed on the client and is assuming that dataset sizes are able to be handled in the client due to being written by Pandas. Arkouda natively verifies the size of data before writing it to the client, so exports are limited.</p>
<dl class="py function">
<dt class="sig sig-object py" id="arkouda.import_data">
<span class="sig-prename descclassname"><span class="pre">arkouda.</span></span><span class="sig-name descname"><span class="pre">import_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">read_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">write_file</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_obj</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#arkouda.import_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Import data from a file saved by Pandas (HDF5/Parquet) to Arkouda object and/or
a file formatted to be read by Arkouda.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>read_path</strong> (<em>str</em>) – path to file where pandas data is stored. This can be glob expression for parquet formats.</p></li>
<li><p><strong>write_file</strong> (<em>str</em><em>, </em><em>optional</em>) – path to file to write arkouda formatted data to. Only write file if provided</p></li>
<li><p><strong>return_obj</strong> (<em>bool</em><em>, </em><em>optional</em>) – Default True. When True return the Arkouda DataFrame object, otherwise return None</p></li>
<li><p><strong>index</strong> (<em>bool</em><em>, </em><em>optional</em>) – Default False. When True, maintain the indexes loaded from the pandas file</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>RuntimeWarning</strong> – <ul>
<li><p>Export attempted on Parquet file. Arkouda formatted Parquet files are readable by pandas.</p></li>
</ul>
</p></li>
<li><p><strong>RuntimeError</strong> – <ul>
<li><p>Unsupported file type</p></li>
</ul>
</p></li>
</ul>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>When <cite>return_obj=True</cite></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>pd.DataFrame</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">pandas.DataFrame.to_parquet</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">pandas.DataFrame.to_hdf</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">pandas.DataFrame.read_parquet</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">pandas.DataFrame.read_hdf</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">ak.export</span></code></p>
</div>
<p class="rubric">Notes</p>
<ul class="simple">
<li><p>Import can only be performed from hdf5 or parquet files written by pandas.</p></li>
</ul>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="arkouda.export">
<span class="sig-prename descclassname"><span class="pre">arkouda.</span></span><span class="sig-name descname"><span class="pre">export</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">read_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'ak_data'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">write_file</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_obj</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#arkouda.export" title="Permalink to this definition">¶</a></dt>
<dd><p>Export data from Arkouda file (Parquet/HDF5) to Pandas object or file formatted to be
readable by Pandas</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>read_path</strong> (<em>str</em>) – path to file where arkouda data is stored.</p></li>
<li><p><strong>dataset_name</strong> (<em>str</em>) – name to store dataset under</p></li>
<li><p><strong>index</strong> (<em>bool</em>) – Default False. When True, maintain the indexes loaded from the pandas file</p></li>
<li><p><strong>write_file</strong> (<em>str</em><em>, </em><em>optional</em>) – path to file to write pandas formatted data to. Only write the file if this is set</p></li>
<li><p><strong>return_obj</strong> (<em>bool</em><em>, </em><em>optional</em>) – Default True. When True return the Pandas DataFrame object, otherwise return None</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>RuntimeError</strong> – <ul class="simple">
<li><p>Unsupported file type</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>When <cite>return_obj=True</cite></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>pd.DataFrame</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">pandas.DataFrame.to_parquet</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">pandas.DataFrame.to_hdf</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">pandas.DataFrame.read_parquet</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">pandas.DataFrame.read_hdf</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">ak.import_data</span></code></p>
</div>
<p class="rubric">Notes</p>
<ul class="simple">
<li><p>If Arkouda file is exported for pandas, the format will not change. This mean parquet files</p></li>
</ul>
<p>will remain parquet and hdf5 will remain hdf5.
- Export can only be performed from hdf5 or parquet files written by Arkouda. The result will be
the same file type, but formatted to be read by Pandas.</p>
</dd></dl>

</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">arkouda</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../setup/prerequisites.html">Prerequisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="../setup/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../setup/testing.html">Performance Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../setup/quickstart.html">Quickstart</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../usage.html">Usage</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="startup.html">Startup</a></li>
<li class="toctree-l2"><a class="reference internal" href="pdarray.html">The <code class="docutils literal notranslate"><span class="pre">pdarray</span></code> class</a></li>
<li class="toctree-l2"><a class="reference internal" href="creation.html">Creating Arrays</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Data I/O</a></li>
<li class="toctree-l2"><a class="reference internal" href="arithmetic.html">Arithmetic and Numeric Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="indexing.html">Indexing and Assignment</a></li>
<li class="toctree-l2"><a class="reference internal" href="histogram.html">Summarizing Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="argsort.html">Sorting</a></li>
<li class="toctree-l2"><a class="reference internal" href="setops.html">Array Set Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="groupby.html">GroupBy</a></li>
<li class="toctree-l2"><a class="reference internal" href="strings.html">Strings in Arkouda</a></li>
<li class="toctree-l2"><a class="reference internal" href="categorical.html">Categoricals</a></li>
<li class="toctree-l2"><a class="reference internal" href="segarray.html">SegArrays in Arkouda</a></li>
<li class="toctree-l2"><a class="reference internal" href="arrayview.html">ArrayView in Arkouda</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../autoapi/index.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../server/index.html">Chapel API Reference</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="../usage.html">Usage</a><ul>
      <li>Previous: <a href="creation.html" title="previous chapter">Creating Arrays</a></li>
      <li>Next: <a href="arithmetic.html" title="next chapter">Arithmetic and Numeric Operations</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, Michael Merrill and William Reus.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 5.1.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/usage/IO.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>